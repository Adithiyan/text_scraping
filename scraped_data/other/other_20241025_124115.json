{
    "total_articles": 22,
    "articles": [
        {
            "title": "Frequently Asked Questions",
            "text": "Get answers to the most commonly asked questions about Clearview AI's facial recognition solutions.\n\nIs facial recognition legal in the U.S.?\n\n​\n\nYes. Facial recognition technology is legal to use in the United States, including by law enforcement and government agencies. It is commonly used for various purposes in everyday life, such as unlocking phones, logging into websites, and security screening. Some U.S. jurisdictions place restrictions on the use of facial recognition technology, while others have statewide laws that require explicit consent before processing facial recognition data related to an individual. Most state privacy and biometric data laws have exceptions for public data or law enforcement usage. Clearview AI is compliant with all biometric and data privacy laws in every state where we offer our technology.\n\n​\n\n​\n\n​\n\nIs Clearview AI banned in the U.S.?\n\n​\n\nNo, Clearview AI is not banned in the U.S. It’s available in almost every state in the USA, except for states Vermont, New Jersey, Illinois, Maine, Massachusetts and Montana, where there are various restrictions on uses of facial recognition technology.\n\n​\n\n​\n\n​\n\nIs Clearview illegal?\n\n​\n\nNo, Clearview AI’s technology is entirely lawful. Clearview AI technology is only available for government agencies and contractors, and its core customer market is in the USA. Clearview AI does not offer its technology in the EU, UK, Australia and Canada. ‍\n\n​\n\n​\n\n​\n\nDoes Clearview AI offer its technology to entities found on U.S. sanction lists or the Unverified List?\n\n​\n\nNo, Clearview AI does not offer or provide access to its technology product to any country or entity that is on the Unverified List, Specially Designated Nationals List, Entity List, Debarred List, Denied Persons List, sanctioned or partially sanctioned by the United States of America.\n\n​\n\n​\n\n​\n\nH ow is facial recognition used by the police?\n\n​\n\nClearview AI is used by law enforcement and police in an after-the-fact manner, not in real-time, and probe images are searched against a database of public images from the internet and separate customer private image galleries. This means, after a crime has been committed, only then do the police turn to facial recognition technology like Clearview AI to help with identification. Once a search is performed, the search may return a set of potential leads, which the investigator is required to independently verify by both peer review and other means, before continuing with their investigation.\n\n​\n\n​\n\nHow has facial recognition helped to catch criminals?\n\nFacial recognition is used by law enforcement in an after-the-fact manner to assist with the identification of a criminal. After a crime is committed, facial recognition technology like Clearview AI may be used in the investigation process to help identify persons of interest, in addition to other methods of identification. For example, in 2019, the NYPD’s Facial Identification Section used other facial recognition products to identify 2,510 possible matches, including possible matches in 68 murders, 66 rapes, 277 felony assaults, 386 robberies, and 525 grand larcenies.\n\n​\n\n​\n\n​\n\nWhy is facial recognition illegal in some municipalities?\n\nUse of facial recognition technology by law enforcement and government agencies is not illegal in the USA. It is reported that only 25 city councils in the U.S. have a ban on the use of facial recognition technology by government agencies, with exceptions. Contrarily, more than half of U.S. adults trust law enforcement to use facial recognition responsibly (e.g. 77% of Illinois residents say using facial recognition to solve crimes is appropriate).\n\nWhich states have banned facial recognition?\n\nThere are no states in the USA that have an outright ban on facial recognition for law enforcement usage. However, there are 4 out of 50 states with significant restrictions on facial recognition usage by law enforcement: Maine, Vermont, Montana and Massachusetts. ​\n\n​\n\n​\n\nIs Clearview AI available to the public?\n\nNo. Clearview AI’s technology is not available to the general public. It is only provided to vetted law enforcement and government agencies that have been reviewed and approved by Clearview AI's legal department to ensure compliance with due diligence standards. Clearview AI has no plans to release its technology product, which consists of a 50+ billion public image database, to the general public.\n\n​\n\n​\n\nWhat companies use Clearview AI?\n\n​\n\nClearview AI does not offer its search technology platform with the 50 billion + image database to private companies. It is currently only available to vetted law enforcement and government agencies and contractors performing work for those agencies. In 2019, Clearview AI had a handful of non-government customers in banking and retail, who used it for after-the-fact investigations to combat financial fraud and retail theft, but discontinued access for these select customers in early 2020.\n\n​\n\n​\n\n​\n\nDoes Walmart use Clearview AI?\n\n​\n\nNo. Walmart does not use Clearview AI. In 2019, Clearview AI had a handful of non-government customers in banking and retail who used it for after-the-fact investigations to combat financial fraud and retail theft, but discontinued access to these select customers, including Walmart, in early 2020.\n\n​\n\n​\n\n​\n\nIs Clearview still in business?\n\n​\n\nYes. Clearview AI launched in 2017 and has remained in business since then, continuously growing and proudly serving its law enforcement and government customers.\n\n​\n\n​\n\n​\n\nWhat alternatives are there to using Clearview AI?\n\n​\n\nClearview AI is the only technology platform available in the U.S. that offers its unique combination of web crawling and facial recognition capabilities while being in full compliance with data privacy laws. Clearview AI holds U.S. Patent No. 11,250,266, which covers this proprietary technology. There are currently no alternative technology platforms available in the U.S. that offer the same technological and legal compliance capabilities as Clearview AI.\n\n​\n\n​\n\n​\n\nWhat are some of the biggest concerns regarding the use of facial recognition technology?\n\n​\n\nHistorically, one of the biggest concerns associated with facial recognition technology is alleged inaccuracies and biases, particularly racial and demographic biases. However, this perception is largely based on outdated studies and does not accurately reflect Clearview AI's technology, which has been independently tested by the U.S. National Institute of Standards and Technology (NIST) and achieved high accuracy across all demographic groups in that testing.\n\nA second concern relates to individual privacy and use of the technology to perform unrestricted mass surveillance, tracking, and profiling of individuals without their consent. Clearview AI's technology and platform addresses these privacy concerns, as its design and implementation (i) is for use by government agencies and law enforcement for post-event investigations and not for real-time surveillance and (ii) searches are performed only against publicly available online images.\n\n​\n\n​\n\n​\n\nIs facial recognition surveillance?\n\n​\n\nClearview AI is not a real-time surveillance tool. Clearview AI is designed for use in an after-the-fact manner for law enforcement investigations and to generate investigative leads.\n\n​\n\n​\n\n​\n\nIs facial recognition racially biased?\n\n​\n\nBias in facial recognition technology is not inherent but depends on the quality of the technology and the data used, as well as the individual user reviewing facial recognition image search results. The best modern facial recognition algorithms have achieved statistically insignificant levels of inaccuracy and bias. Clearview AI's facial recognition algorithm has been independently tested by the U.S. National Institute of Standards and Technology (NIST), and achieved over 99% accuracy across different demographics and genders in that testing.\n\n​\n\n​\n\n​\n\nHow accurate is facial recognition?\n\n​\n\nFacial recognition technologies have become increasingly accurate in recent years, with advancements rendering it more accurate and sophisticated than the human eye by training on diverse large datasets. Some of the top algorithms evaluated by the National Institute of Standards and Technology (NIST), including Clearview AI’s, demonstrate minimal bias and achieve over 99% accuracy in matching photos out of a large scale database under NIST test conditions.\n\n​\n\n​\n\n​\n\nWhat does Clearview AI do to mitigate misuse of facial recognition technology?\n\n​\n\nClearview AI has implemented several measures to mitigate misuse of its facial recognition technology. These include requiring peer review of search results, mandatory user training, audit features that enable administrators to monitor user activity, mandatory user intake forms detailing the lawful purpose of the investigation, and requiring customers to train their own users and establish facial recognition usage policies. These controls are intended to ensure the responsible and appropriate deployment of Clearview's technology.\n\n​\n\n​\n\n​\n\nDoes Clearview AI have access to my private data?\n\n​\n\nNo, Clearview AI does not have access to your private data. Clearview AI is a search engine that searches images compiled from publicly available online sources. Depending on where you live, you may have the right to access and delete any of your images that may be included in Clearview's database. If applicable, to exercise this right, you can visit Clearview's Privacy Policy page for instructions on how to submit a request.",
            "url": "https://www.clearview.ai/faq#:~:text=No.,compliance%20with%20due%20diligence%20standards.",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "recognition",
                "questions",
                "law",
                "does",
                "technology",
                "enforcement",
                "used",
                "ai",
                "frequently",
                "available",
                "asked",
                "clearview",
                "facial"
            ],
            "summary": "Get answers to the most commonly asked questions about Clearview AI's facial recognition solutions.\nFacial recognition technology is legal to use in the United States, including by law enforcement and government agencies.\nSome U.S. jurisdictions place restrictions on the use of facial recognition technology, while others have statewide laws that require explicit consent before processing facial recognition data related to an individual.\nClearview AI technology is only available for government agencies and contractors, and its core customer market is in the USA.\n​Historically, one of the biggest concerns associated with facial recognition technology is alleged inaccuracies and biases, particularly racial and demographic biases.",
            "metadata": {
                "source_domain": "www.clearview.ai",
                "scrape_date": "2024-10-25T12:40:34.184901",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 9591
            }
        },
        {
            "title": "Privacy Policy",
            "text": "CLEARVIEW AI, INC. PRIVACY POLICY ​ This privacy policy (“Policy”) explains what kind of information Clearview AI, Inc. (“Clearview”) collects from users of all Clearview platforms, Products, Services, applications, websites, technology and other services (“Clearview Platform”), our business-to-business contacts (e.g., our service providers, contractors or processors), from others online, and how we use that data. This Policy applies only to personal information, not to de-identified or aggregate information or other information that cannot identify you. Access to and use of the Clearview Products and Services is subject to the Clearview Terms of Service and User Code of Conduct. Certain elements of the Clearview Platform may operate under separate or additional terms of practice different from or in addition to those described in this Policy; in those cases, you will be provided separate notice and information relevant to your use of those parts of the Clearview Platform. ​ Topics: ​\n\nWhat Data Do We Collect? ​ We collect several types of information for our business operations, including: ​ ​Information users provide to us directly: When users create a user account or conduct business with us, they provide us with information such as name, address, contact information (email and phone number) and employing organization. In addition, if you or a third party sends Clearview a comment, message or other communication (such as, by way of example only, email, letter, text, fax, phone call, or voice message) about you or your activities on or through the website and/or the Clearview products or services, then Clearview may collect any personal or non-personal information provided in or with the communication. This information may be used to respond to your communication, to improve our products and services, or for other purposes as described in this Privacy Policy ​ Usage details, IP address and Cookies: When a user logs in to our services, navigates through them and uses Clearview’s search functionality, or accesses the Clearview website, we may automatically collect certain information about usage activity. This may include the user’s IP address, browser information, location data, search history within our services, user website preferences and settings, and login history. The information does not directly identify you unless you have chosen to provide us with identifying information.\n\nPublicly available photos and information derived from them: As part of Clearview’s normal business operations, it collects photos that are publicly available on the internet. The photos may contain metadata which may be collected by Clearview due to it being contained in the photos, and information derived from the facial appearance of individuals in the photos.\n\nInformation provided by individuals: When an individual submits a request to exercise a right identified in this Policy, in order to fulfill the individual’s request, we may collect that individual’s email address, contact information, photo, an image of the requester’s government-issued ID, or other information required by applicable law to process such request. ​ ​ ​ Why Do We Collect Data? ​ ​We collect data in order to provide you with our Products and Services. ​ ​ ​ Clearview collects the name, contact information and employer of our users so that we can: ​ Provide a user login ID and password\n\nVerify that users are law enforcement, defense and security professionals\n\nProvide customer service support Opting In to SMS Communications - When collecting personal information from users, including their phone numbers, Clearview may request user consent to use these phone numbers for the purpose of sending SMS messages. By providing a phone number and opting in to SMS messaging, users consent to be contacted via SMS for customer support purposes and agree to any applicable charges from their mobile service provider. ​ In some cases, Clearview may engage third-party service providers to facilitate SMS communications. These service providers may have access to user phone numbers solely for the purpose of delivering SMS messages on behalf of Clearview. Clearview ensures that these service providers adhere to strict confidentiality and data protection standards to safeguard user information. Opting Out of SMS Communications - Clearview understands and respects the users' preferences regarding SMS communications. If at any time a user no longer wishes to receive SMS notifications, they can opt out by following the instructions provided in the SMS message or by contacting Clearview's Customer Support. Upon opting out, the user will no longer receive SMS messages for customer support purposes. However, it's important to note that communications for two-factor authentication may still be delivered via text message and other channels, such as email or phone calls, to ensure continued access to the products and services . ​ ​ ​Clearview collects the name and contact information of our business contacts so that we can: Enter into contracts for certain services with our service providers, processors, or contractors\n\nCommunicate with these contacts for services and fulfill the terms of our agreements ​ ​ Clearview collects the usage details, IP addresses, and cookies of our users so that we can: ​​ Ensure compliance with the Clearview User Code of Conduct and Terms of Service\n\nSecure our services and user accounts\n\nImprove our Products, Services and the performance and functionality of our website\n\nProtect our Products and Services and prevent fraud\n\nRemember your preferences and settings\n\nUnderstand how you use our Platform and to improve our services\n\nAllow you to log into your individual account. Clearview collects publicly available photos and information derived from them to: ​ Provide our Products and Services\n\nImprove our Products and Services ​ We do not use cookies for tracking or to target advertising to you. When you visit our website, it may store or retrieve information on your browser, mostly in the form of cookies. This information can be about your preferences, your type of device, or activity on the site and is used to make the website work as you expect it to, as well as to help us operate our business. The information does not directly identify you unless you have chosen to provide us with identifying information. Enabling cookies can give you a more personalized experience on our website. You can choose not to allow some types of cookies. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer. If you want to disable cookies on our site, you can do so through our Cookie Manager located at the bottom of our website. Clearview collects information from individuals seeking to exercise a privacy right in order to verify the identity of the individual making the request and to fulfill the request. ​ ​ ​ ​ ​ Who Do We Disclose Data To? ​ Users of Clearview AI: The publicly available images collected by Clearview are disclosed, along with the source of the image, in a searchable format with our users, who are all either law enforcement, government agency, national security professionals, or a contractor authorized to work on behalf of and fulfill a duty on behalf of the foregoing entities. Unless a user provides or requests written consent to disclose their personal information with other users, personal information derived from users is not disclosed by Clearview with its other users except as required by a legal mandate such as a judicial order.\n\n​\n\nLegal: The law may require or permit us to use or disclose the information we collect with other parties in response to legal proceedings, in response to a request from a competent law enforcement or government agency, to protect our rights, privacy, safety or property, or the public, to enforce the terms of any agreement, or for any other purpose that is required or permitted by law. Fraud Detection: We may use or disclose the information we collect in order to investigate, prevent, or take action regarding illegal activities, suspected fraud, cybersecurity threats, situations involving potential threats to the physical safety of any person, violations of this policy, or as otherwise required by law.​ Compliance with Clearview Policies: We may use or disclose the information we collect in order to ensure that our users are complying with all applicable aspects of our policies.​ Mergers and Acquisitions: In the event that Clearview or its assets may be or are acquired by, or merged with, another organization or company including through bankruptcy, we may use or disclose the information we collect with any of our legal successors. Lawyers and Advisors: We may disclose information with our lawyers and other professional advisors where necessary to obtain legal or other advice or otherwise protect and manage our business interests. Service Providers and Others: Clearview shares information with vendors, service providers, independent contractors, processors, and consultants that need access to information to perform services for us, such as companies that assist us with cloud storage, data collection, customer service and support, marketing, software, payment, and other technology services. We require service providers, processors, and contractors to limit the purposes for which they process data on our behalf to only those purposes authorized by Clearview and in accordance with applicable law. Your Consent: We may disclose information that you have provided us, except when another lawful ground for doing so is present, such as a legal, regulatory or other compliance obligations.\n\n‍ ​ Retention of Personal Information ​ We store personal information for as long as necessary to carry out the purposes for which we originally collected it and for other legitimate business purposes, including to meet our legal, regulatory, or other compliance obligations.\n\nFor more information about how we handle information under Illinois Biometric Information Privacy Act, please click here. ​ ​\n\nSummary of Our Prior 12-Month Personal Information Handling Practices\n\nCATEGORY OF PERSONAL INFORMATION SOURCES BUSINESS OR COMMERCIAL PURPOSE OF PROCESSING AND DISCLOSURE AND RECIPIENTS OF PERSONAL INFORMATION\n\nIdentifiers, such as your real name, alias, postal address, unique personal identifier, online identifier, Internet Protocol address, email address, account name, or other similar identifiers. From our website users, customers, business contacts, vendors, employees, contractors, and others with whom we collect personal information from in the course of our contact with that individual\n\nNote: we do not collect such personal information from the general public unless such information is voluntarily shared from the user. SOLD\n\nWe have not sold this category of personal information.\n\nSHARE\n\nWe have not shared this category of personal information for cross-context behavioral advertising.\n\nSERVICE PROVIDERS, CONTRACTORS OR PROCESSORS\n\nWe may have disclosed this category of personal information with service providers, contractors or processors who provide us with certain services, such as cloud storage, data collection, customer service and support, marketing, software, payment, and other technology services.\n\nPURPOSE OF PROCESSING\n\nWe process this personal information to provide our services, for business-to-business purposes, and for security and fraud prevention. For more details regarding our use and disclosure of this category of personal information, please see Why Do We Collect Data? and Who Do We Disclose Data To? sections above.\n\nFace vectors and photos, and such metadata as image files may contain (sensitive personal information). From the Internet SOLD\n\nWe may have sold this category of personal information to law enforcement, governmental agencies, authorized contractors of law enforcement or government agencies, security and national security professionals. Please note: Clearview does not provide any third party with access to face vectors Clearview produces.\n\nSHARE\n\nWe have not shared this category of personal information for cross-context behavioral advertising.\n\nSERVICE PROVIDERS, CONTRACTORS OR PROCESSORS\n\nWe may have disclosed this category of personal information with service providers, contractors or processors who provide us with certain services, such as cloud storage and other technology services.\n\nPURPOSE OF PROCESSING\n\nWe process this personal information to provide and improve our services to customers and to cooperate with our customers’ investigation, research, or fulfillment of their government duties concerning conduct or activity that the Customer or Clearview reasonably and in good faith believes may violate federal, state, or local laws, rules, or regulations. For more details regarding our use and disclosure of this category of personal information, please see Why Do We Collect Data? and Who Do We Disclose Data To? sections above.\n\nGovernment-Issued Identification, such as driver’s license, state identification card or passport (sensitive personal information) You SOLD\n\nWe have not sold this category of personal information.\n\nSHARE\n\nWe have not shared this category of personal information for cross-context behavioral advertising.\n\nSERVICE PROVIDERS, CONTRACTORS OR PROCESSORS\n\nWe may have disclosed this category of personal information with service providers, contractors or processors who provide us with certain services, such as cloud storage and other technology services.\n\nPURPOSE OF PROCESSING\n\nWe process this personal information to handle your privacy rights request. For more details regarding our use and disclosure of this category of personal information, please see Why Do We Collect Data? and Who Do We Disclose Data To? sections above.\n\nAccount Login Information (sensitive personal information) You SOLD\n\nWe have not sold this category of personal information.\n\nSHARE\n\nWe have not shared this category of personal information for cross-context behavioral advertising.\n\nSERVICE PROVIDERS, CONTRACTORS OR PROCESSORS\n\nWe may have disclosed this category of personal information with service providers, contractors or processors who provide us with certain services, such as cloud storage and other technology services.\n\nPURPOSE OF PROCESSING\n\nWe process this personal information to provide our services to customers and for security purposes. For more details regarding our use and disclosure of this category of personal information, please see Why Do We Collect Data? and Who Do We Disclose Data To? sections above.\n\nInternet or other electronic network activity information. You SOLD\n\nWe have not sold this category of personal information.\n\nSHARE\n\nWe have not shared this category of personal information for cross-context behavioral advertising.\n\nSERVICE PROVIDERS, CONTRACTORS OR PROCESSORS\n\nWe may have disclosed this category of personal information with service providers, contractors or processors who provide us with certain services, such as cloud storage, data collection, customer service and support, marketing, software, payment, and other technology services.\n\nPURPOSE OF PROCESSING\n\nWe process this personal information to provide our services and for security and fraud prevention. For more details regarding our use and disclosure of this category of personal information, please see Why Do We Collect Data? and Who Do We Disclose Data To? sections above.\n\nWhat Are Cookies And How Do We Use Cookies? A cookie is a small piece of data that is stored on your computer or device when you visit a website. It is used to remember information about your visit, such as your browsing history, login details, and preferences. When you visit our website, Clearview’s website server may send a cookie to your computer or device, which is then stored in your web browser. The next time you visit the same website, your browser sends the cookie back to the server, allowing the website to recognize you and customize your experience based on your previous activity. Enabling cookies can give you a more personalized experience on our website. You can choose not to allow some types of cookies. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer. If you want to disable cookies on our site, you can do so through our Cookie Manager located at the bottom of our website. We use three types of cookies: essential performance cookies, functional cookies, and performance cookies. Essential performance cookies are necessary for the basic functioning of our website and Platform. Functional cookies are used to personalize your experience and to remember your preferences and settings. Performance cookies are used to collect information about how you use our website. These cookies do not collect personal information, but they do collect information such as which pages you visit and how long you spend on each page. We use this information to improve the performance of our Platform and to understand how users interact with it.\n\nFor further information, visit allaboutcookies.org.\n\nLinking To External Websites\n\nOur Products and Services may provide links to other websites. We do not control, and are not responsible for, the content or practices of these other websites. Our provision of such links does not constitute our endorsement of these other websites, their content, their owners, or their practices. This Policy does not apply to these other websites, which are subject to any privacy and other policies they may have.\n\n​\n\nCopyright Protections\n\nIt is Clearview's policy to comply with notices of copyright infringement pursuant to the Digital Millennium Copyright Act (DMCA). Persons who seek to file a DMCA takedown notice can do so by clicking here.\n\n‍\n\nUpdates To This Policy\n\nWe may modify this Policy at any time at our sole discretion. If we make material changes to this Policy that change our rights to use personal information that we have previously collected about you, we will comply with applicable law regarding the use of that personal information. Any changes to this Policy will become effective when we post the revised Policy on our website. ​ ​\n\nContact Information\n\nIf you have any questions, you can contact us by emailing us at privacy@clearview.ai.‍ Please do not email us requesting to process your consumer request such as opting out and access. Rather, please read below for instructions on how to fill out the applicable webform. ​\n\n​ ​ Consumer Requests & State Rights Some U.S. state laws provide residents with rights regarding their personal information. Currently, only those who are a resident of one of the following states may submit a consumer request for access, opt-out, and/or delete: California Colorado Connecticut Illinois Montana Nevada Oregon Utah Virginia ​\n\nTo request access to or deletion of your personal information, or to exercise any other data rights under these laws, please contact us using one of the following methods: Webform: You may submit your request to exercise rights by visiting the appropriate webform on our Privacy and Requests page and providing all of the verification information required, or Leave a voicemail at (866) 637-0257. All verifiable consumer requests must: ​ Provide sufficient information that allows us to reasonably verify you are the person about whom we collected personal information, or an authorized representative.\n\nFor a request by the actual person, we will typically require: (1) your email address (2) a headshot of you, and (3) a government-issued ID. If we require any additional information from you in order to verify your identity, we will contact you. Subject to applicable law, any additional information you provide for verification purposes will be deleted within a reasonable period of time after responding to your consumer request.\n\nIf we receive your request from an authorized agent, we may ask for evidence that you have provided such agent with a power of attorney or that the agent otherwise has valid written authority to submit requests to exercise rights on your behalf. ​ ​​ ​​ 1. California ​ If you are a California resident, this section applies to you. This section, combined with the above, describes how we collect, use, and disclose your personal information in our capacity as a “business” under the California Consumer Privacy Act (“CCPA”) and, as amended by the California Privacy Rights Act of 2020 (together with the CCPA, “CPRA”), and the rights that you have with respect to your personal information, including sensitive personal information. For purposes of this section, “personal information” and “sensitive personal information” have the meanings given in the CPRA and do not include information excluded from the CPRA’s scope. Clearview does not sell your personal information, as that term is traditionally understood. However, Clearview’s disclosure of photos collected from the Internet is deemed a “sale” under the CPRA. To opt out of the sale of your personal information, please see the instructions below. Clearview does not “share” personal information with third parties for cross-context behavioral advertising. Clearview does not have actual knowledge of the age of the persons in the photos it collects from the Internet. As such, Clearview does not knowingly sell or share personal information about consumers under the age of 16. California’s Shine the Light law, California Civil Code § 1798.83, permits California residents to request and obtain from us, once a year and free of charge, information about categories of personal information (if any) we disclosed to third parties for direct marketing purposes and the names and addresses of all third parties with which we disclosed personal information in the immediately preceding calendar year. Please note that Clearview does not currently disclose your personal information to any third parties for marketing purposes. However, if you are a California resident and have any questions, please contact us by emailing privacy@clearview.ai. “Do Not Track.” Please note that we do not respond to Do Not Track requests. However, we do honor opt-out of sale requests, as noted below.​ Under the California Privacy Rights Act of 2020 (“CPRA”), California Civil Code § 1798.100, et seq., California residents have additional privacy rights, which you can learn more about by visiting our California Privacy section, which is located here under “State-Specific Information and Rights”. ​ ​ CPRA​ We provide in the chart above a summary of our prior 12-month personal information handling practices. You can learn more about the information we collect at or before the point of collection in our general Privacy Policy section. ​ ​ Consumer Rights If you are a California resident, you may exercise the rights below, subject to some exceptions. ​ ​ Your Right to Know and Access Personal Information You have the right to know and access the personal information we have collected about you, including the categories of personal information, the categories of sources from which the personal information is collected, the business or commercial purpose for collecting, selling, or sharing personal information, the categories of third parties to whom we disclose personal information, and the specific pieces of personal information we have collected about you. ​ You may submit a verifiable consumer request up to two (2) times in a twelve (12)-month period for access to your personal information. When you submit an access request, you can request that we deliver the information to you by mail or electronically. If you elect to receive the information electronically, to the extent it is technically feasible for us to do so, we will provide the requested information in a portable and readily usable format. ​ ​ Your Right to Request Deletion If you want us to delete the personal information we have collected from you, you can send us a verifiable consumer request requesting that we delete some or all of the information we have collected from you, subject to certain exceptions. Once we receive and confirm your request, we will delete your personal information in our active records, unless an exception applies. We will also notify our service providers, contractors or third parties regarding your deletion request to the extent this is necessary to accomplish your request.. In the event that we deny your request to delete based on an exception or another ground under the CPRA, we will inform you, in writing, of the reason. ​ ​ Your Right to Correct You have the right to request us to correct inaccurate personal information we maintain about you. ​ How You Can Submit a Verifiable Consumer Request to Know and Access, Delete and Correct In order for us to process a request for a right to know and access, delete or correct made pursuant to the CPRA, it is necessary for us to verify your identity. We cannot fulfill your request if we cannot verify your identity. ​ We will acknowledge receipt of a consumer request to know and access, delete, or correct within ten (10) business days of receipt. However, it may take up to forty-five (45) calendar days to fulfill your request, or up to a total of ninety (90) calendar days if additional time is needed. In the event that we cannot complete your request within the initial forty-five (45) calendar day period, we will notify you in writing within the initial forty-five (45) calendar day period. ​ To request to exercise one or more of your CPRA rights, please submit a verifiable consumer request by Visiting the appropriate webform here and providing all of the verification information set forth below; or\n\nYou can call our toll-free number 1(866) 637-0257 and follow our instructions. Only you or a person that you authorize to act on your behalf may submit a Personal Information request. You may also make a personal information request on behalf of your minor child. However, please note that we do not knowingly process children’s information, as mentioned above.\n\n​\n\nAll verifiable consumer requests must: Provide sufficient information that allows us to reasonably verify you are the person about whom we collected personal information, or an authorized representative.\n\nFor a request by the actual person, we will typically require: (1) your email address (2) a headshot of you, and (3) a government-issued ID. If we require any additional information from you in order to verify your identity, we will contact you. Subject to applicable law, any additional information you provide for verification purposes will be deleted within a reasonable period of time after responding to your consumer request.\n\nIf we receive your request from an authorized agent, we may ask for evidence that you have provided such agent with a power of attorney or that the agent otherwise has valid written authority to submit requests to exercise rights on your behalf. ​ ​ Your Right to Opt-Out of the Sale of Personal Information You may submit a request for opt-out of appearance in Clearview search results using this webform or by calling our toll-free number 1(866) 637-0257 and following our instructions. We will honor your request within fifteen (15) business days. ​ Please note that we do not “share” personal information with third parties for cross-context behavioral advertising. As such, we do not offer an opt-out right related to sharing. ​ ​ Your Right to Non-Discrimination ​ The CPRA prohibits businesses from discriminating against California consumers for exercising any of their rights under the CPRA. This includes us not: (a) denying you goods or services; (b) charging you different prices or rates for goods or services, including through the use of discounts or other benefits or imposing penalties; (c) providing you a different level or quality of goods or services; (d) suggesting to you that you will receive a different price or rate for goods or services or a different level or quality of goods or services; and (e) retaliating against you for exercising your privacy rights. ​ Your Right to Limit the Use and Disclosure of Your Sensitive Personal Information Under the CPRA, certain types of personal information are considered “sensitive” personal information and require additional data privacy rights and obligations. Clearview collects driver’s license, state identification card and passport (“ID Information”), account login information, and face vectors and photos, and such metadata as image files may contain (“Face Vector Data”), which may be deemed sensitive personal information under the CPRA. You may limit any use and disclosure of your Face Vector Data by submitting a photo of yourself along with California resident proof (i.e., government-issued documentation). We will honor your request within fifteen (15) business days. Please note that we will only use ID Information to honor your privacy rights request and your account login information to provide you our services. We also only use these types of sensitive personal information for other limited purposes permitted under the CPRA for sensitive data. As such, there is no need to exercise a right to limit use and disclosure of ID Information and account login information, as we do not use it for any purposes beyond that permitted for sensitive personal information under the CPRA. ​ ​ 2023 Reporting Metrics California Consumer Privacy Act (CCPA) Reporting Metrics Between January 1, 2023 and December 31, 2023 Clearview received 2,330 requests under the CCPA from both California and non-California residents. The below metrics describe how we handle these requests.\n\n2. Colorado ​ If you are a Colorado resident, this section applies to you. This section, combined with the general Privacy Policy above, describes how we collect, use, and disclose your personal data under the Colorado Privacy Act (“CPA”), and the rights that you have with respect to your personal data, including sensitive data. Your Colorado Rights Regarding Your Personal Data. Colorado law provides Colorado residents with the rights listed below. To exercise these rights see the “Exercising Your Colorado Privacy Rights” section below. Right to Know and Access. You have the right to know and see what personal data we have collected about you in a portable format. You may submit a verifiable consumer request up to two (2) times in a twelve (12)-month period for access to your personal data. Right to Correct. You have the right to request that we correct inaccurate personal data. Right to Delete. You have the right to request that we delete the personal data we have collected about you. Right to Opt Out. You have the right to opt out of targeted advertising, sale of your personal data (as defined under Colorado law), the collection and use of personal data, and profiling in furtherance of decisions that produce legal or similarly significant effects concerning a consumer. Please note that we do not use your personal data for targeted advertising. As such, we do not offer an opt-out of targeted advertising rights. Exercising Your Colorado Privacy Rights. To request access to or deletion of your personal data, or to exercise any other privacy rights under Colorado law, please contact us using one of the following methods: Webform: You may submit your request to exercise rights by visiting the appropriate webform on our Privacy and Requests page and providing all of the verification information required, or Leave a voicemail at (866) 637-0257. All verifiable consumer requests must: ​ Provide sufficient information that allows us to reasonably verify you are the person about whom we collected personal information, or an authorized representative.\n\nFor a request by the actual person, we will typically require: (1) your email address (2) a headshot of you, and (3) a government-issued ID. If we require any additional information from you in order to verify your identity, we will contact you. Subject to applicable law, any additional information you provide for verification purposes will be deleted within a reasonable period of time after responding to your consumer request.\n\nIf we receive your request from an authorized agent, we may ask for evidence that you have provided such agent with a power of attorney or that the agent otherwise has valid written authority to submit requests to exercise rights on your behalf.\n\nTo respond to some rights we may need to authenticate you by providing additional information. Authorized agents can make a request on your behalf if you have given them legal power of attorney or we are provided proof of signed permission, verification of your identity, and, in some cases, confirmation that you provided the agent permission to submit the request. How to Appeal a Denied Request. If you submitted a verifiable consumer request and we have denied your request, you have the right to appeal. To appeal a denied request, please indicate so on the webform here. If your appeal is denied, you may contact the Colorado Attorney General to submit a complaint here. ​​ ​​ 3. Connecticut ​ If you are a Connecticut resident, this section applies to you. This section, combined with the general Privacy Policy above, describes how we collect, use, and disclose your personal data under the Connecticut Act Concerning Personal Data Privacy and Online Monitoring (“CTDPA”), and the rights that you have with respect to your personal data, including sensitive data. Your Connecticut Rights Regarding Your Personal Data. Connecticut law provides Connecticut residents with the rights listed below. To exercise these rights see the “Exercising Your Connecticut Privacy Rights” section below. Right to Know and Access. You have the right to know and see what personal data we have collected about you in a portable format. You may submit a verifiable consumer request once (1) in a twelve (12)-month period for access to your personal data. Right to Correct. You have the right to request that we correct inaccurate personal data. Right to Delete. You have the right to request that we delete the personal data we have collected about you. Right to Opt Out. You have the right to opt out of targeted advertising, sale of your personal data (as defined under Connecticut law), the collection and use of personal data, and profiling in furtherance of decisions that produce legal or similarly significant effects concerning a consumer. Please note that we do not use your personal data for targeted advertising. As such, we do not offer an opt-out of targeted advertising rights. Exercising Your Connecticut Privacy Rights. To request access to or deletion of your personal data, or to exercise any other privacy rights under Colorado law, please contact us using one of the following methods: Webform: You may submit your request to exercise rights by visiting the appropriate webform on our Privacy and Requests page and providing all of the verification information required, or Leave a voicemail at (866) 637-0257. All verifiable consumer requests must: ​ Provide sufficient information that allows us to reasonably verify you are the person about whom we collected personal information, or an authorized representative.\n\nFor a request by the actual person, we will typically require: (1) your email address (2) a headshot of you, and (3) a government-issued ID. If we require any additional information from you in order to verify your identity, we will contact you. Subject to applicable law, any additional information you provide for verification purposes will be deleted within a reasonable period of time after responding to your consumer request.\n\nIf we receive your request from an authorized agent, we may ask for evidence that you have provided such agent with a power of attorney or that the agent otherwise has valid written authority to submit requests to exercise rights on your behalf. To respond to some rights we may need to verify your request either by asking you to log in and authenticate your account or otherwise verify your identity by providing information about yourself or your account. Authorized agents can make a request on your behalf if you have given them legal power of attorney or we are provided proof of signed permission, verification of your identity, and, in some cases, confirmation that you provided the agent permission to submit the request. How to Appeal a Denied Request. If you submitted a verifiable consumer request and we have denied your request, you have the right to appeal. To appeal a denied request, please indicate so on the webform here. If your appeal is denied, you may contact the Connecticut Attorney General to submit a complaint here. ​ ​​ ​​ 4. Illinois ​ Illinois residents can go here to opt-out of appearing in Clearview search results. You can read our Biometric Information Privacy statement here. ​​ ​​​ ​​ 5. Montana ​ If you are a Montana resident, this section applies to you. This section, combined with the general Privacy Policy above, describes how we collect, use, and disclose your personal data under the Montana Consumer Data Privacy Act (“MTCDPA”), and the rights that you have with respect to your personal data, including sensitive data. Your Montana Rights Regarding Your Personal Data. Montana law provides Montana residents with the rights listed below. To exercise these rights see the “Exercising Your Montana Privacy Rights” section below. Right to Know and Access. You have the right to know and see what personal data we have collected about you in a portable format. You may submit a verifiable consumer request up to one (1) time in a twelve (12)-month period for access to your personal data. Right to Correct. You have the right to request that we correct inaccurate personal data. Right to Delete. You have the right to request that we delete the personal data we have collected about you. Right to Opt Out. You have the right to opt out of targeted advertising, sale of your personal data (as defined under Montana law), the collection and use of personal data, and profiling in furtherance of decisions that produce legal or similarly significant effects concerning a consumer. Please note that we do not use your personal data for targeted advertising. As such, we do not offer an opt-out of targeted advertising rights. Exercising Your Montana Privacy Rights. To request access to or deletion of your personal data, or to exercise any other privacy rights under Montana law, please contact us using one of the following methods: ​ 1. Webform: You may submit your request to exercise rights by visiting the appropriate webform on our Privacy and Requests page and providing all of the verification information required,\n\n2. Leave a voicemail at (866) 637-0257, or\n\n3. Email us at privacy@clearview.ai ​ All verifiable consumer requests must:\n\n​ Provide sufficient information that allows us to reasonably verify you are the person about whom we collected personal information, or an authorized representative.\n\nFor a request by the actual person, we will typically require: (1) your email address (2) a headshot of you, and (3) a government-issued ID. If we require any additional information from you in order to verify your identity, we will contact you. Subject to applicable law, any additional information you provide for verification purposes will be deleted within a reasonable period of time after responding to your consumer request.\n\nIf we receive your request from an authorized agent, we may ask for evidence that you have provided such agent with a power of attorney or that the agent otherwise has valid written authority to submit requests to exercise rights on your behalf. To respond to some rights we may need to authenticate you by providing additional information. Authorized agents can make a request on your behalf if you have given them legal power of attorney or we are provided proof of signed permission, verification of your identity, and, in some cases, confirmation that you provided the agent permission to submit the request. How to Appeal a Denied Request. If you submitted a verifiable consumer request and we have denied your request, you have the right to appeal. To appeal a denied request, please indicate so on the webform here. If your appeal is denied, you may contact the Montana Attorney General to submit a complaint here.​​ ​​ 6. Nevada ​ ​ ​ We do not presently sell any covered information of consumers, as defined by Nevada law, to any third parties for monetary consideration. If we were to do so in the future, we will update this Policy, and provide Nevada residents with the opportunity to opt-out of the sale of their covered information. ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ 7. Oregon ​ ​ If you are an Oregon resident, this section applies to you. This section, combined with the general Privacy Policy above, describes how we collect, use, and disclose your personal data under the Oregon Consumer Privacy Act (“OCPA”), and the rights that you have with respect to your personal data, including sensitive data. Your Oregon Rights Regarding Your Personal Data. Oregon law provides Oregon residents with the rights listed below. To exercise these rights see the “Exercising Your Oregon Privacy Rights” section below. Right to Know and Access. You have the right to know and see what personal data we have collected about you in a portable format. You may submit a verifiable consumer once in a twelve (12)-month period for access to your personal data. Right to Correct. You have the right to request that we correct inaccurate personal data. Right to Delete. You have the right to request that we delete the personal data we have collected about you. Right to Opt Out. You have the right to opt out of targeted advertising, sale of your personal data (as defined under Oregon law), the collection and use of personal data, and profiling in furtherance of decisions that produce legal effects or effects of similar significance Please note that we do not use your personal data for targeted advertising. As such, we do not offer an opt-out of targeted advertising rights. Exercising Your Oregon Privacy Rights. To request access to or deletion of your personal data, or to exercise any other privacy rights under Oregon law, please contact us using one of the following methods: Webform: You may submit your request to exercise rights by visiting the appropriate webform on our Privacy and Requests page and providing all of the verification information required, or Leave a voicemail at (866) 637-0257. All verifiable consumer requests must: ​ Provide sufficient information that allows us to reasonably verify you are the person about whom we collected personal information, or an authorized representative.\n\nFor a request by the actual person, we will typically require: (1) your email address (2) a headshot of you, and (3) a government-issued ID. If we require any additional information from you in order to verify your identity, we will contact you. Subject to applicable law, any additional information you provide for verification purposes will be deleted within a reasonable period of time after responding to your consumer request.\n\nIf we receive your request from an authorized agent, we may ask for evidence that you have provided such agent with a power of attorney or that the agent otherwise has valid written authority to submit requests to exercise rights on your behalf. ​ To respond to some rights we may need to authenticate you by providing additional information. Authorized agents can make a request on your behalf if you have given them legal power of attorney or we are provided proof of signed permission, verification of your identity, and, in some cases, confirmation that you provided the agent permission to submit the request. How to Appeal a Denied Request. If you submitted a verifiable consumer request and we have denied your request, you have the right to appeal. To appeal a denied request, please indicate so on the webform here. If your appeal is denied, you may contact the Oregon Attorney General to submit a complaint here. ​​ ​ ​​ 8. Utah ​ ​ If you are a Utah resident, this section applies to you. This section, combined with the general Privacy Policy above, describes how we collect, use, and disclose your personal data under the Utah Consumer Privacy Act (“UCPA”), and the rights that you have with respect to your personal data, including sensitive data. Your Utah Rights Regarding Your Personal Data. Utah law provides Utah residents with the rights listed below. To exercise these rights see the “Exercising Your Utah Privacy Rights” section below. Right to Know and Access. You have the right to know and see what personal data we have collected about you in a portable format. You may submit a verifiable consumer request up to two (2) times in a twelve (12)-month period for access to your personal data. Right to Correct. You have the right to request that we correct inaccurate personal data. Right to Delete. You have the right to request that we delete the personal data we have collected about you. Right to Opt Out. You have the right to opt out of targeted advertising, sale of your personal data (as defined under Utah law), the collection and use of personal data. Please note that we do not use your personal data for targeted advertising. As such, we do not offer an opt-out of targeted advertising rights. Exercising Your Utah Privacy Rights. To request access to or deletion of your personal data, or to exercise any other privacy rights under Utah law, please contact us using one of the following methods: Webform: You may submit your request to exercise rights by visiting the appropriate webform on our Privacy and Requests page and providing all of the verification information required, or Leave a voicemail at (866) 637-0257. All verifiable consumer requests must: ​ Provide sufficient information that allows us to reasonably verify you are the person about whom we collected personal information, or an authorized representative.\n\nFor a request by the actual person, we will typically require: (1) your email address (2) a headshot of you, and (3) a government-issued ID. If we require any additional information from you in order to verify your identity, we will contact you. Subject to applicable law, any additional information you provide for verification purposes will be deleted within a reasonable period of time after responding to your consumer request.\n\nIf we receive your request from an authorized agent, we may ask for evidence that you have provided such agent with a power of attorney or that the agent otherwise has valid written authority to submit requests to exercise rights on your behalf. ​ To respond to some rights we may need to authenticate you by providing additional information. Authorized agents can make a request on your behalf if you have given them legal power of attorney or we are provided proof of signed permission, verification of your identity, and, in some cases, confirmation that you provided the agent permission to submit the request. ​\n\n9. Virginia ​ ​ ​ If you are a Virginia resident, this section applies to you. This section, combined with the general privacy Policy above, describes how we collect, use, and disclose your personal data under the Virginia Consumer Data Protection Act (“CDPA”), and the rights that you have with respect to your personal data, including sensitive data. Your Virginia Rights Regarding Your Personal Data. Virginia law provides Virginia residents with the rights listed below. To exercise these rights see the “Exercising your Virginia Privacy Rights” section below. Right to Confirmation of Processing and Access to Personal Data in Portable Format. You have the right to confirm whether we are processing your personal data and access such personal data in a portable format. You may submit a verifiable consumer request up to two (2) times in a twelve(12)-month period for access to your personal data. When you submit an access request, you can request that we deliver the information to you by mail or electronically. If you elect to receive the information electronically, to the extent it is technically feasible for us to do so, we will provide the requested information in a portable and readily usable format. Right to Request Deletion. If you want us to delete the personal data we have collected from you, you can send us a verifiable consumer request requesting that we delete some or all of the information we have collected from you, subject to certain exceptions. Once we receive and confirm your request, we will delete your personal data in our active records, unless an exception applies. In the event that we deny your request to delete based on an exception or another ground under the CDPA, we will inform you, in writing, of the reason. Right to Correct. You have the right to request us to correct inaccurate personal information we maintain about you. Right to Opt Out. You have the right to opt out of targeted advertising, sale of your personal data (as defined under Virginia law), the collection and use of personal data, and profiling in furtherance of decisions that produce legal or similarly significant effects concerning a consumer. Please note that we do not use your personal data for targeted advertising. As such, we do not offer an opt-out of targeted advertising rights. Right to Non-Discrimination. The CDPA prohibits businesses from discriminating against Virginia consumers for exercising any of their rights under the CDPA. This includes us not: (a) denying you goods or services; (b) charging you different prices or rates for goods or services, including through the use of discounts or other benefits or imposing penalties; (c) providing you a different level or quality of goods or services; (d) suggesting to you that you will receive a different price or rate for goods or services or a different level or quality of goods or services; and (e) retaliating against you for exercising your privacy rights. Exercising Your Virginia Privacy Rights. In order for us to process a privacy rights request made pursuant to the CDPA, it is necessary for us to verify your identity. We cannot fulfill your request if we cannot verify your identity. ​ We will respond to your privacy rights request within forty-five (45) calendar days of receipt, or up to a total of ninety (90) calendar days if additional time is needed. In the event that we cannot complete your request within the initial forty-five (45) calendar day period, we will notify you in writing within the initial forty-five (45) calendar day period. ​ To request to exercise one or more of your CDPA rights, please submit a verifiable consumer request by: ​ Visiting the appropriate webform here and providing all of the verification information set forth below; or\n\nYou can call our toll-free number 1(866) 637-0257 and follow our instructions. ​ Only you may submit a privacy rights request. You may also make a privacy rights request on behalf of your minor child. However, please note that we do not knowingly process children’s information, as mentioned above. ​ All verifiable consumer requests must: ​ Provide sufficient information that allows us to reasonably verify you are the person about whom we collected personal information, or an authorized representative.\n\nFor a request by the actual person, we will typically require: (1) your email address (2) a headshot of you, and (3) a government-issued ID. If we require any additional information from you in order to verify your identity, we will contact you. Subject to applicable law, any additional information you provide for verification purposes will be deleted within a reasonable period of time after responding to your consumer request.\n\nIf we receive your request from an authorized agent, we may ask for evidence that you have provided such agent with a power of attorney or that the agent otherwise has valid written authority to submit requests to exercise rights on your behalf. How to Appeal a Denied Request. If you submitted a verifiable consumer request and we have denied your request, you have the right to appeal. To appeal a denied request, please indicate so on the webform here. If your appeal is denied, you may contact the Virginia Attorney General to submit a complaint here.",
            "url": "https://www.clearview.ai/privacy-policy",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "policy",
                "request",
                "submit",
                "personal",
                "right",
                "information",
                "data",
                "rights",
                "privacy",
                "consumer",
                "clearview"
            ],
            "summary": "CLEARVIEW AI, INC. PRIVACY POLICY ​ This privacy policy (“Policy”) explains what kind of information Clearview AI, Inc. (“Clearview”) collects from users of all Clearview platforms, Products, Services, applications, websites, technology and other services (“Clearview Platform”), our business-to-business contacts (e.g., our service providers, contractors or processors), from others online, and how we use that data.\nAccount Login Information (sensitive personal information) You SOLDWe have not sold this category of personal information.\nThis section, combined with the general Privacy Policy above, describes how we collect, use, and disclose your personal data under the Colorado Privacy Act (“CPA”), and the rights that you have with respect to your personal data, including sensitive data.\nThis section, combined with the general Privacy Policy above, describes how we collect, use, and disclose your personal data under the Connecticut Act Concerning Personal Data Privacy and Online Monitoring (“CTDPA”), and the rights that you have with respect to your personal data, including sensitive data.\nThis section, combined with the general Privacy Policy above, describes how we collect, use, and disclose your personal data under the Montana Consumer Data Privacy Act (“MTCDPA”), and the rights that you have with respect to your personal data, including sensitive data.",
            "metadata": {
                "source_domain": "www.clearview.ai",
                "scrape_date": "2024-10-25T12:40:34.631526",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 52523
            }
        },
        {
            "title": "Clearview AI",
            "text": "OUR MISSION AI FOR PUBLIC SAFETY\n\nClearview AI’s mission is to create and deliver identification technology that helps combat crime and fraud, keep communities safe and industry and commerce secure, protect victims and promote justice.\n\n​\n\nWe aim to help protect the public through processes that are consistent with protecting fundamental freedoms and human rights. We have developed and applied best practices to all uses and every user of our identity solutions.\n\n​\n\n​\n\nWHAT DO WE DO & HOW DOES IT WORK?\n\nClearview AI acts as a search engine of publicly available images – now more than 50 billion -- to support investigative and identification processes by providing for highly accurate facial recognition across all demographic groups. Similar to other search engines, which pull and compile publicly available data from across the Internet into an easily searchable universe, Clearview AI compiles only publicly available images from across the Internet into a proprietary image database to be used in combination with Clearview AI's facial recognition technology. When a Clearview AI user uploads an image, Clearview AI’s proprietary technology processes the image and returns links to publicly available images that contain faces similar to the person pictured in the uploaded image.\n\n​\n\nClearview AI currently offers its solutions to only one category of customer – government agencies and their agents. It limits the uses of its system to agencies engaged in lawful investigative processes directed at criminal conduct, or at preventing specific, substantial, and imminent threats to people’s lives or physical safety. In each case, Clearview AI requires its government customers to make independent assessments of whether there is a match between the images retrieved by Clearview AI, and the image provided by the customer. Each decision about an identification is made by a professional working on behalf of a government agency, not by an automatic process.\n\nClearview AI’s facial recognition algorithm is designed to take into account age progression, variations in poses and positions, changes in facial hair, and many visual conditions and to perform at 99% [1] or better across all demographic groups on key tests.\n\n​\n\n​\n\nSTANDARDS & POLICIES\n\nClearview AI has developed required standards and best practices for the use of facial recognition technology which it applies to every use of its solutions. These include:\n\n​\n\nEnsuring Accuracy\n\nClearview AI only provides results for human review using the same algorithm and match threshold settings that achieved 99% or better accuracy on key tests [2]. Those results are then subject to non-automated human review and verification. In any case where an image does not reach a high level of probability of being a true positive, the image is excluded from the results and not provided to the customer for any use, except as needed to protect children from crimes by adults, as detailed in the section “Protecting Children.”\n\n​\n\nPreventing Discrimination\n\nClearview AI limits its results from its software solely to images which are retrieved using the same algorithm and match threshold settings which achieved 99% [3] or better accuracy for every demographic group on key tests, to make certain that Clearview AI’s data is provided without bias across all groups, regardless of age, gender, ethnic background, or race. While Clearview AI’s results exceed the standard of 99% [4] accuracy on key tests for some groups, it has adopted the identical requirement for accuracy for all of its results to ensure that no group is put at risk through a lesser standard for identification except as needed to protect children from crimes by adults, as detailed below in the section “Protecting Children.” In cases where the algorithm cannot identify an image that meets the same match threshold that achieved 99% [5] or better results on key tests, Clearview AI returns no results.\n\n​\n\nTesting & Validation\n\nClearview AI conducts regular testing and validation of its system through industry-standard testing by objective third parties. It used a system developed by an independent U.S. academic institution to test and validate its system to verify that it meets its promised standard for 99% [6] or better accuracy for adults across a demographically diverse test set. The initial testing and validation was followed by Clearview AI submitting its most recent image analysis algorithm to the National Institute for Standards and Technology, which also validated Clearview AI’s technology as achieving 99% or better accuracy on its test which measures facial recognition performance across demographic groups. [7]\n\n​\n\nProtecting Security\n\nClearview AI has put into place measures to guard against the risk of unauthorized access or use through a secure, cloud-based platform which houses its more than 50 billion facial images, relying on end-to-end encryption for the transmission of data, inbound and outbound, and designing systems that create a record to enable legal authorities as needed to reconstruct each use of Clearview AI’s system to help them undertake lawful investigations. Clearview AI stores all live data on servers in a secured data center with strict internal access controls. Clearview AI retains one or more independent external organizations to provide security assessments of its systems annually.\n\n​\n\nProtecting the Privacy of Data Subjects\n\nClearview AI limits the data it collects from the Internet to information that has been made available online to the general public. It requires each of its customers to adhere to all applicable data protection laws in their use of Clearview AI’s technology and its data. Clearview AI does not share client uploaded probe images with any other entity, and does not share images from the public internet with anyone other than government customers engaged in lawful investigations and public protection, except as required by law, such as providing access to data subjects to data pertaining to them, when applicable.\n\n​\n\nLimiting Uses to What’s Legal, Ethical, and in the Public Interest\n\nClearview AI licenses its technology only for limited and lawful purposes. These include helping government agencies identify criminals after a crime has taken place and providing lead information to help track down people engaged in illegal conduct such as child exploitation, terrorist activity, or to investigate other specific, substantial and imminent threats to people’s lives or physical safety. [8]\n\nProtecting Against Misidentification\n\nClearview AI’s system is hard coded to limit the return of false positives. It intentionally does not include match scoring or percentage matching with results. To limit the risk of a customer using the technology to identify the wrong person, Clearview AI’s system will return no results if the search falls below the 99% [9] threshold for accuracy, except as needed to protect children from crimes by adults, as detailed below in the section “Protecting Children.” Clearview AI requires that any possible match generated by the Clearview AI system be reviewed and assessed by a trained law enforcement agent to verify and validate the possible match, so that no identification of any person is based solely on automated results. Clearview AI also tests its system to detect and counter the risk of algorithmic biases with respect to race, gender, and age.\n\n​\n\nPreventing Abuse\n\nClearview AI imposes strict conditions on the use of its technology to limit its use to purposes that are both lawful and authorized. Clearview AI’s image database is cloud based, enabling it to halt the use of its technology by any customer who violates their obligations to use Clearview AI only for lawful and authorized purposes. Clearview AI will shut down the use of its technology by any customer, anywhere, as appropriate to investigate and to stop any abuse that may be identified, when Clearview AI is aware of such abuse.\n\n​\n\nEnsuring Accountability\n\nEvery use of Clearview AI enables the production of a unique, finished report, that contains all of the information used by its customer for an identification, as well as applicable metadata [10]. It also stores a search history containing the probe image, the purpose of the search and the identity of the searching user. Clearview AI thereby assures that this stored information can be made available by its customers to legal and judicial authorities, those charged with oversight to provide for accountability, and/or data subjects, as authorized by applicable law.\n\n​\n\nProtecting Human Rights\n\nFor every law enforcement use, Clearview AI has designed its system to require a lawful predicate. For example, a law enforcement agency must identify the specific category of crime under investigation after a crime has taken place prior to enabling a search of its database, or similar specified authority, such as an identification of a missing person. These controls make Clearview AI’s system for law enforcement generally usable only for post-event law enforcement. Clearview AI authorizes limited additional uses of its technology for governments to enable it to assist them in preventing specific, substantial and imminent threats to people’s lives or physical safety.\n\n​\n\nPROCEDURES TO PROTECT DATA SUBJECTS\n\nClearview AI requires all of its users to have in place processes and procedures to protect data subjects, so that its technology is only used for lawful and proper purposes consistent with the public good, and is not abused to threaten civil rights, civil liberties, and personal privacy. These procedures include:\n\n​\n\nProviding a Specific, Lawful Basis For Each Search Undertaken Using Clearview AI’s System\n\nIn the case of law enforcement investigations after a crime has taken place, Clearview AI requires the law enforcement agency to specify the particular crime(s) that are being investigated. In the case of specific, substantial and imminent threats to the public, Clearview AI requires the government agency to specify the lawful basis of the search and the reason immediate identification is needed to assist a person in carrying out lawful duties.\n\nRequiring the Preservation of Data & Metadata\n\nTo protect the rights of each person who is identified through a process that makes use of Clearview AI’s System, Clearview AI has developed a system to ensure that every search is documented to maintain the integrity of the search and the ability to assess that it was done properly and lawfully. Clearview AI preserves and reports the metadata accompanying every search, which provides the date of the search, the nature of the information used to initiate the search (such as an image or other information in the possession of the law enforcement agency), and other information helpful to ensuring the integrity of the search process and its lawfulness.\n\nRequiring Specialized Training to be Provided for All Users Authorized to Access Clearview AI’s System\n\nClearview AI does not make decisions that an image of a face is a particular person. It provides the results of a search of its database based on an image provided to Clearview AI by a law enforcement agency, and returns images which are produced using the same algorithm and match threshold which have achieved performance of 99% accuracy [11] or better on key tests. As part of the onboarding process, the law enforcement agency is required to have any personnel and agents who will be using Clearview AI’s technology and images participate in training programs before they are authorized to use the facial recognition system. In any use of Clearview AI’s system and database, a law enforcement agent must review the images and any relevant information in the possession of the government agency to determine whether there is a match, and to decide whether to undertake further investigative steps. Proposed matches must then go through a peer review process, so that a decision on whether there is an apparent match is subject to a further check by one or more persons in addition to the original agent. All of these steps are designed to protect the rights of the data subject, and to reduce the risk of mistakes.\n\nProhibiting Purely Automated Matching, Requiring Investigative Process for Each Match\n\nClearview AI does not license its system to law enforcement for purely automated matching. It requires that there always be a person exercising judgment before a match can be declared. Facial examiner training includes training in facial recognition system functions, interpreting results, best practices on public safety use of facial recognition technology, how to assess image quality and suitability for face recognition searches, proper and improper uses of image enhancement tools for image pre-processing, procedures and criteria for face image comparisons, candidate image comparison, annotation, background verification processes, and related processes and procedures, to promote accuracy and accountability.\n\n​\n\n​\n\nTESTING & VALIDATION\n\nClearview AI undertakes regular internal testing and validation of its system to ensure that its algorithm meets or exceeds the 99% [12] or better requirement for accuracy for all demographics when tested. Clearview AI’s technology currently meets this standard for all groups, regardless of age, gender, ethnic background, or race, for all persons 16 years or older.\n\n​\n\nIn the National Institute of Standards and Technology (NIST) 1:1 Face Recognition Vendor Test (\"FRVT\") that evaluates demographic accuracy, published on December 16th 2021, Clearview AI’s algorithm consistently achieved greater than 99 percent accuracy across all demographics.\n\nIn the National Institute of Standards and Technology (NIST) 1:N Face Recognition Vendor Test (\"FRVT\"), published on December 16th 2021, Clearview AI's algorithm correctly matched the correct face out of a lineup of 12 million photos at an accuracy rate of 99.85 percent, which is much more accurate than the human eye.\n\n​\n\nEstablished by Congress in 1901, the National Institute of Standards and Technology, a division of the U.S. Department of Commerce, provides the marketplace with accurate and reliable information about companies’ measurable industrial and technology performance capabilities.\n\nPROTECTING FUNDAMENTAL FREEDOMS\n\nClearview AI is committed to ensuring that its facial recognition system is used for the public good. Its proper uses include helping bring criminals to justice, stopping terrorists and child abusers from ongoing criminal conduct and protecting public safety while minimizing risks to individual privacy, civil rights, civil liberties, and other legally protected interests.\n\n​\n\nClearview AI’s general standards and the policies and the procedures it has put into place to protect data subjects are all intended to fulfill that commitment.\n\nIn every license, Clearview AI requires its government customers to limit their uses of Clearview AI technology to those that are consistent with rule of law and civil rights.\n\nOther requirements Clearview AI has put in place to protect human rights and fundamental freedoms include Clearview AI refusing to authorize the use of its technology to enable real-time use to enable government surveillance of any population or subgroup.\n\nClearview AI will suspend any customer from access to its technology, when it has concrete indicators of a potential abuse of its system. Clearview AI will undertake an investigation of any such indicator, and take appropriate action, including putting into place further restrictions on use, or terminating a customer to counter the risk of abuse.\n\n​\n\nPROTECTING CHILDREN\n\nChildren represent a special, and challenging, class for facial recognition purposes. Due to the facial changes that take place as a person matures, images of children are harder to identify with certainty as they age than are images of people who are 16 or older. Clearview AI also recognizes that privacy issues involving children are especially sensitive. Facial recognition technology should only be enabled for uses that protect children and never for any purpose that could harm any child.\n\n​\n\nClearview AI’s technology is a tool of unprecedented power in the fight against child sexual exploitation. Protecting children also means empowering law enforcement to deliver justice to victims and stem the torrent of online sexual abuse material.\n\n​\n\nAccordingly, Clearview AI’s technology is authorized only for use of images of persons under the age of 16 for the purposes of protecting the child's safety, victim identification, when the child’s welfare is at risk, in connection with investigations of violent felonies, and to help protect against the spread of CSAM, where legally authorized.\n\n​\n\nENSURING LEGALITY\n\nClearview AI only licenses its technology for use in jurisdictions where such use is lawful.\n\nClearview AI has designed its system to help achieve important public interests. The company adheres to applicable legal requirements in every aspect of its technology, from its acquisition and maintenance of images to its licensing of access to those images for facial identification for approved customers.\n\n​\n\nClearview AI’s technology is designed to be used in a responsible and proportionate manner, as well as to be consistent with all applicable laws. Clearview AI’s systems have controls built-in that are intended to reduce the risk of abuse of its technologies, and to enable the company to terminate any user who engages in an improper or otherwise unauthorized use of Clearview AI.",
            "url": "https://www.clearview.ai/principles#:~:text=Clearview%20AI%20does%20not%20share,data%20subjects%20to%20data%20pertaining",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "ais",
                "image",
                "facial",
                "data",
                "ai",
                "system",
                "clearview",
                "images",
                "search",
                "technology"
            ],
            "summary": "When a Clearview AI user uploads an image, Clearview AI’s proprietary technology processes the image and returns links to publicly available images that contain faces similar to the person pictured in the uploaded image.\nIn each case, Clearview AI requires its government customers to make independent assessments of whether there is a match between the images retrieved by Clearview AI, and the image provided by the customer.\nClearview AI will shut down the use of its technology by any customer, anywhere, as appropriate to investigate and to stop any abuse that may be identified, when Clearview AI is aware of such abuse.\nIn every license, Clearview AI requires its government customers to limit their uses of Clearview AI technology to those that are consistent with rule of law and civil rights.\nOther requirements Clearview AI has put in place to protect human rights and fundamental freedoms include Clearview AI refusing to authorize the use of its technology to enable real-time use to enable government surveillance of any population or subgroup.",
            "metadata": {
                "source_domain": "www.clearview.ai",
                "scrape_date": "2024-10-25T12:40:34.865941",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 17593
            }
        },
        {
            "title": "The ClearView Way - Clearview",
            "text": "How We Work\n\nWe live and breathe the life sciences.\n\nOur work is built on decades of problem-solving and the deep scientific expertise of our team, enabling us to interrogate, integrate, and communicate the biological foundations of your endeavors.\n\nWe make the complex simple.\n\nThe best story is easy to tell. We believe in transparent, collaborative thinking that creates direct and clear recommendations.\n\nWe represent a higher standard.\n\nWe pit dedicated teams of smart, intellectually curious consultants against tough challenges. Our results are time-tested and trusted throughout the industry.\n\nWe create an exceptional project experience.\n\nSuccess is more than just the outcome – it’s how you got there. We cultivate a deep understanding of your needs and a tailored approach to build solutions together.\n\nWe invest in our people.\n\nWe provide best-in-class training and foster a strong community because we believe our team is core to our success.",
            "url": "https://clearviewhcp.com/the-clearview-way/#:~:text=ClearView%20was%20founded%20on%20the,%2Dmaking%2C%20and%20business%20outcomes.",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "training",
                "workwe",
                "understanding",
                "work",
                "deep",
                "team",
                "believe",
                "way",
                "trusted",
                "transparent",
                "tough",
                "clearview"
            ],
            "summary": "How We WorkWe live and breathe the life sciences.\nOur work is built on decades of problem-solving and the deep scientific expertise of our team, enabling us to interrogate, integrate, and communicate the biological foundations of your endeavors.\nWe believe in transparent, collaborative thinking that creates direct and clear recommendations.\nWe cultivate a deep understanding of your needs and a tailored approach to build solutions together.\nWe provide best-in-class training and foster a strong community because we believe our team is core to our success.",
            "metadata": {
                "source_domain": "clearviewhcp.com",
                "scrape_date": "2024-10-25T12:40:35.133279",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 955
            }
        },
        {
            "title": "U.S. COMMISSION ON CIVIL RIGHTS",
            "text": "March 8, 2024\n\n​\n\nDear Commissioners Garza, Nourse, Gilchrist, Adams, Jones, Magpantay, Kirsanow and Heriot,\n\n​\n\nIt is an honor and a pleasure to participate in our conversation today, which covers the very important topic of technology’s impact on civil rights. As a person of mixed race, it’s especially important to me that technology is deployed into the world in a way that protects and enhances civil rights.\n\n​\n\nMy name is Hoan Ton-That and I’m the founder and CEO of Clearview AI, a facial recognition search engine company. Our product is used by law enforcement and government agencies to solve crimes, such as child exploitation, murder, money laundering and financial fraud, as well as to investigate threats to national security. It is used in an after-the-fact forensic manner, not in real-time, and it only searches public information from the internet.\n\n​\n\nClearview AI’s facial recognition search engine has proven to be an extremely effective tool for law enforcement and national security agencies. For example, Clearview AI’s technology played an essential role in the investigation that followed the storming of the Capitol on January 6th, by helping law enforcement agencies investigate unidentified persons pictured engaging in violence that day.\n\n​\n\nOur technology has also been used by public defenders to help exonerate the innocent. In June 2023, the New York Times reported that a Florida man was facing 15 years in jail for a case of vehicular manslaughter that he did not commit. His public defender was able to use Clearview AI’s technology to identify another witness to the case from the police bodycam video. After the witness testified, the charges were dropped.\n\n​\n\n​\n\nClearview AI’s Efforts to Maximize Accuracy & Accountability\n\n​\n\nClearview AI has worked hard to validate our algorithm against external benchmarks and to create safeguards in our software and business practices that help protect civil rights and mitigate racial bias. As a result of these efforts, we offer one of the most accurate facial recognition systems in the world today. Here are some examples of our initiatives to ensure accuracy and accountability:\n\n​\n\nClearview AI’s technology is only available to government agencies and government contractors. We believe that this helps ensure our technology is being used in a manner consistent with the public good.\n\nClearview AI submits its algorithm to NIST’s Facial Recognition Technology Evaluation program, which offers the world’s most comprehensive accuracy and bias testing. In the NIST 1:N Face Recognition Vendor Test (\"FRVT\"), Clearview AI’s algorithm found the correct face out of a lineup of 12 million photos at an accuracy rate of 99.85 percent. This is much more accurate than the human eye. In the NIST 1:1 FRVT that evaluates demographic accuracy, Clearview AI’s algorithm consistently achieved greater than 99 percent accuracy across all demographics. As a person of mixed race, having an unbiased algorithm is important to me, so we have worked to ensure that our neural network algorithm is trained with data that is representative of all demographic groups. We are confident that our algorithm is much more accurate than the human eye across age, gender, and race.\n\nWe have included strong auditing features in our platform to ensure that it is being used for legitimate law enforcement purposes. Every law enforcement officer that uses Clearview AI must identify each search and document its purpose by assigning a crime type and case number for each search, ensuring that all searches are tied to a legitimate investigation. Each law enforcement agency must also assign an administrator that conducts audits to ensure that every search is for a legitimate purpose. Clearview AI’s application includes a suite of tools that enables administrators to view all search activity in their agency and generate a variety of statistics and reports on how the tool is being used, ensuring that agencies can exercise proper oversight and control of how facial recognition is being used.\n\nWe provide training on the responsible use of facial recognition to our customers. Every customer is instructed that facial recognition search results from Clearview AI should never be the sole source of an arrest. Independent investigation and confirmation is always required.\n\nWe do not display any “percentage match” score or value in software, ensuring that there’s always human review for any corresponding results by the investigator using Clearview AI. We are strong believers that technology’s role is not to replace human judgment, but rather to support human judgment, while speeding up time-consuming processes and minimizing mistakes.\n\nUnlike other facial recognition vendors, we use an algorithm to proactively check the resolution and quality of images that our users input to start a search (the “probe image”), and to generate an automatic warning if the probe image is classified as low quality. This protects against the risk of misidentification due to low-quality probe images.\n\nHigh Quality Facial Recognition Systems Can Reduce Bias\n\n​\n\nI’m sure that you have read that facial recognition technology suffers from issues of accuracy and bias, especially with regard to faces of persons of color. Some vendors have marketed systems that exhibited what I consider to be unacceptable levels of accuracy and racial bias. However, facial recognition technology has evolved dramatically over the last few years. Today, the top performing algorithms are rated to have extremely high levels of accuracy in NIST testing. Dr. Charles Romine, then-Director of NIST’s Information Technology Laboratory, testified in 2020 before the House of Representatives’ Homeland Security Committee that the class of top-performing algorithms exhibit “undetectable” bias below the “statistical level of significance”.\n\n​\n\nDespite the technological advances, there is still the question of whether or not widespread adoption of facial recognition technology by law enforcement is a positive development for communities of color. I believe that it is. Below are some exemplary scenarios that can explain how FRT generally, and Clearview AI’s search engine specifically, help decrease systemic bias in the criminal justice system.\n\nAccording to the Innocence Project, 70% of wrongful convictions result from eyewitness misidentification, which is especially prevalent in cases where the eyewitness and the identified person are of different races. Technology like Clearview AI is, in many senses, much more accurate than the human eye, which is subject to faulty memory and inherent human bias in eyewitness scenarios. By reducing the need to rely on human eyewitnesses, we reduce reliance on one of the most inaccurate and racially biased identification methodologies in criminal justice.\n\nThe status quo absent technology like Clearview AI is reliance on human eyewitnesses. And eyewitness misidentification is the number one factor in known instances of wrongful conviction, occurring in 190 out of the first 250 DNA exonerations. Most of these wrongful identifications were cross-racial, with a white victim wrongfully identifying a black defendant. This is consistent with the long-observed phenomenon that misidentifications are more common where the eyewitness and the identified person are of different races. Technology like Clearview AI can reduce the need to rely solely on human eyewitnesses, which in turn reduces reliance on one of the most inaccurate and racially biased identification methodologies in criminal justice.\n\nCurrently when law enforcement encounter a photo of a suspect from camera footage or elsewhere and are unable to identify them, they put out a “BOLO” (Be On the Lookout For) alert to surrounding law enforcement agencies with a description of the suspect, which typically includes race, gender, and physical description. This causes law enforcement to look for suspects who match that description, and question many people who may not be the suspect. It can involve unnecessary traffic stops and other police interactions with innocent people in the community. In a world with accurate facial recognition, the technology can help reliably identify the correct person sooner by searching against public information, preventing unneeded police interaction and biased eyewitness IDs.\n\nAccording to Justice Department statistics, Americans of color are disproportionately victimized by violent crime, at rates much higher than white Americans. Investigative facial recognition helps law enforcement agencies solve cases of violent crime quickly. Not only does this provide restorative justice to victims, who are usually members of marginalized communities, it also ensures that more resources can be dedicated to proactive crime prevention, community policing, and investigations of cold cases. The investigative efficiency made possible by facial recognition technology can help reduce the disproportionate toll that violent crime takes on communities of color.\n\nSome other facial recognition systems only search against datasets that are disproportionately composed of persons of color, as a result of pre-existing social inequalities, such as arrest records and so-called gang databases. Clearview AI is different. Because we can search a diverse dataset composed of more than 40 billion photos on the public internet, our searches are less likely to perpetuate systemic inequalities.\n\nPublic defenders often lack the resources to properly investigate on behalf of their clients. Today, they can use facial recognition technology, including Clearview AI’s search engine, to help identify witnesses and suspects and to use that information to exonerate the innocent.\n\nWe believe that facial recognition technology, properly used with training and oversight, can help combat discrimination, reduce systemic bias in the criminal justice system, and respect civil rights. We should not live in a world where police need to use imprecise descriptions which include race, height and gender to help identify people. Instead, facial recognition offers us an opportunity to live in a safer world with fewer unnecessary police interactions and misidentifications.\n\n​\n\nEvery positive identification made with Clearview AI’s technology is also an instance in which a misidentification from reliance on eyewitnesses was prevented. This is the other positive side to facial recognition that is not talked about.\n\n​\n\nConclusion\n\nClearview AI has worked hard to engage with the public and other key stakeholders and address concerns. We have engaged with the media to build understanding and trust with the public, and proactively sought out members of Congress, and state and local elected officials, to educate them about what our technology does. I hope that my testimony here today will continue that process. I believe that these efforts have helped bring about a more accurate understanding of facial recognition technology and its positive impact. Public opinion polling consistently shows that broad majorities of Americans support use of facial recognition technology by law enforcement.\n\nThis support is not surprising, when we take into account the dramatic positive impact that investigative facial recognition technology can have for victims. Most recently, a dedicated Homeland Security Investigations task force was able to use Clearview AI’s technology in an operation that led to the identification of 311 missing and exploited children in only 3 weeks. HSI and other agencies were able to conduct multiple child rescues as a result. This outstanding result speaks for itself. We can use a highly accurate algorithm, with effective risk mitigation measures, to search public online images, and help protect the innocent while providing justice and safety to countless victims.",
            "url": "https://www.clearview.ai/us-commission-on-civil-rights",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "public",
                "law",
                "technology",
                "enforcement",
                "facial",
                "ais",
                "rights",
                "ai",
                "civil",
                "commission",
                "clearview",
                "search",
                "recognition"
            ],
            "summary": "​My name is Hoan Ton-That and I’m the founder and CEO of Clearview AI, a facial recognition search engine company.\n​Clearview AI’s facial recognition search engine has proven to be an extremely effective tool for law enforcement and national security agencies.\nAs a result of these efforts, we offer one of the most accurate facial recognition systems in the world today.\nWe believe that facial recognition technology, properly used with training and oversight, can help combat discrimination, reduce systemic bias in the criminal justice system, and respect civil rights.\nI believe that these efforts have helped bring about a more accurate understanding of facial recognition technology and its positive impact.",
            "metadata": {
                "source_domain": "www.clearview.ai",
                "scrape_date": "2024-10-25T12:40:36.872675",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 11874
            }
        },
        {
            "title": "Clearview AI policy \"statements\"",
            "text": "{\"text\": \"Copies of the written statements provided by these bodies are available below. Additional written statements will be added as they become available. The�...\\nFeb 3, 2021 � Statement by the Privacy Commissioner of Canada following an investigation into Clearview AI ... Brief statements followed by Q and A .\\nAug 21, 2024 � That media reporting was not based on new information, but rather referenced statements made by Clearview AI in the course of the AAT�...\\nPeople also ask\\nCan the public use Clearview AI?\\nWhat is Clearview AI mission statement?\\nCan you opt out of Clearview AI?\\nWhat happened to Clearview AI?\\nFeb 3, 2021 � ... statements that the technology had not been procured or used. This is not, therefore, just a story about a bad technology actor, but also�...\\n24 So statements like “The Service is committed to continuously ensuring bias is avoided” offer a false promise. Bias cannot be avoided, it can only be�...\\nFeb 3, 2021 � Furthermore, Clearview publicly declared Canada to be part of its core market in statements to the media and its own promotional materials.\\nApr 6, 2022 � In response to fines, Clearview AI's CEO issues statements that mock all the fines national authorities issue. National agencies and�...\\nDec 20, 2021 � it mixes technical characteristics about the technologies with statements about the scope of the. Policy. The definition also includes “any�...\\nMay 24, 2022 � ... Clearview AI facial recognition system—and making misleading statements about it. Earlier this year, Italian data protection authorities�...\\nClearview made false and mislead- ing statements about its business in. Vermont; and that Clearview bro- kered personal biometric informa- tion through�...\"}",
            "url": "https://www.google.com/search?sca_esv=98f1e80d24ca1b54&q=Clearview+AI+policy+%22statements%22&sa=X&ved=2ahUKEwi3vMCy16iJAxUoLFkFHUY-MsoQ5t4CegQIMxAB",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "policy",
                "feb",
                "bad",
                "ę",
                "alsoā",
                "used",
                "2021",
                "procured",
                "ai",
                "statements",
                "clearview",
                "actor",
                "technology"
            ],
            "summary": "Feb 3, 2021 Ę ... statements that the technology had not been procured or used.\nThis is not, therefore, just a story about a bad technology actor, but alsoĀ...",
            "metadata": {
                "source_domain": "www.google.com",
                "scrape_date": "2024-10-25T12:40:36.490261",
                "content_type": "other",
                "extraction_method": "trafilatura",
                "content_length": 159
            }
        },
        {
            "title": "",
            "text": "",
            "url": "https://www.clearview.ai/_files/ugd/6d87a5_5366e5a617b24de9a086c694d9266a90.pdf?index=true",
            "authors": [],
            "publish_date": null,
            "keywords": [],
            "summary": "",
            "metadata": {
                "source_domain": "www.clearview.ai",
                "scrape_date": "2024-10-25T12:40:36.717499",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 0
            }
        },
        {
            "title": "A big success for Homo Digitalis: The Hellenic DPA fines CLEARVIEW AI with €20 million – Homo Digitalis",
            "text": "Today, following a complaint filed by Homo Digitalis in May 2021 representing our member and data subject Marina Zacharopoulou, the Hellenic Data Protection Authority (HDPA) issued Decision 35/2022 imposing a fine of 20 million euros on Clearview AI for its intrusive practices. This is the highest GDPR fine, ever imposed by the Hellenic DPA. By the same Decision, the DPA prohibits that company from collecting and processing the personal data of data subjects located in Greece using facial recognition methods and requires it to delete immediately any data it has already collected.\n\nSpecifically, in May 2021, an alliance of civil society organizations consisting of Homo Digitalis and the organizations Privacy International, Hermes Center, and noyb filed complaints before the competent authorities in Greece, the United Kingdom, Italy, Austria, France and the United Kingdom against Clearview AI for its mass surveillance practices through facial recognition.\n\nEarlier this year, the Italian Data Protection Authority had decided to fine the company €20 million, while the UK’s equivalent authority had decided to fine it £7.5 million.\n\nThe €20 million fine imposed by the DPA today is another strong signal against intrusive business models of companies that seek to make money through the illegal processing of personal data. At the same time, it sends a clear message to law enforcement authorities working with companies of this kind that such practices are illegal and grossly violate the rights of data subjects.\n\nClearview AI is an American company founded in 2017 that develops facial recognition software. It claims to have “the largest known database of more than three billion facial images” which it collects from social media platforms and other online sources. It is an automated tool that visits public websites and collects any images it detects that contain human faces. Along with these images, the automated collector also collects metadata that complements these images, such as the title of the website and its source link. The collected facial images are then matched against the facial recognition software created by Clearview AI in order to build the company’s database. Clearview AI sells access to this database to private companies and law enforcement agencies, such as police authorities, internationally.\n\nThe full text of Decision 35/2022 can be found here (only in EL).",
            "url": "https://homodigitalis.gr/en/posts/12155/",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "digitalis",
                "fines",
                "recognition",
                "fine",
                "dpa",
                "facial",
                "big",
                "homo",
                "data",
                "hellenic",
                "ai",
                "million",
                "clearview",
                "images",
                "practices",
                "success"
            ],
            "summary": "The €20 million fine imposed by the DPA today is another strong signal against intrusive business models of companies that seek to make money through the illegal processing of personal data.\nClearview AI is an American company founded in 2017 that develops facial recognition software.\nIt claims to have “the largest known database of more than three billion facial images” which it collects from social media platforms and other online sources.\nThe collected facial images are then matched against the facial recognition software created by Clearview AI in order to build the company’s database.\nClearview AI sells access to this database to private companies and law enforcement agencies, such as police authorities, internationally.",
            "metadata": {
                "source_domain": "homodigitalis.gr",
                "scrape_date": "2024-10-25T12:40:39.104871",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 2409
            }
        },
        {
            "title": "Imposition of fine on Clearview AI, Inc",
            "text": "Summary\n\nBy Decision No 35/2022, the Authority examined a complaint against Clearview AI Inc, lodged by the civil nonprofit organization “Homo Digitalis” on behalf of a complainant, who claimed that s/he was not satisfied in relation to the right of access s/he exercised before the aforementioned company. By the complaint it was also requested that the practices of the defendant company on the whole be examined from the point of view of the protection of personal data. In particular, the Authority found that in this case the company, which markets facial recognition services, violated the principles of lawfulness and transparency (art. 5 paragraphs 1(a), 6, 9 GDPR) and its obligations under Articles 12, 14, 15 and 27 of the GDPR, imposing a fine of twenty million euros (20 000 000). In addition, the Authority issued a compliance order to the same company so that the latter satisfies the complainant’s request for access to personal data, while imposing on the same company a prohibition on the collection and processing of personal data of subjects located in the Greek territory, using methods included in the facial recognition service. Finally, with this Decision, the Authority sent Clearview AI Inc. an order to delete the personal data of those subjects located in Greece, which the defendant collects and processes using those methods.",
            "url": "http://www.dpa.gr/en/en/enimerwtiko/prakseisArxis/imposition-fine-clearview-ai-inc",
            "authors": [
                "Helpful Links"
            ],
            "publish_date": null,
            "keywords": [
                "using",
                "fine",
                "authority",
                "order",
                "company",
                "personal",
                "subjects",
                "data",
                "located",
                "methods",
                "ai",
                "imposition",
                "clearview",
                "recognition"
            ],
            "summary": "SummaryBy Decision No 35/2022, the Authority examined a complaint against Clearview AI Inc, lodged by the civil nonprofit organization “Homo Digitalis” on behalf of a complainant, who claimed that s/he was not satisfied in relation to the right of access s/he exercised before the aforementioned company.\nBy the complaint it was also requested that the practices of the defendant company on the whole be examined from the point of view of the protection of personal data.\nIn particular, the Authority found that in this case the company, which markets facial recognition services, violated the principles of lawfulness and transparency (art.\n5 paragraphs 1(a), 6, 9 GDPR) and its obligations under Articles 12, 14, 15 and 27 of the GDPR, imposing a fine of twenty million euros (20 000 000).\nFinally, with this Decision, the Authority sent Clearview AI Inc. an order to delete the personal data of those subjects located in Greece, which the defendant collects and processes using those methods.",
            "metadata": {
                "source_domain": "www.dpa.gr",
                "scrape_date": "2024-10-25T12:40:39.968030",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 1355
            }
        },
        {
            "title": "Facial Recognition: Greek DPA imposes a fine of 20 million Euros on Clearview AI",
            "text": "In July 2022, the Greek Data Protection Authority (DPA) imposed a mammoth fine of 20 million Euros on Clearview AI. According to the DPA Decision No 35/2022, this fine followed a complaint of the nonprofit organisation “Homo Digitalis”, regarding processing of biometric data. This is the highest fine ever imposed by the Greek DPA since the implementation of the GDPR. The DPA’s enforcement decision is part of a broader mistrust towards Clearview’s mass surveillance practices through facial recognition in Europe. The decision reflects the public attention AI-supported facial recognition technologies have been gaining recently.\n\nPan-European action against Clearview AI\n\nClearview AI collects information derived from publicly available photos and selfies on social media platforms and other online sources, including their metadata, i.e. the URLs of the websites where those photos are located. These techniques are commonly known as web scraping methods. Clearview AI matches the collected data against its facial recognition software to include it in its extensive database of more than 10 billion facial images. Access to the database is sold to private companies and law enforcement agencies around the world.\n\nIn May 2021, several nonprofit organisations (including Homo Digitalis, Privacy International, Hermes Center, and Noyb) lodged complaints before the supervisory authorities of Greece, Austria, France, Italy and the United Kingdom, in an effort to create a coordinated response to these practices.\n\nAs of today, several DPAs in Europe (CNIL, ICO and Garante) have found numerous GDPR infringements by Clearview AI. These DPAs have imposed several sanctions, totaling almost 50 million Euros. Additionally, the DPAs ordered Clearview AI to delete and stop processing affected data. Austria’s ruling is expected to be released in the coming months.\n\nThe ruling of the Greek DPA\n\nIn this case, the complainant claimed that Clearview did not appropriately respond to her data access request. More generally, the complainant requested the data collection practices of Clearview AI to be examined as a whole.\n\nThe Greek DPA, in its 21-page Decision, determined that Clearview AI, as a controller, breached the GDPR principle of lawfulness, fairness and transparency. Furthermore, Clearview AI violated its obligations to provide access and information, and the requirement for non-EU controllers to name an EU representative. The Greek DPA further reasoned that “the processing in question does not concern a simple collection of data.” Instead, Clearview AI converted the photographs it collected into biometric data. As the GDPR imposes differing requirements on the collection of photographs and the processing of biometric data, Clearview AI would have needed separate legal bases for both.\n\nAs a result, the DPA elected to impose this record breaking fine and an accompanying compliance order that requires Clearview AI to act in accordance with its obligations.\n\nIn determining the fine, the Greek DPA has taken into account – amongst other – “the nature, gravity and duration of the infringement, which is not an isolated incident, but is systematic and concerns the basic principles of the lawfulness of the processing (art. 5, 6, 9 GDPR), which are fundamental to the protection of personal data”. Other factors considered were the number of affected subjects in the Greek territory, and also the fact that Clearview AI collects and processes biometric data, a particularly sensitive category of data. In other words, Clearview AI was deemed to have violated the main concepts of the GDPR, thereby posing a particularly high risk to individuals’ rights.\n\nLastly, with regard to the GDPR’s territorial scope, it is worth noting that Clearview AI is a U.S. based company that does not operate or offer services in Greece or the EU. However, if products are used to monitor or otherwise affect EU citizens, this case clearly shows that GDPR compliance still might be required. Accordingly, companies based outside the EU should be prepared to assess possible risks. Clearview AI’s reaction to these DPA enforcement actions seems to suggest that Clearview AI may attempt not to conduct business in Europe anymore. Time will tell if this attempt can be successful, especially from the regulator’s perspective.\n\nKey takeaways\n\nAssessment of compliance risks can be made much easier if your organisation has a comprehensive and proactive data protection programme in place. Experienced DPOs can support you in maturing data protection, and in avoiding adverse effects, such as penalties or public mistrust of your services.\n\nFor support on data protection and privacy-related matters, please contact us at dpo@hewardmills.com.",
            "url": "https://www.hewardmills.com/facial-recognition-greek-dpa-imposes-a-fine-of-20-million-euros-on-clearview-ai/",
            "authors": [],
            "publish_date": "2022-09-30T08:47:24+00:00",
            "keywords": [
                "protection",
                "gdpr",
                "fine",
                "euros",
                "imposes",
                "dpa",
                "greek",
                "facial",
                "data",
                "ai",
                "million",
                "processing",
                "clearview",
                "recognition"
            ],
            "summary": "In July 2022, the Greek Data Protection Authority (DPA) imposed a mammoth fine of 20 million Euros on Clearview AI.\nClearview AI matches the collected data against its facial recognition software to include it in its extensive database of more than 10 billion facial images.\nThe Greek DPA, in its 21-page Decision, determined that Clearview AI, as a controller, breached the GDPR principle of lawfulness, fairness and transparency.\nFurthermore, Clearview AI violated its obligations to provide access and information, and the requirement for non-EU controllers to name an EU representative.\nClearview AI’s reaction to these DPA enforcement actions seems to suggest that Clearview AI may attempt not to conduct business in Europe anymore.",
            "metadata": {
                "source_domain": "www.hewardmills.com",
                "scrape_date": "2024-10-25T12:40:40.090250",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 4742
            }
        },
        {
            "title": "The highest fine ever imposed by the Greek DPA on Clearview AI",
            "text": "The U.S.-based company Clearview AI (hereafter Clearview) known for its facial recognition services received a fine of €20.000.000 by the Greek Data Protection Authority for the non-compliant collection and processing of personal data. This is the first time that the Hellenic DPA has imposed such a high data protection fine. Clearview develops facial recognition software collecting facial images from public online sources. The collection of so many photos creates an oasis of images, which are sold to private companies and law enforcement agencies. More information on the services offered by Clearview and on fines imposed by other DPAs can be found here.\n\nBackground of the case\n\nThe complaint, which led to the decision of the Authority, was lodged by the non-profit civil organization ‚Homo Digitalis‘ on behalf of the complainant in May 2021. The complainant exercised the right of access to the company as described in Art. 15 GDPR, but according to her allegation, her right was not fulfilled. In addition, the practices of the accused company were requested to be examined with regard to personal data and compliance with data protection law.\n\nThe Decision\n\nAccording to the 35/2022 decision of the Greek Data Protection Authority, Clearview AI received a €20.000.000 fine for non-compliance with the principles of lawfulness and transparency and with the requirements under Art. 12, 14, 15 and 27 of the GDPR. Furthermore, the Authority imposed an order on fulfilling the right of access of the complainant, imposed a prohibition on the collection and processing of personal data of subjects located in the Greek territory and required the immediate deletion of any data already collected of data subjects located in Greece through the company’s facial recognition services (Art. 58 para. 2 lit. g).\n\nClearview creates “profiles” of individuals\n\nClearview collects photos of individuals from different public sources (blogs, social media, etc). Specifically, the company may extract information from these photos such as metadata or routines, habits and preferences of individuals, and information derived from their facial appearance, that allows the evaluation and potentially the identification of the person’s behavior. As a result, this automated processing of personal data leads to the creation of profiles of individuals. The data gathered is then marketed through Clearview’s database and users of the Clearview facial recognition platform can search and identify respective individuals. Furthermore, users of Clearview’s platform have the possibility to search the database by uploading an image of the individual they wish to identify. In fact, the database is constantly updated, determining the evolution of the information relating to a specific individual. However, the defendant denied these statements and refused the monitoring of people through their images due to the fact that there is a preview of images and not a systematic monitoring of each individual.\n\nThe reasoning behind the decision\n\nViolation of GDPR principles:\n\nThe Hellenic DPA found out that in this particular case the company systematically violated the principles of lawfulness and transparency (Articles 5(1)(a), 6, 9 of the GDPR).\n\nPrinciple of lawfulness of processing\n\nAs the Authority pointed out there is no legal basis for processing personal data as provided for in Article 6 of the GDPR. Moreover, none of the exceptions in relation to special categories of data listed in Article 9 of the GDPR are met. The data processed by Clearview belong to the category of biometric data, which are considered a special category of data that can only be processed under certain exceptions. Therefore, the processing of personal data is unlawful.\n\nPrinciple of transparency of processing\n\nAccording to the Authority, there is a breach of the principle of transparency (Article 5(1)(a) of the GDPR) and the related right to information of the data subjects (Article 14 of the GDPR), because the defendant failed to inform the data subjects whose data it processes accurately and clearly about the collection and use of their personal data.\n\nViolation of data subject rights:\n\nThe Authority found that the company, violated its obligations under Articles 12, 14, and 15 of the GDPR. Subsequently, it was held that the data subjects whose data are processed by the defendant do not receive any information from the latter, through its privacy policy, in relation to any of the data provided for in Article 14 of the GDPR, neither before nor even after the processing. In fact, the data subjects are likely to never know that their data were processed by the defendant.\n\nSimilarly, although the complainant exercised her right of access to her personal data under Article 15 of the GDPR by sending an e-mail to the defendant, she never received any reply to it and her right of access was never met.\n\nViolation of the obligation to appoint a representative:\n\nThe Authority noted that the company violated its obligations under Article 27 of the GDPR. However, the defendant argued that they are not regulated by the GDPR, they don’t have an establishment in the EU and they do not offer goods or services to people residing in the EU nor monitor their behavior (Art. 3 GDPR). Additionally, the company argued that their services are merely offered to law enforcement agencies outside EU.\n\nClearview’s use of profiling techniques constitutes an act of targeting data subjects residing in the EU. In this regard, it was initially found that Clearview falls within the scope of the GDPR, under Article 3 para. 2(b) without having an establishment in the EU. Therefore, it has an obligation to designate a representative in the EU in accordance with Article 27 of the GDPR, which it has not fulfilled.",
            "url": "https://www.datenschutz-notizen.de/the-highest-fine-ever-imposed-by-the-greek-dpa-on-clearview-ai-2339293/",
            "authors": [
                "Marina Anagnostaki",
                ".Wp-Block-Co-Authors-Plus-Coauthors.Is-Layout-Flow",
                "Class",
                "Wp-Block-Co-Authors-Plus",
                "Display Inline",
                ".Wp-Block-Co-Authors-Plus-Avatar",
                "Where Img",
                "Height Auto Max-Width",
                "Vertical-Align Bottom .Wp-Block-Co-Authors-Plus-Coauthors.Is-Layout-Flow .Wp-Block-Co-Authors-Plus-Avatar",
                "Vertical-Align Middle .Wp-Block-Co-Authors-Plus-Avatar Is .Alignleft .Alignright"
            ],
            "publish_date": "2022-11-30T11:35:23+01:00",
            "keywords": [
                "fine",
                "article",
                "dpa",
                "authority",
                "company",
                "highest",
                "imposed",
                "greek",
                "personal",
                "subjects",
                "right",
                "data",
                "ai",
                "gdpr",
                "processing",
                "clearview"
            ],
            "summary": "The U.S.-based company Clearview AI (hereafter Clearview) known for its facial recognition services received a fine of €20.000.000 by the Greek Data Protection Authority for the non-compliant collection and processing of personal data.\nThe DecisionAccording to the 35/2022 decision of the Greek Data Protection Authority, Clearview AI received a €20.000.000 fine for non-compliance with the principles of lawfulness and transparency and with the requirements under Art.\nAs a result, this automated processing of personal data leads to the creation of profiles of individuals.\nIn fact, the data subjects are likely to never know that their data were processed by the defendant.\nClearview’s use of profiling techniques constitutes an act of targeting data subjects residing in the EU.",
            "metadata": {
                "source_domain": "www.datenschutz-notizen.de",
                "scrape_date": "2024-10-25T12:40:40.349567",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 5793
            }
        },
        {
            "title": "Dutch DPA imposes a fine on Clearview because of illegal data collection for facial recognition",
            "text": "Clearview is a commercial business that offers facial recognition services to intelligence and investigative services. Customers of Clearview can provide camera images to find out the identity of people shown in the images. For this purpose, Clearview has a database with more than 30 billion photos of people. Clearview scrapes these photos automatically from the Internet. And then converts them into a unique biometric code per face. Without these people knowing this and without them having given consent for this.\n\nNever anonymous anymore\n\n‘Facial recognition is a highly intrusive technology, that you cannot simply unleash on anyone in the world’, Dutch DPA chairman Aleid Wolfsen says. ‘If there is a photo of you on the Internet – and doesn't that apply to all of us? – then you can end up in the database of Clearview and be tracked. This is not a doom scenario from a scary film. Nor is it something that could only be done in China.’\n\nClearview says that it provides services to intelligence and investigative services outside the European Union (EU) only. ‘That is bad enough as it is’, Wolfsen says. ‘This really shouldn't go any further. We have to draw a very clear line at incorrect use of this sort of technology.’\n\nWolfsen acknowledges the importance of safety and the detection of criminals by official authorities. He also acknowledges that techniques such as facial recognition can make a contribution to this. ‘But certainly not by a commercial business. And by competent authorities in highly exceptional cases only. The police, for example, have to manage the software and database themselves in that case, subject to strict conditions and under the watchful eye of the Dutch DPA and other supervisory authorities.’\n\nServices of Clearview illegal\n\nWolfsen warns: do not use Clearview. ‘Clearview breaks the law, and this makes using the services of Clearview illegal. Dutch organisations that use Clearview may therefore expect hefty fines from the Dutch DPA.’\n\nViolations by Clearview\n\nClearview has seriously violated the privacy law General Data Protection Regulation (GDPR) on several points: the company should never have built the database and is insufficiently transparent.\n\nIllegal database\n\nClearview should never have built the database with photos, the unique biometric codes and other information linked to them. This especially applies for the codes. Like fingerprints, these are biometric data. Collecting and using them is prohibited. There are some statutory exceptions to this prohibition, but Clearview cannot rely on them.\n\nInsufficient transparency\n\nClearview informs the people who are in the database insufficiently about the fact that the company uses their photo and biometric data. People who are in the database also have the right to access their data. This means that Clearview has to show people which data the company has about them, if they ask for this. But Clearview does not cooperate in requests for access.\n\nIncremental penalties\n\nClearview did not stop the violations after the investigation by the Dutch DPA. That is why the Dutch DPA has ordered Clearview to stop those violations. If Clearview fails to do this, the company will have to pay penalties for non-compliance in a total maximum amount of 5.1 million euro on top of the fine.\n\nAmerican company\n\nClearview is an American company without an establishment in Europe. Other data protection authorities have already fined Clearview at various earlier occasions, but the company does not seem to adapt its conduct. That is why the Dutch DPA is looking for ways to make sure that Clearview stops the violations. Among other things, by investigating if the directors of the company can be held personally responsible for the violations.\n\nWolfsen: ‘Such company cannot continue to violate the rights of Europeans and get away with it. Certainly not in this serious manner and on this massive scale. We are now going to investigate if we can hold the management of the company personally liable and fine them for directing those violations. That liability already exists if directors know that the GDPR is being violated, have the authority to stop that, but omit to do so, and in this way consciously accept those violations.’\n\nClearview has not objected to this decision and is therefore unable to appeal against the fine.",
            "url": "https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-on-clearview-because-of-illegal-data-collection-for-facial-recognition",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "database",
                "recognition",
                "fine",
                "biometric",
                "imposes",
                "illegal",
                "dpa",
                "company",
                "collection",
                "violations",
                "dutch",
                "data",
                "services",
                "clearview",
                "stop",
                "facial"
            ],
            "summary": "Never anonymous anymore‘Facial recognition is a highly intrusive technology, that you cannot simply unleash on anyone in the world’, Dutch DPA chairman Aleid Wolfsen says.\nLike fingerprints, these are biometric data.\nIncremental penaltiesClearview did not stop the violations after the investigation by the Dutch DPA.\nThat is why the Dutch DPA has ordered Clearview to stop those violations.\nThat is why the Dutch DPA is looking for ways to make sure that Clearview stops the violations.",
            "metadata": {
                "source_domain": "www.autoriteitpersoonsgegevens.nl",
                "scrape_date": "2024-10-25T12:40:40.948797",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 4339
            }
        },
        {
            "title": "Clearview AI",
            "text": "Clearview AI is a privately-owned, U.S. based company, dedicated to innovating and providing the most cutting-edge technology to law enforcement, government agencies and the military to investigate crimes, enhance public safety, secure our communities and provide justice to victims.\n\nWe have developed a revolutionary, web-based intelligence platform for government agencies to use as a tool to help generate high-quality investigative leads. Our platform, powered by facial recognition technology, includes the largest known database of 50+ billion facial images sourced from public-only web sources, including news media, mugshot websites, public social media, and other open sources.\n\nOur solutions empower agencies to gain intelligence, disrupt crime, and enhance public safety by revealing leads, insights and relationships, aiding investigators in solving both simple and complex crimes, ultimately enhancing officer and public safety, and ensuring the safety of our communities and families.",
            "url": "https://www.clearview.ai/overview#:~:text=WE%20ARE%20CLEARVIEW%20AI&text=The%20platform%20includes%20a%20facial,media%2C%20and%20other%20open%20sources.",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "public",
                "enhance",
                "intelligence",
                "agencies",
                "facial",
                "leads",
                "platform",
                "safety",
                "ai",
                "clearview",
                "media",
                "technology"
            ],
            "summary": "Clearview AI is a privately-owned, U.S. based company, dedicated to innovating and providing the most cutting-edge technology to law enforcement, government agencies and the military to investigate crimes, enhance public safety, secure our communities and provide justice to victims.\nWe have developed a revolutionary, web-based intelligence platform for government agencies to use as a tool to help generate high-quality investigative leads.\nOur platform, powered by facial recognition technology, includes the largest known database of 50+ billion facial images sourced from public-only web sources, including news media, mugshot websites, public social media, and other open sources.\nOur solutions empower agencies to gain intelligence, disrupt crime, and enhance public safety by revealing leads, insights and relationships, aiding investigators in solving both simple and complex crimes, ultimately enhancing officer and public safety, and ensuring the safety of our communities and families.",
            "metadata": {
                "source_domain": "www.clearview.ai",
                "scrape_date": "2024-10-25T12:40:42.307026",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 1003
            }
        },
        {
            "title": "Clearview AI",
            "text": "{\"text\": \"SECURITY AT CLEARVIEW AI\\nClearview AI’s Security teams establish policies and controls, monitor compliance with those controls, and prove our security and compliance to third-party auditors.\\nOur policies are based on the following foundational principles:\\n1: Access to Clearview AI products is limited to only those with a legitimate business need and granted based on the principle of least privilege.\\n2: Security controls should be implemented and layered according to the principle of defense-in-depth.\\n3. Security controls should be applied consistently across all areas of the enterprise.\\n4. The implementation of controls should be iterative, continuously maturing across the dimensions of improved effectiveness, increased auditability, and decreased friction.\\nSECURITY & COMPLIANCE AT CLEARVIEW AI\\nClearview AI maintains a SOC 2 Type II attestation. Our SOC 2 Type II report is available to prospective clients with a signed NDA through our sales team.\\nClearview AI maintains compliance with key regulations including SOC 2 and applicable data privacy laws.\\nClearview AI is also TX-RAMP (Risk and Authorization Management Program) certified. This certification highlights our adherence to the highest security standards required by the state of Texas.\\nDATA PROTECTION\\nDATA AT REST\\nClearview AI stores customer data in encrypted datastores to protect it at rest. Sensitive collections and tables also use row-level encryption. This data is encrypted even before it hits the database so that logical access to the database prevents reading the most sensitive information.\\nDATA IN TRANSIT\\nClearview AI uses TLS 1.2 or higher when data is transmitted between users and our platform. To maximize the security of our data in transit, we also employ point to point mutual TLS encryption between internal servers.\\nPRODUCT SECURITY\\nPENETRATION TESTING\\nClearview AI conducts comprehensive penetration testing at least once a year with a leading penetration testing consulting firm. The tests cover all areas of our product and cloud infrastructure. The penetration testers have full access to our source code to maximize the effectiveness and coverage of the assessments.\\nOur penetration tests are available to prospective clients with a signed NDA through our sales team.\\nVULNERABILITY SCANNING\\nClearview AI requires vulnerability scanning at key stages of our Software Development Lifecycle (SDLC):\\nStatic analysis (SAST) testing of code during pull requests and on an ongoing basis\\nMalicious dependency scanning to prevent the introduction of malware into our software supply chain\\nNetwork vulnerability scanning on a period basis\\nSoftware composition analysis (SCA) to identify known vulnerabilities in our software supply chain\\nExternal attack surface management (EASM) continuously running to discover new external-facing assets\\nENTERPRISE SECURITY\\nENDPOINT PROTECTION: All corporate devices are centrally managed and are equipped with mobile device management software (MDM) and anti-malware protection. Endpoint security alerts are monitored with 24/7/365 coverage. We use MDM software to enforce secure configuration of endpoints, such as disk encryption, screen lock configuration, and software updates. Clearview AI's security team has protocols in place for external and internal emergency situations, such as breach notification or loss of equipment.\\nSECURE REMOTE ACCESS: Clearview AI secures remote access to internal resources using a modern VPN platform. We also use malware-blocking DNS servers to protect employees and their endpoints while browsing the internet.\\nSECURITY EDUCATION: Clearview AI ensures that all its employees receive thorough security training when they join the company and annually thereafter. This training involves live sessions led by the Head of Security, focusing on essential security principles and their implementation within Clearview AI's Security Program. Additionally, new engineers are required to attend a mandatory live onboarding session with senior team leads, where they learn about secure coding principles and practices. Clearview AI's security team also regularly provides threat briefings to keep employees informed about critical security and safety updates that may require special attention or action.\\nIDENTITY & ACCESS MANAGEMENT: Clearview AI uses secure identity and access management, enforcing strong MFA and SAML-based Single Sign-on wherever possible. Clearview AI employees are granted access to applications and services based on their role, and automatically deprovisioned upon termination of their employment. Further access must be approved according to the policies set for each application or service.\\nBUG BOUNTY PROGRAM\\nClearview AI works with an industry leading Bug Bounty program. Security is a top priority for Clearview AI, and Clearview AI believes that working with skilled security researchers can identify weaknesses in any technology.\\nIf you believe you have discovered a security vulnerability in Clearview AI’s service, please notify us; we will work with you to resolve the issue promptly\\nTo participate in our Bug Bounty Program, click below:\\nDATA PRIVACY\\nAt Clearview AI, data privacy is a first-class priority—we strive to be trustworthy stewards of all sensitive data.\\nTo see more on our data privacy and security, please see the Privacy Policy and Data Request sections of our website.\"}",
            "url": "https://www.clearview.ai/security",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "prospective",
                "testing",
                "penetration",
                "tests",
                "team",
                "signed",
                "source",
                "testingclearview",
                "sales",
                "testers",
                "ai",
                "clearview"
            ],
            "summary": "PENETRATION TESTINGClearview AI conducts comprehensive penetration testing at least once a year with a leading penetration testing consulting firm.\nThe tests cover all areas of our product and cloud infrastructure.\nThe penetration testers have full access to our source code to maximize the effectiveness and coverage of the assessments.\nOur penetration tests are available to prospective clients with a signed NDA through our sales team.",
            "metadata": {
                "source_domain": "www.clearview.ai",
                "scrape_date": "2024-10-25T12:40:42.347031",
                "content_type": "other",
                "extraction_method": "trafilatura",
                "content_length": 441
            }
        },
        {
            "title": "What Clearview AI has Implemented to Ensure That Facial Recognition Technology is Used Responsibly",
            "text": "At Clearview AI, every decision we make is grounded in a commitment to ensuring that our technology is used ethically to make society safer. Our mission as a company is to provide technology that can help prevent and solve crime and fraud. Our software is faster, more robust, and more accurate than any competing platform or traditional identification method. We believe that we can help governments do their work of protecting the public while respecting privacy.\n\nWith any new technology, we want to ensure that it is used for the best and highest purpose, while proactively limiting any potential downsides of the technology. We have implemented both technical solutions and human processes and procedures that significantly reduce the chance of misidentification and misuse.\n\nI am writing this to address typical questions about facial recognition and provide information about how our platform works in reality, and the structural safeguards we have in place to carry out our commitment to safe, ethical facial recognition technology.\n\nHOW DOES OUR PLATFORM WORK?\n\nWho may access Clearview AI’s platform?\n\nClearview AI’s facial recognition search engine is not a consumer application. Our only current customers are government agencies. Our platform may only be used to assist government agencies in the course of law enforcement investigations or in connection with national security matters.\n\nEach customer is vetted to ensure that they are a legitimate government agency, and have the appropriate authorization in order to start a trial. We encourage each customer to have a public facing Facial Recognition Policy, outlining the use cases, situations, and types of crimes for which they will use facial recognition.\n\nTraining protocols\n\nEven though Clearview AI offers a simple, intuitive, and easy-to-use facial recognition platform , we provide training before any individual may access our software. We also require our agency users to appoint administrators to oversee the use of Clearview AI by their employees and manage access. We provide reporting tools that enable them to generate usage reports and audits. Our terms of use require our users never to rely on the results we provide as the sole means of identifying a suspect. Each possible match must be confirmed by independent, corroborating information.\n\nNot real-time surveillance\n\nClearview AI’s database is not used for any real-time surveillance. Surveillance is the live monitoring of behavior, activities, or information. A platform like Clearview AI is used to generate leads connected to an incident after an event has occurred. The process of uploading an image of a suspect, victim, or person of interest after an incident occurs is not “monitoring” or “surveillance” of an individual. Rather, it is an information gathering step in the investigative process.\n\nAfter-the-crime investigations\n\nClearview AI’s investigative platform is only used for after-the-crime investigations. What that means, is if a crime has occurred, and there is a photo of the suspect or the victim who is unidentified, law enforcement can search that photo against Clearview AI’s publicly available database to help in the investigative process. The use of facial recognition in this case is the beginning of an investigation, not the definitive answer to an investigation.\n\nStrict standards for accurate results\n\nUnlike other facial recognition technologies for law enforcement, Clearview AI doesn’t provide a percentage match score, or distance score next to its results. This pushes the investigator to click the web link associated with the result, and not rely on algorithms (no matter how accurate) as the only piece of information for making identifications.\n\nAlso, Clearview AI’s system cannot be changed to modify the confidence interval cutoff for the number of results displayed. Some other facial recognition systems for law enforcement always return a defined number of results, no matter how accurate or inaccurate they may be. These other systems also can be configured to return more results at a higher confidence interval. Clearview AI’s system cannot be modified in this way. Our threshold for showing results is very strict. We would rather show no results, than show a false positive.\n\nCommon uses\n\nAfter initial training, law enforcement can use our platform to help identify a potential criminal suspect by comparing an image law enforcement already has with images on our database. Oftentimes this comes from images that record a suspect in the course of the commission of a criminal act. This has included obtaining information on a suspect’s identity from pictures of sexual assault obtained by a law enforcement agency from online images of child sexual abuse material.\n\nCase Documentation\n\nBefore processing an image, law enforcement must provide information about the suspected crime and intended use. This information is saved for agency audits, and helps the agency’s command staff identify any potential misuse of our platform which would be grounds for preventing future use. After filling out an intake form, law enforcement can process an image through our platform, and our proprietary AI searches our database for a facial match.\n\nResults are returned with a link to where the image was found publicly-available online. Our platform does not provide personally identifying information like name, address or date of birth - only images and links to online sites where the images appear. It is up to the investigator to follow those links and do more research to find additional information to make an identification.\n\nIndustry-leading accuracy\n\nOur powerful algorithm’s performance meets the gold standard for facial recognition. Clearview AI’s algorithm can pick the correct person out of a lineup of 12 million photos, with a staggering 99.85 percent accuracy. This accuracy has been verified by third-party testing at the National Institute of Standards and Technology (NIST), and works with substantially equal effectiveness regardless of race, age, gender or other demographic features.\n\nBias-free policing\n\nIn the NIST 1:1 Face Recognition Vendor Test (\"FRVT\") that evaluates demographic accuracy, Clearview AI’s algorithm consistently achieved greater than 99 percent accuracy across all demographics.\n\nAccording to the Innocence Project, 70% of wrongful convictions result from eyewitness lineups. Accurate facial recognition technology like Clearview AI is able to help create a world of bias-free policing. As a person of mixed race this is highly important to me.\n\nFurthermore, the application of accurate, non-biased facial recognition technology can decrease the chance of the wrong person being apprehended. For example, it's much preferable to have law enforcement accurately identify someone, as opposed to looking for a general description, where wrongful detention, apprehension, and arrests are more likely, especially for those in black and brown communities.\n\nNo wrongful arrest\n\nAs I mentioned earlier, our commitment to accuracy means that we would rather return no matches than a false positive and our search result threshold is intentionally set to ensure that the chance of an individual being misidentified are small, and users cannot change this setting. To date, there has never been a reported wrongful arrest due to an agency using Clearview AI.\n\nHOW DO WE COLLECT INFORMATION FOR OUR DATABASE?\n\nOnly public information\n\nClearview AI’s image repository consists of public data that can be obtained by a typical Google search. The images in our database come from news media sites, mugshot websites, public social media, and other open sources. This means, if the content of your social media post is in private mode, then it won’t appear in Clearview AI search results.\n\nA larger dataset prevents bias\n\nClearview AI’s searches against billions of public images, which reduces potential bias and increases accuracy in several ways. First, the chance of an incorrect search result is lower when the dataset contains an accurate search result, which is more likely when a dataset is larger rather than smaller. Secondly, Clearview AI’s public online dataset reduces or eliminates demographic bias caused by selection effects.\n\nSearches of the public internet enable law enforcement to go beyond images of individuals in their area. Many crimes cross state or international borders (especially human, gun and drug trafficking, as well as online sexual exploitation of minors). Because of the breadth of our database, Clearview AI is the most effective facial recognition tool for law enforcement agencies who need to identify and locate potential suspects from outside their own jurisdiction.\n\n​​Every photo in the dataset is a potential clue that could save a life, provide justice to a victim, prevent a wrongful identification, or exonerate an innocent person.\n\nSOCIAL MEDIA PRIVACY\n\nClearview AI’s facial recognition search engine operates similarly to other search engines. The only social media images searched by Clearview AI are images that are available to the general public. When a user modifies his or her privacy settings to prevent the general online public and other search engines from viewing a particular image, he or she also restricts Clearview AI’s access.\n\nSTATE-OF-THE-ART DATA SECURITY\n\nClearview AI is committed to ensuring that our data is protected by the highest standards of data security. We have invested significant resources to provide our platform with world-class cybersecurity protection. Our platform is third-party certified as SOC 2 compliant for security, is subject to regular penetration tests, and features advanced data encryption, as well as intrusion detection. Look for a future blog on this topic!\n\nTHANK YOU\n\nWe are committed to ensuring that Clearview AI’s technology is used for good, and ensuring it does not fall into the wrong hands. We receive daily testimonials from our law enforcement customers sharing how Clearview AI has been able to solve crimes such as human trafficking, financial fraud and money laundering, and to protect the innocent.\n\nWe are open to regulation and we are honored to be at the center of the debate on privacy, safety and security. Thank you for taking the time to read about how our technology is used in practice, and how facial recognition can make the world a safer place.\n\n___\n\nHOAN TON-THAT\n\nCo-Founder & CEO, Clearview AI",
            "url": "https://www.clearview.ai/post/what-clearview-ai-has-implemented-to-ensure-that-facial-recognition-technology-is-used-responsibly",
            "authors": [],
            "publish_date": "2022-04-21T23:38:53.924000+00:00",
            "keywords": [
                "clearview",
                "public",
                "responsibly",
                "law",
                "technology",
                "used",
                "enforcement",
                "facial",
                "ais",
                "platform",
                "ai",
                "ensure",
                "implemented",
                "search",
                "recognition"
            ],
            "summary": "At Clearview AI, every decision we make is grounded in a commitment to ensuring that our technology is used ethically to make society safer.\nClearview AI’s facial recognition search engine is not a consumer application.\nWe encourage each customer to have a public facing Facial Recognition Policy, outlining the use cases, situations, and types of crimes for which they will use facial recognition.\nTraining protocolsEven though Clearview AI offers a simple, intuitive, and easy-to-use facial recognition platform , we provide training before any individual may access our software.\nAccurate facial recognition technology like Clearview AI is able to help create a world of bias-free policing.",
            "metadata": {
                "source_domain": "www.clearview.ai",
                "scrape_date": "2024-10-25T12:40:43.074611",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 10645
            }
        },
        {
            "title": "Clearview AI",
            "text": "OUR MISSION AI FOR PUBLIC SAFETY\n\nClearview AI’s mission is to create and deliver identification technology that helps combat crime and fraud, keep communities safe and industry and commerce secure, protect victims and promote justice.\n\n​\n\nWe aim to help protect the public through processes that are consistent with protecting fundamental freedoms and human rights. We have developed and applied best practices to all uses and every user of our identity solutions.\n\n​\n\n​\n\nWHAT DO WE DO & HOW DOES IT WORK?\n\nClearview AI acts as a search engine of publicly available images – now more than 50 billion -- to support investigative and identification processes by providing for highly accurate facial recognition across all demographic groups. Similar to other search engines, which pull and compile publicly available data from across the Internet into an easily searchable universe, Clearview AI compiles only publicly available images from across the Internet into a proprietary image database to be used in combination with Clearview AI's facial recognition technology. When a Clearview AI user uploads an image, Clearview AI’s proprietary technology processes the image and returns links to publicly available images that contain faces similar to the person pictured in the uploaded image.\n\n​\n\nClearview AI currently offers its solutions to only one category of customer – government agencies and their agents. It limits the uses of its system to agencies engaged in lawful investigative processes directed at criminal conduct, or at preventing specific, substantial, and imminent threats to people’s lives or physical safety. In each case, Clearview AI requires its government customers to make independent assessments of whether there is a match between the images retrieved by Clearview AI, and the image provided by the customer. Each decision about an identification is made by a professional working on behalf of a government agency, not by an automatic process.\n\nClearview AI’s facial recognition algorithm is designed to take into account age progression, variations in poses and positions, changes in facial hair, and many visual conditions and to perform at 99% [1] or better across all demographic groups on key tests.\n\n​\n\n​\n\nSTANDARDS & POLICIES\n\nClearview AI has developed required standards and best practices for the use of facial recognition technology which it applies to every use of its solutions. These include:\n\n​\n\nEnsuring Accuracy\n\nClearview AI only provides results for human review using the same algorithm and match threshold settings that achieved 99% or better accuracy on key tests [2]. Those results are then subject to non-automated human review and verification. In any case where an image does not reach a high level of probability of being a true positive, the image is excluded from the results and not provided to the customer for any use, except as needed to protect children from crimes by adults, as detailed in the section “Protecting Children.”\n\n​\n\nPreventing Discrimination\n\nClearview AI limits its results from its software solely to images which are retrieved using the same algorithm and match threshold settings which achieved 99% [3] or better accuracy for every demographic group on key tests, to make certain that Clearview AI’s data is provided without bias across all groups, regardless of age, gender, ethnic background, or race. While Clearview AI’s results exceed the standard of 99% [4] accuracy on key tests for some groups, it has adopted the identical requirement for accuracy for all of its results to ensure that no group is put at risk through a lesser standard for identification except as needed to protect children from crimes by adults, as detailed below in the section “Protecting Children.” In cases where the algorithm cannot identify an image that meets the same match threshold that achieved 99% [5] or better results on key tests, Clearview AI returns no results.\n\n​\n\nTesting & Validation\n\nClearview AI conducts regular testing and validation of its system through industry-standard testing by objective third parties. It used a system developed by an independent U.S. academic institution to test and validate its system to verify that it meets its promised standard for 99% [6] or better accuracy for adults across a demographically diverse test set. The initial testing and validation was followed by Clearview AI submitting its most recent image analysis algorithm to the National Institute for Standards and Technology, which also validated Clearview AI’s technology as achieving 99% or better accuracy on its test which measures facial recognition performance across demographic groups. [7]\n\n​\n\nProtecting Security\n\nClearview AI has put into place measures to guard against the risk of unauthorized access or use through a secure, cloud-based platform which houses its more than 50 billion facial images, relying on end-to-end encryption for the transmission of data, inbound and outbound, and designing systems that create a record to enable legal authorities as needed to reconstruct each use of Clearview AI’s system to help them undertake lawful investigations. Clearview AI stores all live data on servers in a secured data center with strict internal access controls. Clearview AI retains one or more independent external organizations to provide security assessments of its systems annually.\n\n​\n\nProtecting the Privacy of Data Subjects\n\nClearview AI limits the data it collects from the Internet to information that has been made available online to the general public. It requires each of its customers to adhere to all applicable data protection laws in their use of Clearview AI’s technology and its data. Clearview AI does not share client uploaded probe images with any other entity, and does not share images from the public internet with anyone other than government customers engaged in lawful investigations and public protection, except as required by law, such as providing access to data subjects to data pertaining to them, when applicable.\n\n​\n\nLimiting Uses to What’s Legal, Ethical, and in the Public Interest\n\nClearview AI licenses its technology only for limited and lawful purposes. These include helping government agencies identify criminals after a crime has taken place and providing lead information to help track down people engaged in illegal conduct such as child exploitation, terrorist activity, or to investigate other specific, substantial and imminent threats to people’s lives or physical safety. [8]\n\nProtecting Against Misidentification\n\nClearview AI’s system is hard coded to limit the return of false positives. It intentionally does not include match scoring or percentage matching with results. To limit the risk of a customer using the technology to identify the wrong person, Clearview AI’s system will return no results if the search falls below the 99% [9] threshold for accuracy, except as needed to protect children from crimes by adults, as detailed below in the section “Protecting Children.” Clearview AI requires that any possible match generated by the Clearview AI system be reviewed and assessed by a trained law enforcement agent to verify and validate the possible match, so that no identification of any person is based solely on automated results. Clearview AI also tests its system to detect and counter the risk of algorithmic biases with respect to race, gender, and age.\n\n​\n\nPreventing Abuse\n\nClearview AI imposes strict conditions on the use of its technology to limit its use to purposes that are both lawful and authorized. Clearview AI’s image database is cloud based, enabling it to halt the use of its technology by any customer who violates their obligations to use Clearview AI only for lawful and authorized purposes. Clearview AI will shut down the use of its technology by any customer, anywhere, as appropriate to investigate and to stop any abuse that may be identified, when Clearview AI is aware of such abuse.\n\n​\n\nEnsuring Accountability\n\nEvery use of Clearview AI enables the production of a unique, finished report, that contains all of the information used by its customer for an identification, as well as applicable metadata [10]. It also stores a search history containing the probe image, the purpose of the search and the identity of the searching user. Clearview AI thereby assures that this stored information can be made available by its customers to legal and judicial authorities, those charged with oversight to provide for accountability, and/or data subjects, as authorized by applicable law.\n\n​\n\nProtecting Human Rights\n\nFor every law enforcement use, Clearview AI has designed its system to require a lawful predicate. For example, a law enforcement agency must identify the specific category of crime under investigation after a crime has taken place prior to enabling a search of its database, or similar specified authority, such as an identification of a missing person. These controls make Clearview AI’s system for law enforcement generally usable only for post-event law enforcement. Clearview AI authorizes limited additional uses of its technology for governments to enable it to assist them in preventing specific, substantial and imminent threats to people’s lives or physical safety.\n\n​\n\nPROCEDURES TO PROTECT DATA SUBJECTS\n\nClearview AI requires all of its users to have in place processes and procedures to protect data subjects, so that its technology is only used for lawful and proper purposes consistent with the public good, and is not abused to threaten civil rights, civil liberties, and personal privacy. These procedures include:\n\n​\n\nProviding a Specific, Lawful Basis For Each Search Undertaken Using Clearview AI’s System\n\nIn the case of law enforcement investigations after a crime has taken place, Clearview AI requires the law enforcement agency to specify the particular crime(s) that are being investigated. In the case of specific, substantial and imminent threats to the public, Clearview AI requires the government agency to specify the lawful basis of the search and the reason immediate identification is needed to assist a person in carrying out lawful duties.\n\nRequiring the Preservation of Data & Metadata\n\nTo protect the rights of each person who is identified through a process that makes use of Clearview AI’s System, Clearview AI has developed a system to ensure that every search is documented to maintain the integrity of the search and the ability to assess that it was done properly and lawfully. Clearview AI preserves and reports the metadata accompanying every search, which provides the date of the search, the nature of the information used to initiate the search (such as an image or other information in the possession of the law enforcement agency), and other information helpful to ensuring the integrity of the search process and its lawfulness.\n\nRequiring Specialized Training to be Provided for All Users Authorized to Access Clearview AI’s System\n\nClearview AI does not make decisions that an image of a face is a particular person. It provides the results of a search of its database based on an image provided to Clearview AI by a law enforcement agency, and returns images which are produced using the same algorithm and match threshold which have achieved performance of 99% accuracy [11] or better on key tests. As part of the onboarding process, the law enforcement agency is required to have any personnel and agents who will be using Clearview AI’s technology and images participate in training programs before they are authorized to use the facial recognition system. In any use of Clearview AI’s system and database, a law enforcement agent must review the images and any relevant information in the possession of the government agency to determine whether there is a match, and to decide whether to undertake further investigative steps. Proposed matches must then go through a peer review process, so that a decision on whether there is an apparent match is subject to a further check by one or more persons in addition to the original agent. All of these steps are designed to protect the rights of the data subject, and to reduce the risk of mistakes.\n\nProhibiting Purely Automated Matching, Requiring Investigative Process for Each Match\n\nClearview AI does not license its system to law enforcement for purely automated matching. It requires that there always be a person exercising judgment before a match can be declared. Facial examiner training includes training in facial recognition system functions, interpreting results, best practices on public safety use of facial recognition technology, how to assess image quality and suitability for face recognition searches, proper and improper uses of image enhancement tools for image pre-processing, procedures and criteria for face image comparisons, candidate image comparison, annotation, background verification processes, and related processes and procedures, to promote accuracy and accountability.\n\n​\n\n​\n\nTESTING & VALIDATION\n\nClearview AI undertakes regular internal testing and validation of its system to ensure that its algorithm meets or exceeds the 99% [12] or better requirement for accuracy for all demographics when tested. Clearview AI’s technology currently meets this standard for all groups, regardless of age, gender, ethnic background, or race, for all persons 16 years or older.\n\n​\n\nIn the National Institute of Standards and Technology (NIST) 1:1 Face Recognition Vendor Test (\"FRVT\") that evaluates demographic accuracy, published on December 16th 2021, Clearview AI’s algorithm consistently achieved greater than 99 percent accuracy across all demographics.\n\nIn the National Institute of Standards and Technology (NIST) 1:N Face Recognition Vendor Test (\"FRVT\"), published on December 16th 2021, Clearview AI's algorithm correctly matched the correct face out of a lineup of 12 million photos at an accuracy rate of 99.85 percent, which is much more accurate than the human eye.\n\n​\n\nEstablished by Congress in 1901, the National Institute of Standards and Technology, a division of the U.S. Department of Commerce, provides the marketplace with accurate and reliable information about companies’ measurable industrial and technology performance capabilities.\n\nPROTECTING FUNDAMENTAL FREEDOMS\n\nClearview AI is committed to ensuring that its facial recognition system is used for the public good. Its proper uses include helping bring criminals to justice, stopping terrorists and child abusers from ongoing criminal conduct and protecting public safety while minimizing risks to individual privacy, civil rights, civil liberties, and other legally protected interests.\n\n​\n\nClearview AI’s general standards and the policies and the procedures it has put into place to protect data subjects are all intended to fulfill that commitment.\n\nIn every license, Clearview AI requires its government customers to limit their uses of Clearview AI technology to those that are consistent with rule of law and civil rights.\n\nOther requirements Clearview AI has put in place to protect human rights and fundamental freedoms include Clearview AI refusing to authorize the use of its technology to enable real-time use to enable government surveillance of any population or subgroup.\n\nClearview AI will suspend any customer from access to its technology, when it has concrete indicators of a potential abuse of its system. Clearview AI will undertake an investigation of any such indicator, and take appropriate action, including putting into place further restrictions on use, or terminating a customer to counter the risk of abuse.\n\n​\n\nPROTECTING CHILDREN\n\nChildren represent a special, and challenging, class for facial recognition purposes. Due to the facial changes that take place as a person matures, images of children are harder to identify with certainty as they age than are images of people who are 16 or older. Clearview AI also recognizes that privacy issues involving children are especially sensitive. Facial recognition technology should only be enabled for uses that protect children and never for any purpose that could harm any child.\n\n​\n\nClearview AI’s technology is a tool of unprecedented power in the fight against child sexual exploitation. Protecting children also means empowering law enforcement to deliver justice to victims and stem the torrent of online sexual abuse material.\n\n​\n\nAccordingly, Clearview AI’s technology is authorized only for use of images of persons under the age of 16 for the purposes of protecting the child's safety, victim identification, when the child’s welfare is at risk, in connection with investigations of violent felonies, and to help protect against the spread of CSAM, where legally authorized.\n\n​\n\nENSURING LEGALITY\n\nClearview AI only licenses its technology for use in jurisdictions where such use is lawful.\n\nClearview AI has designed its system to help achieve important public interests. The company adheres to applicable legal requirements in every aspect of its technology, from its acquisition and maintenance of images to its licensing of access to those images for facial identification for approved customers.\n\n​\n\nClearview AI’s technology is designed to be used in a responsible and proportionate manner, as well as to be consistent with all applicable laws. Clearview AI’s systems have controls built-in that are intended to reduce the risk of abuse of its technologies, and to enable the company to terminate any user who engages in an improper or otherwise unauthorized use of Clearview AI.",
            "url": "https://www.clearview.ai/principles",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "ais",
                "image",
                "facial",
                "data",
                "ai",
                "system",
                "clearview",
                "images",
                "search",
                "technology"
            ],
            "summary": "When a Clearview AI user uploads an image, Clearview AI’s proprietary technology processes the image and returns links to publicly available images that contain faces similar to the person pictured in the uploaded image.\nIn each case, Clearview AI requires its government customers to make independent assessments of whether there is a match between the images retrieved by Clearview AI, and the image provided by the customer.\nClearview AI will shut down the use of its technology by any customer, anywhere, as appropriate to investigate and to stop any abuse that may be identified, when Clearview AI is aware of such abuse.\nIn every license, Clearview AI requires its government customers to limit their uses of Clearview AI technology to those that are consistent with rule of law and civil rights.\nOther requirements Clearview AI has put in place to protect human rights and fundamental freedoms include Clearview AI refusing to authorize the use of its technology to enable real-time use to enable government surveillance of any population or subgroup.",
            "metadata": {
                "source_domain": "www.clearview.ai",
                "scrape_date": "2024-10-25T12:40:43.402373",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 17593
            }
        },
        {
            "title": "Australia’s privacy regulator just dropped its case against ‘troubling’ facial recognition company Clearview AI. Now what?",
            "text": "The office of the Australian Information Commissioner announced this week it would be taking no further action against facial recognition company Clearview AI. This marked a significant victory for one of the most controversial technology companies in the world.\n\nIn 2021, Australia’s privacy regulator ruled Clearview AI broke privacy laws for scraping millions of photographs from social media sites such as Facebook and using them to train its facial recognition tool. It ordered the company to stop collecting images and delete the ones it had already had.\n\nHowever, there was no evidence Clearview AI followed this order. And earlier this year, media reports suggested the company was still going about its business as usual in Australia and collecting more images of citizens.\n\nGiven this, why did the privacy regulator suddenly stop pursuing Clearview AI? What does this mean for the broader fight to protect peoples’ privacy in the age of big tech? And how might the law be changed to give the regulator a greater chance at reining in companies like Clearview AI?\n\nA long-running fight\n\nClearview AI is a facial recognition tool trained on more than 50 billion photographs scraped from social media websites such as Facebook and Twitter, as well as the wider web in general.\n\nThe company behind it was established in 2017 by an Australian citizen, Hoan Ton-That, who is now based in the United States. The site claims the tool is 99% accurate in identifying the individual in any given photo.\n\nEarlier this month, Ton-That told Inc.Australia he expects the company’s growth in the United States to rapidly accelerate.\n\nThere will be more of these bigger enterprise deals, especially with the federal government. Plus, there are 18,000 state and local agencies in law enforcement and government alone. This could be a billion-plus or two billion dollar annual recurring revenue company.\n\nThe tool was initially offered to police authorities for trial in countries such as the US, United Kingdom and Australia. War-torn Ukraine also used Clearview AI to recognise Russian soldiers who participated in the invasion to Ukraine.\n\nBut the technology quickly sparked controversy – and legal pushback.\n\nIn 2022, the UK privacy watchdog fined Cleaview AI A$14.5 million for violating its privacy laws. However, the decision was later overruled, because UK authorities did not have authority to issue fines to a foreign company.\n\nFrance, Italy, Greece and other countries in the European Union also each issued Clearview AI with $33 million or larger fines. They imposed further penalties when the company did not comply with legal orders.\n\nIn the US, the company faced a class action, which was settled in June. The settlement allowed it to continue selling this tool to US law enforcement agencies but not to the private sector.\n\nIn Australia, the privacy regulator ruled in 2021 that Clearview AI violated the country’s privacy laws by collecting images of Australians without their consent. It ordered the company to cease collecting the images and delete the collected ones within 90 days. However, it did not issue a fine.\n\nSo far, there is no evidence Clearview AI complied with the the office of the Australian Information Commissioner’s order and it is reportedly still collecting images of Australians.\n\nA lack of enforcement power – and resources\n\nYesterday Privacy commissioner Carly Kind described the practices of Clearview AI as “troubling”. However she also said:\n\nConsidering all the relevant factors, I am not satisfied that further action is warranted in the particular case of Clearview AI at this time.\n\nThis is a disappointing decision.\n\nUnder the Privacy Act, when an organisation does not comply with a decision, the regulator can commence enforcement proceedings in court. However, in this case it chose not to do so.\n\nThe lack of further action against Clearview AI confirms the weakness of current privacy laws in Australia. In contrast to other countries, significant penalties for breach of privacy laws in Australia are very rare.\n\nThe decision also underscores the regulator’s lack of enforcement powers under current privacy laws.\n\nCompounding this is the lack of resources at the regulator’s disposal to investigate multiple large cases. Its investigation into Bunnings and Kmart for their use of facial recognition technology has been pending for more than two years.\n\nWhat can be done?\n\nThere is some hope the forthcoming privacy law reforms in Australia will both strengthen the Australian privacy law and provide more enforcement powers to the privacy regulator.\n\nHowever, it is questionable whether general privacy law will be sufficient to adequately regulate facial recognition technologies.\n\nAustralian experts have instead called for special rules for high risk technologies. For example, former Australian human rights commissioner Ed Santow has proposed a model law to regulate facial recognition technologies.\n\nOther countries have already started developing special rules for facial recognition tools. The recently adopted Artificial Intelligence Act in the European Union prohibits certain uses of this technology, and sets strict rules around its development.\n\nHowever, research shows many countries around the world are still struggling to establish appropriate regulations for facial recognition systems.\n\nThe Australian government should seriously consider specific actions to both prevent companies such as Clearview AI from using personal data of Australians for the development of such technologies – and introduce clear rules about when facial recognition can be used, and when it cannot.",
            "url": "https://theconversation.com/australias-privacy-regulator-just-dropped-its-case-against-troubling-facial-recognition-company-clearview-ai-now-what-237231",
            "authors": [
                "Rita Matulionyte"
            ],
            "publish_date": "2024-08-22T02:02:54+00:00",
            "keywords": [
                "recognition",
                "law",
                "case",
                "company",
                "australias",
                "enforcement",
                "australian",
                "ai",
                "privacy",
                "australia",
                "dropped",
                "clearview",
                "troubling",
                "regulator",
                "facial"
            ],
            "summary": "The office of the Australian Information Commissioner announced this week it would be taking no further action against facial recognition company Clearview AI.\nIn 2021, Australia’s privacy regulator ruled Clearview AI broke privacy laws for scraping millions of photographs from social media sites such as Facebook and using them to train its facial recognition tool.\nAnd how might the law be changed to give the regulator a greater chance at reining in companies like Clearview AI?\nThere is some hope the forthcoming privacy law reforms in Australia will both strengthen the Australian privacy law and provide more enforcement powers to the privacy regulator.\nHowever, research shows many countries around the world are still struggling to establish appropriate regulations for facial recognition systems.",
            "metadata": {
                "source_domain": "theconversation.com",
                "scrape_date": "2024-10-25T12:40:43.924859",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 5641
            }
        },
        {
            "title": "Clearview AI faces the biggest GDPR fine given in Europe",
            "text": "{\"text\": \"The Netherlands' data protection authority (AP) announced that it had fined Clearview AI EUR 30.5 million for multiple violations of the European Union's General Data Protection Regulation (GDPR). This penalty was imposed after it was confirmed that Clearview AI's database contains images of Dutch citizens.\\nThe Dutch data protection authority began investigating Clearview AI in March 2023 after receiving complaints related to the company's failure to comply with data access requests. Clearview AI is being sanctioned for GDPR violations, including collecting biometric data without a valid legal basis and transparency failings.\\nThe fine imposed on Clearview AI is higher than the GDPR sanctions faced by data protection authorities in France, Italy, Greece, and the UK in 2022. In a press release, the AP warned that it has ordered an additional penalty of up to EUR 5.1 million for continued non-compliance. Clearview failed to stop the GDPR violations after the investigation concluded, which is why an additional order has been made. The total fine could reach EUR 35.6 million if Clearview AI continues to ignore the Netherlands regulator.\\nClearview representatives stated that the company does not have a business location in the Netherlands or the EU, has no customers in the Netherlands or the EU, and does not engage in any activities that would make it subject to the GDPR, and that the decision is unlawful, lacks due process, and is unenforceable.\\nHowever, the Dutch regulator declared that the company cannot appeal the penalty as it did not object to the decision by the authority and that GDPR applies extraterritorially, meaning it covers the processing of personal data of EU citizens regardless of location.\\nUS-based Clearview uses scraped data to provide identity-matching services to clients, including government agencies, law enforcement, and security services. However, its EU clients are decreasing due to the risk of regulatory sanctions, as seen with a Swedish police authority in 2021.\\nEvery day we send out a free e-mail with the most important headlines of the last 24 hours.\\nSubscribe now\"}",
            "url": "https://thepaypers.com/digital-identity-security-online-fraud/clearview-ai-faces-the-biggest-gdpr-fine-given-in-europe--1269969",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "gdpr",
                "fine",
                "faces",
                "europe",
                "ai",
                "given",
                "clearview",
                "biggest"
            ],
            "summary": "",
            "metadata": {
                "source_domain": "thepaypers.com",
                "scrape_date": "2024-10-25T12:40:42.567156",
                "content_type": "other",
                "extraction_method": "trafilatura",
                "content_length": 0
            }
        },
        {
            "title": "Announcement: Clearview AI Ordered to Comply with Alberta’s Privacy Law",
            "text": "The Office of the Information and Privacy Commissioner of Alberta (OIPC AB) issued an order to Clearview AI.\n\nThe order requires Clearview to:\n\nCease offering all of the facial recognition services that have been the subject of this investigation to clients in Alberta\n\nCease the collection, use and disclosure of images and biometric facial arrays collected from individuals in Alberta\n\nDelete images and biometric facial arrays that have been collected from individuals in Alberta and that are in its possession\n\nClearview has 50 days to report to the Commissioner on the good faith steps that it has taken to comply with this order. The order may be subject to judicial review.\n\nThe order was issued under the Personal Information Protection Act, Alberta’s private sector privacy law.\n\nThe order follows Clearview’s refusal to implement recommendations made in a February 2021 investigation report issued by the Office of the Privacy Commissioner of Canada, Commission d’accès à l’information du Québec, Office of the Information and Privacy Commissioner for British Columbia and OIPC AB.\n\nThe OIPC will not comment on the order. The order speaks for itself.",
            "url": "https://oipc.ab.ca/clearview-ai-order/",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "announcement",
                "law",
                "comply",
                "commissioner",
                "order",
                "albertas",
                "issued",
                "subject",
                "facial",
                "oipc",
                "information",
                "report",
                "privacy",
                "ordered",
                "clearview",
                "office",
                "ai"
            ],
            "summary": "The Office of the Information and Privacy Commissioner of Alberta (OIPC AB) issued an order to Clearview AI.\nThe order may be subject to judicial review.\nThe order was issued under the Personal Information Protection Act, Alberta’s private sector privacy law.\nThe order follows Clearview’s refusal to implement recommendations made in a February 2021 investigation report issued by the Office of the Privacy Commissioner of Canada, Commission d’accès à l’information du Québec, Office of the Information and Privacy Commissioner for British Columbia and OIPC AB.\nThe OIPC will not comment on the order.",
            "metadata": {
                "source_domain": "oipc.ab.ca",
                "scrape_date": "2024-10-25T12:40:44.444555",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 1161
            }
        },
        {
            "title": "Australia’s privacy regulator just dropped its case against ‘troubling’ facial recognition company Clearview AI. Now what?",
            "text": "The office of the Australian Information Commissioner announced this week it would be taking no further action against facial recognition company Clearview AI. This marked a significant victory for one of the most controversial technology companies in the world.\n\nIn 2021, Australia’s privacy regulator ruled Clearview AI broke privacy laws for scraping millions of photographs from social media sites such as Facebook and using them to train its facial recognition tool. It ordered the company to stop collecting images and delete the ones it had already had.\n\nHowever, there was no evidence Clearview AI followed this order. And earlier this year, media reports suggested the company was still going about its business as usual in Australia and collecting more images of citizens.\n\nGiven this, why did the privacy regulator suddenly stop pursuing Clearview AI? What does this mean for the broader fight to protect peoples’ privacy in the age of big tech? And how might the law be changed to give the regulator a greater chance at reining in companies like Clearview AI?\n\nA long-running fight\n\nClearview AI is a facial recognition tool trained on more than 50 billion photographs scraped from social media websites such as Facebook and Twitter, as well as the wider web in general.\n\nThe company behind it was established in 2017 by an Australian citizen, Hoan Ton-That, who is now based in the United States. The site claims the tool is 99% accurate in identifying the individual in any given photo.\n\nEarlier this month, Ton-That told Inc.Australia he expects the company’s growth in the United States to rapidly accelerate.\n\nThere will be more of these bigger enterprise deals, especially with the federal government. Plus, there are 18,000 state and local agencies in law enforcement and government alone. This could be a billion-plus or two billion dollar annual recurring revenue company.\n\nThe tool was initially offered to police authorities for trial in countries such as the US, United Kingdom and Australia. War-torn Ukraine also used Clearview AI to recognise Russian soldiers who participated in the invasion to Ukraine.\n\nBut the technology quickly sparked controversy – and legal pushback.\n\nIn 2022, the UK privacy watchdog fined Cleaview AI A$14.5 million for violating its privacy laws. However, the decision was later overruled, because UK authorities did not have authority to issue fines to a foreign company.\n\nFrance, Italy, Greece and other countries in the European Union also each issued Clearview AI with $33 million or larger fines. They imposed further penalties when the company did not comply with legal orders.\n\nIn the US, the company faced a class action, which was settled in June. The settlement allowed it to continue selling this tool to US law enforcement agencies but not to the private sector.\n\nIn Australia, the privacy regulator ruled in 2021 that Clearview AI violated the country’s privacy laws by collecting images of Australians without their consent. It ordered the company to cease collecting the images and delete the collected ones within 90 days. However, it did not issue a fine.\n\nSo far, there is no evidence Clearview AI complied with the the office of the Australian Information Commissioner’s order and it is reportedly still collecting images of Australians.\n\nA lack of enforcement power – and resources\n\nYesterday Privacy commissioner Carly Kind described the practices of Clearview AI as “troubling”. However she also said:\n\nConsidering all the relevant factors, I am not satisfied that further action is warranted in the particular case of Clearview AI at this time.\n\nThis is a disappointing decision.\n\nUnder the Privacy Act, when an organisation does not comply with a decision, the regulator can commence enforcement proceedings in court. However, in this case it chose not to do so.\n\nThe lack of further action against Clearview AI confirms the weakness of current privacy laws in Australia. In contrast to other countries, significant penalties for breach of privacy laws in Australia are very rare.\n\nThe decision also underscores the regulator’s lack of enforcement powers under current privacy laws.\n\nCompounding this is the lack of resources at the regulator’s disposal to investigate multiple large cases. Its investigation into Bunnings and Kmart for their use of facial recognition technology has been pending for more than two years.\n\nWhat can be done?\n\nThere is some hope the forthcoming privacy law reforms in Australia will both strengthen the Australian privacy law and provide more enforcement powers to the privacy regulator.\n\nHowever, it is questionable whether general privacy law will be sufficient to adequately regulate facial recognition technologies.\n\nAustralian experts have instead called for special rules for high risk technologies. For example, former Australian human rights commissioner Ed Santow has proposed a model law to regulate facial recognition technologies.\n\nOther countries have already started developing special rules for facial recognition tools. The recently adopted Artificial Intelligence Act in the European Union prohibits certain uses of this technology, and sets strict rules around its development.\n\nHowever, research shows many countries around the world are still struggling to establish appropriate regulations for facial recognition systems.\n\nThe Australian government should seriously consider specific actions to both prevent companies such as Clearview AI from using personal data of Australians for the development of such technologies – and introduce clear rules about when facial recognition can be used, and when it cannot.",
            "url": "https://theconversation.com/australias-privacy-regulator-just-dropped-its-case-against-troubling-facial-recognition-company-clearview-ai-now-what-237231#:~:text=In%20Australia%2C%20the%20privacy%20regulator,did%20not%20issue%20a%20fine.",
            "authors": [
                "Rita Matulionyte"
            ],
            "publish_date": "2024-08-22T02:02:54+00:00",
            "keywords": [
                "recognition",
                "law",
                "case",
                "company",
                "australias",
                "enforcement",
                "australian",
                "ai",
                "privacy",
                "australia",
                "dropped",
                "clearview",
                "troubling",
                "regulator",
                "facial"
            ],
            "summary": "The office of the Australian Information Commissioner announced this week it would be taking no further action against facial recognition company Clearview AI.\nIn 2021, Australia’s privacy regulator ruled Clearview AI broke privacy laws for scraping millions of photographs from social media sites such as Facebook and using them to train its facial recognition tool.\nAnd how might the law be changed to give the regulator a greater chance at reining in companies like Clearview AI?\nThere is some hope the forthcoming privacy law reforms in Australia will both strengthen the Australian privacy law and provide more enforcement powers to the privacy regulator.\nHowever, research shows many countries around the world are still struggling to establish appropriate regulations for facial recognition systems.",
            "metadata": {
                "source_domain": "theconversation.com",
                "scrape_date": "2024-10-25T12:40:45.137164",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 5641
            }
        },
        {
            "title": "Clearview AI surveillance \"criticism\"",
            "text": "{\"text\": \"Use of the facial recognition tool has been controversial. Several U.S. senators have expressed concern about privacy rights and the American Civil Liberties Union (ACLU) has sued the company for violating privacy laws on several occasions. U.S. police have used the software to apprehend suspected criminals.\\nPeople also ask\\nHow accurate is Clearview AI facial recognition?\\nWhat are the privacy issues with AI surveillance?\\nWhat happened to Clearview AI?\\nCan you opt out of Clearview AI?\\nFeb 14, 2020 � As the company confronts mounting criticism over its disturbing surveillance practices, its chief executive, Hoan Ton-That, is rolling out�...\\nMay 27, 2022 � But Clearview has faced other intense criticism, too. Advocates for responsible uses of AI say that facial recognition technology often�...\\nThere has been warranted backlash and criticism of this work, because it's all about predicting attributes that are not visually discernible. Benefits of Facial�...\\nSep 28, 2023 � And that criticism was heard by the facial recognition technology industry, and they have improved these system. They have gotten more�...\\nJun 14, 2021 � ... criticism that the firm's controversial technology infringes on the privacy of hundreds of millions. ... How Clearview AI surveillance works.\\nFeb 16, 2022 � Clearview has dismissed criticism of its data collection and surveillance work by saying it is built exclusively for law enforcement and the�...\\nFeb 15, 2023 � Facial recognition tech draws new criticism amid MSG controversy � 'Automating the bias' � Cost concerns � Political action.\\nMar 6, 2020 � In response to the criticism, Clearview published a “code of conduct,” emphasizing in a blog post that its technology was “available only�...\\nThe extent of investigations and the timeliness of dealing with complaints have both been areas of criticism. For example, in 2020, a group of cross-party�...\"}",
            "url": "https://www.google.com/search?sca_esv=98f1e80d24ca1b54&q=Clearview+AI+surveillance+%22criticism%22&sa=X&ved=2ahUKEwjc0_TY16iJAxX_FVkFHRotMzQQ5t4CegQIFRAB",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "privacy",
                "surveillance",
                "software",
                "criticism",
                "used",
                "sued",
                "violating",
                "rights",
                "union",
                "ai",
                "tool",
                "senators",
                "clearview",
                "suspected"
            ],
            "summary": "Use of the facial recognition tool has been controversial .\nSeveral U.S. senators have expressed concern about privacy rights and the American Civil Liberties Union (ACLU) has sued the company for violating privacy laws on several occasions.\nU.S. police have used the software to apprehend suspected criminals.",
            "metadata": {
                "source_domain": "www.google.com",
                "scrape_date": "2024-10-25T12:40:45.233529",
                "content_type": "other",
                "extraction_method": "trafilatura",
                "content_length": 310
            }
        },
        {
            "title": "PRIVACY & REQUESTS",
            "text": "LEGAL RESOURCES\n\nPrivacy We will not sell advertisements in our product. We o nly collect publicly available images and data.\n\nFor California Residents: Click below to Access My Information, Delete My Information, Do Not Sell/Share My Information, Correct My Information, or Limit Use and Disclosure of Sensitive Personal Information.\n\nFor Colorado Residents: Click below to Access My Information, Delete/Opt-Out My Information, Do Not Sell My Information, Correct My Information, Opt-Out of Profiling, or Appeal My Denied Request.\n\nFor Connecticut Residents: Click below to Access My Information, Delete/Opt-Out My Information, Do Not Sell My Information, Correct My Information, Opt-Out of Profiling, or Appeal My Denied Request.\n\nFor Illinois Residents: Clearview AI provides an automated webfo rm for Illinois residents to opt-out of appearing in Clearview AI search results at the link below.\n\nFor Montana Residents: Click below to Access My Information, Delete/Opt-Out My Information, Do Not Sell My Information, Correct My Information, Opt-Out of Profiling, or Appeal My Denied Request.\n\nFor Oregon Residents: Click below to Access My Information, Delete/Opt-Out My Information, Do Not Sell My Information, Correct My Information, Opt-Out of Profiling, or Appeal My Denied Request.\n\nFor Utah Residents: Click below to Access My Information, Delete/Opt-Out My Information, or Do Not Sell My Information.\n\nFor Virginia Residents: Click below to Access My Information, Delete My Information, Do Not Sell My Information, Correct My Information, Opt-Out of Targeted Advertising, Opt-Out of Profiling, or Appeal My Denied Request.",
            "url": "https://www.clearview.ai/privacy-and-requests",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "sell",
                "information",
                "click",
                "deleteoptout",
                "requests",
                "residents",
                "privacy",
                "profiling",
                "optout",
                "access",
                "correct",
                "denied"
            ],
            "summary": "For California Residents: Click below to Access My Information, Delete My Information, Do Not Sell/Share My Information, Correct My Information, or Limit Use and Disclosure of Sensitive Personal Information.\nFor Colorado Residents: Click below to Access My Information, Delete/Opt-Out My Information, Do Not Sell My Information, Correct My Information, Opt-Out of Profiling, or Appeal My Denied Request.\nFor Connecticut Residents: Click below to Access My Information, Delete/Opt-Out My Information, Do Not Sell My Information, Correct My Information, Opt-Out of Profiling, or Appeal My Denied Request.\nFor Montana Residents: Click below to Access My Information, Delete/Opt-Out My Information, Do Not Sell My Information, Correct My Information, Opt-Out of Profiling, or Appeal My Denied Request.\nFor Utah Residents: Click below to Access My Information, Delete/Opt-Out My Information, or Do Not Sell My Information.",
            "metadata": {
                "source_domain": "www.clearview.ai",
                "scrape_date": "2024-10-25T12:40:46.214028",
                "content_type": "other",
                "extraction_method": "newspaper3k",
                "content_length": 1631
            }
        }
    ]
}