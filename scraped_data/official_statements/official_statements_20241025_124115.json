{
    "total_articles": 14,
    "articles": [
        {
            "title": "Announcement: Clearview AI ordered to comply with recommendations to stop collecting, sharing images",
            "text": "Clearview AI ordered to comply with recommendations to stop collecting, sharing images\n\nDecember 14, 2021\n\nThree provincial privacy protection authorities have ordered facial recognition company Clearview AI to comply with recommendations flowing from a joint investigation with the Office of the Privacy Commissioner of Canada.\n\nU.S. -based Clearview AI created and maintains a database of more than three billion images scraped from the internet without people’s consent. Clearview clients, which previously included the RCMP , are able to match photographs of people against the images in the databank using facial recognition technology.\n\nIn July 2020, Clearview advised Canadian privacy protection authorities that, in response to their joint investigation, it would cease offering its facial recognition services in Canada.\n\nThe joint investigation by the Office of the Privacy Commissioner of Canada and its counterparts – the Commission d’accès à l’information du Québec, the Information and Privacy Commissioner for British Columbia and the Information and Privacy Commissioner of Alberta – found that Clearview violated federal and provincial private-sector privacy laws by scraping images from the internet without permission.\n\nThe legally binding provincial orders require Clearview to:\n\nStop offering its facial recognition services that have been the subject of the investigation in the three provinces;\n\nStop collecting, using and disclosing images of people in the three provinces without consent; and\n\nDelete images and biometric facial arrays collected without consent from individuals in the three provinces.\n\n“We welcome these important actions taken by our provincial counterparts. While Clearview stopped offering its services in Canada during the investigation, it had refused to cease the collection and use of Canadians’ data or delete images already collected,” says Privacy Commissioner of Canada Daniel Therrien.\n\n“These orders also highlight once again significant shortcomings with the federal private sector privacy law. The Office of the Privacy Commissioner of Canada does not have order-making powers under the Personal Information Protection and Electronic Documents Act ( PIPEDA ).”\n\nThe OPC has called for amendments to PIPEDA to provide for quick and effective enforcement mechanisms. In many countries, this has been enabled through granting powers to the regulator to issue orders and impose significant monetary penalties.\n\nCommissioner Therrien noted that recent amendments to Quebec’s privacy law and proposals for legislative reform in British Columbia and Ontario provide for greater authority to impose meaningful penalties and create strong incentives for businesses to comply with the law.\n\nThese changes would confer to provincial counterparts the authority to make orders- to issue financial penalties directly, subject to judicial review.\n\n“All Canadians should have equal access to the same quick and effective corrective action when their privacy rights are violated,” says Commissioner Therrien.\n\nThe Information Commissioner’s Office in the U.K. recently announced its “provisional intent” to fine Clearview £17 million (approximately $29 million CDN ) and order it to delete any data it held on U.K. citizens. The announcement follows a joint investigation by the ICO and the Office of the Australian Information Commissioner, which found that Clearview had violated privacy laws in both jurisdictions.\n\nRelated documents",
            "url": "https://www.priv.gc.ca/en/opc-news/news-and-announcements/2021/an_211214/",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "announcement",
                "privacy",
                "provincial",
                "comply",
                "recognition",
                "commissioner",
                "investigation",
                "facial",
                "information",
                "ordered",
                "ai",
                "stop",
                "sharing",
                "recommendations",
                "clearview",
                "images",
                "office",
                "collecting"
            ],
            "summary": "Clearview AI ordered to comply with recommendations to stop collecting, sharing imagesDecember 14, 2021Three provincial privacy protection authorities have ordered facial recognition company Clearview AI to comply with recommendations flowing from a joint investigation with the Office of the Privacy Commissioner of Canada.\nU.S. -based Clearview AI created and maintains a database of more than three billion images scraped from the internet without people’s consent.\nClearview clients, which previously included the RCMP , are able to match photographs of people against the images in the databank using facial recognition technology.\nIn July 2020, Clearview advised Canadian privacy protection authorities that, in response to their joint investigation, it would cease offering its facial recognition services in Canada.\nThe announcement follows a joint investigation by the ICO and the Office of the Australian Information Commissioner, which found that Clearview had violated privacy laws in both jurisdictions.",
            "metadata": {
                "source_domain": "www.priv.gc.ca",
                "scrape_date": "2024-10-25T12:40:23.381787",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 3477
            }
        },
        {
            "title": "Statement by the Privacy Commissioner of Canada following an investigation into the RCMP’s use of Clearview AI",
            "text": "June 10, 2021\n\nBy teleconference\n\nPrivacy Commissioner of Canada Daniel Therrien issued the following statement at a media teleconference.\n\n(Check against delivery)\n\nGood morning.\n\nThe Special Report on my office’s investigation into the RCMP ’s use of Clearview AI’s facial recognition technology has been tabled in Parliament.\n\nOur report of findings tells the second part of a story that began earlier this year, when we released the results of an investigation into the practices of Clearview itself.\n\nClearview AI created a databank of more than three billion images scraped from internet websites without users’ consent. Clients of the service, such as the RCMP , could match photographs of people against the photographs in the databank.\n\nBack in February, we and our counterparts in Quebec, Alberta and B.C. found Clearview’s practices to be mass surveillance and illegal under federal and provincial private sector privacy laws.\n\nNow, our most recent investigation has concluded that the RCMP contravened the federal public sector law, the Privacy Act, when it collected information from Clearview. In our view, a government institution simply cannot collect personal information from a third party agent if that third party’s collection was unlawful in the first place.\n\nOur investigation highlighted other concerns.\n\nNotably, we found there were serious and systemic gaps in the RCMP ’s policies and systems to track, identify, assess and control novel collections of personal information through new technologies.\n\nPolice use of facial recognition technologies, with its power to disrupt anonymity in public spaces, and enable mass surveillance, raises the potential for serious privacy harms unless appropriate privacy protections are in place.\n\nCanadians must be free to participate in the increasingly digital, day-to-day activities of a modern society without the risk of their activities being routinely identified, tracked and monitored.\n\nWhile certain intrusions on this right can be justified in specific circumstances, individuals do not forego their right to privacy merely by living and moving in the world in ways that may reveal their face to others, or that may enable their image to be captured on camera.\n\nToday, my office, along with our provincial and territorial counterparts, are launching a consultation on draft guidance to help police ensure any use of facial recognition technology complies with current laws and minimizes privacy risks. We will be consulting police, civil society and other stakeholders on the content of the guidance before it is finalized.\n\nWe also believe that it is necessary to carefully consider issues related to facial recognition technology as Canada looks to modernize federal privacy laws.\n\nCurrently, the use of this technology is regulated through a patchwork of statutes and case law that, for the most part, do not specifically address the risks posed by the technology. This creates room for uncertainty concerning what uses of facial recognition may be acceptable, and under what circumstances.\n\nThe nature of the risks posed by FRT calls for collective reflection on the limits of acceptable use of the technology.\n\nFor instance, our Clearview AI and RCMP investigations underscore a key gap that we see more and more frequently when our federal privacy laws apply to public-private partnerships.\n\nIn the RCMP investigation, we found the onus was on the police force to ensure the database it was using was compiled legally. However, the RCMP has argued doing so would create an unreasonable obligation and that the law does not expressly impose such a duty. That being said, we appreciate the RCMP is now committing to implement our recommendations, notwithstanding this fundamental disagreement.\n\nCommon privacy principles enshrined in both our public and private sector privacy laws would help address gaps in accountability where the sectors interact.\n\nTo that end, our submissions regarding Bill C-11 (in the privacy sector) and the Department of Justice consultation on the Privacy Act (in the public sector) propose that our federal privacy laws should share a rights-based foundation. They should also include the privacy principles of necessity and proportionality to ensure that practices that could be privacy invasive are carried out for a sufficiently important objective, and that they are narrowly tailored so as not to intrude on privacy rights more than is necessary.\n\nFurthermore, our laws should clarify that the concept of publicly available personal information (public information), which allows for some exceptions within privacy legislation, does not apply to information where an individual has a reasonable expectation of privacy. This is particularly critical in the case of facial recognition technology, which relies on massive databases of images that Canadians do not always consider public.\n\nI would be happy to answer any questions you have about our investigative findings, our draft guidance for police or our proposals for legislative reform.\n\nRelated content:",
            "url": "https://www.priv.gc.ca/en/opc-news/speeches/2021/s-d_20210610/",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "rcmps",
                "recognition",
                "public",
                "commissioner",
                "statement",
                "canada",
                "technology",
                "investigation",
                "facial",
                "information",
                "laws",
                "sector",
                "following",
                "privacy",
                "rcmp",
                "clearview",
                "ai"
            ],
            "summary": "The Special Report on my office’s investigation into the RCMP ’s use of Clearview AI’s facial recognition technology has been tabled in Parliament.\nfound Clearview’s practices to be mass surveillance and illegal under federal and provincial private sector privacy laws.\nWe also believe that it is necessary to carefully consider issues related to facial recognition technology as Canada looks to modernize federal privacy laws.\nIn the RCMP investigation, we found the onus was on the police force to ensure the database it was using was compiled legally.\nCommon privacy principles enshrined in both our public and private sector privacy laws would help address gaps in accountability where the sectors interact.",
            "metadata": {
                "source_domain": "www.priv.gc.ca",
                "scrape_date": "2024-10-25T12:40:23.850384",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 5068
            }
        },
        {
            "title": "The French SA fines Clearview AI EUR 20 million",
            "text": "Background information\n\nDate of final decision: 19 October 2022\n\nCross-border case or national case: National case\n\nController: Clearview AI\n\nLegal Reference: Lawfulness of processing of personal data (article 6 of the GDPR), Rights of individuals (articles 12, 15 and 17 of the GDPR), Cooperation with supervisory authority (article 31 of the GDPR)\n\nDecision: Infringement of the GDPR, Administrative fine, Order to comply with periodic penalty payments\n\nKey words: Facial recognition\n\nSummary of the Decision\n\nOrigin of the case\n\nAs of May 2020, the Commission nationale de l'informatique et des libertés, CNIL received complaints from individuals about Clearview AI's facial recognition software and opened an investigation. In May 2021, the association Privacy International also warned the CNIL about this practice.\n\nOn 26 November 2021, the Chair of the CNIL decided to give Clearview AI formal notice to cease the collection and use of data of persons on French territory in the absence of a legal basis to to facilitate the exercise of individuals' rights and to comply with their requests for erasure. Clearview AI had two months to comply with the injunctions formulated in the formal notice and to justify them to the CNIL. However, it did not provide any response to this formal notice.\n\nThe Chair of the CNIL therefore decided to refer the matter to the restricted committee, which is in charge for issuing sanctions.\n\nKey Findings\n\nUnlawful processing of personal data (breach of article 6 of the GDPR)\n\nIndividuals' rights not respected (articles 12, 15 and 17 of the GDPR)\n\nLack of cooperation with the CNIL (Article 31 of the RGPD)\n\nDecision\n\nOn the basis of the information brought to its attention, the restricted committee decided to impose a maximum financial penalty of 20 million euros, according to article 83 of the GDPR.\n\nRegarding the very serious risks to the fundamental rights of the data subjects resulting from the processing carried out by the company, the restricted committee decided to order Clearview AI to stop collecting and processing data of individuals residing in France without a legal basis and to delete the data of these persons that it has already collected, within a period of two months. The restricted committee added to this injunction a penalty of 100,000 euros per day of delay beyond these two months.\n\nFor further information: national news Reconnaissance faciale : sanction de 20 millions d’euros à l’encontre de CLEARVIEW AI (FR), Facial recognition: 20 million euros penalty against CLEARVIEW AI (EN).",
            "url": "https://www.edpb.europa.eu/news/national-news/2022/french-sa-fines-clearview-ai-eur-20-million_en",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "fines",
                "20",
                "cnil",
                "article",
                "individuals",
                "french",
                "eur",
                "data",
                "rights",
                "penalty",
                "restricted",
                "ai",
                "million",
                "processing",
                "clearview"
            ],
            "summary": "In May 2021, the association Privacy International also warned the CNIL about this practice.\nClearview AI had two months to comply with the injunctions formulated in the formal notice and to justify them to the CNIL.\nThe Chair of the CNIL therefore decided to refer the matter to the restricted committee, which is in charge for issuing sanctions.\nThe restricted committee added to this injunction a penalty of 100,000 euros per day of delay beyond these two months.\nFor further information: national news Reconnaissance faciale : sanction de 20 millions d’euros à l’encontre de CLEARVIEW AI (FR), Facial recognition: 20 million euros penalty against CLEARVIEW AI (EN).",
            "metadata": {
                "source_domain": "www.edpb.europa.eu",
                "scrape_date": "2024-10-25T12:40:23.992352",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 2560
            }
        },
        {
            "title": "Clearview AI",
            "text": "American facial recognition software company\n\nClearview AI, Inc. is an American facial recognition company, providing software primarily to law enforcement and other government agencies.[2] The company's algorithm matches faces to a database of more than 20 billion images collected from the Internet, including social media applications.[1] Founded by Hoan Ton-That and Richard Schwartz, the company maintained a low profile until late 2019, until its usage by law enforcement was first reported.[3]\n\nUse of the facial recognition tool has been controversial. Several U.S. senators have expressed concern about privacy rights and the American Civil Liberties Union (ACLU) has sued the company for violating privacy laws on several occasions. U.S. police have used the software to apprehend suspected criminals.[4][5][6] Clearview's practices have led to fines and bans by EU nations for violating privacy laws, and investigations in the U.S. and other countries.[7][8][9] In 2022, Clearview reached a settlement with the ACLU, in which they agreed to restrict U.S. market sales of facial recognition services to government entities.\n\nClearview AI was the victim of a data breach in 2020 which exposed their customer list. This demonstrated 2,200 organizations in 27 countries had accounts with facial recognition searches.[10]\n\nHistory [ edit ]\n\nClearview AI was founded in 2017 by Hoan Ton-That and Richard Schwartz after transferring the assets of another company, SmartCheckr, which the pair originally founded in 2017 alongside Charles C. Johnson.[11][3] The company was founded in Manhattan after the founders met at the Manhattan Institute.[1] The company initially raised $8.4 million from investors including Kirenaga Partners and Peter Thiel.[12] Additional fundraising, in 2020, collected $8.625 million in exchange for equity. The company did not disclose investors in the second round. In 2021, another fundraising round received $30 million. Early use of Clearview's app was given to potential investors in their Series A fundraising round. Billionaire John Catsimatidis used it to identify someone his daughter dated and piloted it at one of his Gristedes grocery markets in New York City to identify shoplifters.[14][15]\n\nIn October 2020, a company spokesperson claimed that Clearview AI's valuation was more than $100 million.[16] The company announced its first chief strategy officer, chief revenue officer, and chief marketing officer in May 2021. Devesh Ashra, a former deputy assistant secretary with the United States Department of the Treasury, became its chief strategy officer. Chris Metaxas, a former executive at LexisNexis Risk Solutions, became its chief revenue officer. Susan Crandall, a former marketing executive at LexisNexis Risk Solutions and Motorola Solutions, became its chief marketing officer.[17] Devesh Ashra and Chris Metaxas left the company in 2021. In August 2021, Clearview AI announced the formation of an advisory board including Raymond Kelly, Richard A. Clarke, Rudy Washington, Floyd Abrams, Lee S. Wolosky, and Owen West.[18] The company claimed to have scraped more than 10 billion images as of October 2021.[19] In May 2022, Clearview AI announced that it would be expanding sales of its facial recognition software to schools and lending platforms outside the U.S.[20]\n\nClearview AI hired a notable legal team to defend the company against several lawsuits that threatened their business model. Their legal staff includes Tor Ekeland, Lee S. Wolosky, Paul Clement, Floyd Abrams, and Jack Mulcaire.[21][1][22] Abrams stated the issue of privacy rights versus free speech in the First Amendment could reach the Supreme Court.[21]\n\nUsage [ edit ]\n\nClearview AI provides facial recognition software where users can upload an image of a face and match it against their database.[23] The software then supplies links to where the \"match\" can be found online.[24] The company operated in near secrecy until the release of an investigative report in The New York Times titled \"The Secretive Company That Might End Privacy as We Know It\" in January 2020. It maintained this secrecy by publishing fake information about the company's location and employees and erasing social media for the founders.[3][1][25] Citing the article, over 40 tech and civil rights organizations sent a letter to the Privacy and Civil Liberties Oversight Board (PCLOB) and four congressional committees, outlining their concerns with facial recognition and Clearview, and asking the PCLOB to suspend use of facial recognition.[26][27][28][1]\n\nClearview served to accelerate a global debate on the regulation of facial recognition technology by governments and law enforcement.[29][30] Law enforcement officers have stated that Clearview's facial recognition is far superior in identifying perpetrators from any angle than previously used technology.[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.[32] On February 5 and 6, 2020, Google, YouTube, Facebook, and Venmo sent cease and desist letters as it is against their policies.[33][34] Ton-That responded in an interview that there is a First Amendment right to access public data. He later stated that Clearview has scraped over 50 billion images from across the web.[29][35][36]\n\nThe New Zealand Police used it in a trial after being approached by Clearview's Marko Jukic in January 2020. Jukic said it would have helped identify the Christchurch mosque shooter had the technology been available. The usage of Clearview's software in this case raised strong objections once exposed, as neither the users' supervisors or the Privacy Commissioner were aware or approved of its use. After it was revealed by RNZ, Justice Minister Andrew Little stated, \"It clearly wasn't endorsed, from the senior police hierarchy, and it clearly didn't get the endorsement from the [Police] Minister... that is a matter of concern.\"[37][38]\n\nClearview's technology was used for identifying an individual at a May 30, 2020 George Floyd police violence protest in Miami, Florida. Miami's WTVJ confirmed this, as the arrest report only said she was \"identified through investigative means\". The defendant's attorney did not even know it was with Clearview. Ton-That confirmed its use, noting that it was not being used for surveillance, but only to investigate a crime.[39]\n\nIn December 2020, the ACLU of Washington sent a letter to Seattle mayor Jenny Durkan, asking her to ban the Seattle Police Department from using Clearview AI.[40] The letter cited public records retrieved by a local blogger, which showed one officer signing up for and repeatedly logging into the service, as well as corresponding with a company representative. While the ACLU letter raised concerns that the officer's usage violated the Seattle Surveillance Ordinance, an auditor at the City of Seattle Office of the Inspector General argued that the ordinance was designed to address the usage of surveillance technologies by the Department itself, not by an officer without the Department's knowledge.[41]\n\nAfter the January 6 riot at the United States Capitol, the Oxford Police Department in Alabama used Clearview's software to run a number of images posted by the Federal Bureau of Investigation in its public request for suspect information to generate leads for people present during the riot. Photo matches and information were sent to the FBI who declined to comment on its techniques.[5]\n\nIn March 2022, Ukraine's Ministry of Defence began using Clearview AI's facial recognition technology \"to uncover Russian assailants, combat misinformation and identify the dead\". Ton-That also claimed that Ukraine's MoD has \"more than 2 billion images from the Russian social media service VKontakte at its disposal\".[42] Ukrainian government agencies used Clearview over 5,000 times as of April 2022.[43][44] The company provided these accounts and searches for free.[45]\n\nIn a Florida case, Clearview's technology was used by defense attorneys to successfully locate a witness, resulting in the dismissal of vehicular homicide charges against the defendant.[46]\n\nLaw enforcement use of the facial recognition software grew rapidly in the United States. In 2022 more than one million searches were conducted. In 2023, this usage doubled.[36]\n\nMarketing efforts and pushback [ edit ]\n\nClearview AI encouraged user adoption by offering free trials to law enforcement officers rather than departments as a whole. The company additionally used its significant connections to the Republican Party to connect with police departments.[1][47] In onboarding emails, new users were encouraged to go beyond running one or two searches to \"[s]ee if you can reach 100 searches\".[48] During 2020, Clearview sold their facial recognition software for one tenth the cost of competitors.[3]\n\nClearview's marketing claimed their facial recognition led to a terrorist arrest. The identification was submitted to the New York Police Department tip line.[49] Clearview claims to have solved two other New York cases and 40 cold cases, later stating they submitted them to tip lines. NYPD stated they have no institutional relationship with Clearview, but their policies do not ban its use by individual officers. In 2020, thirty NYPD officers were confirmed to have Clearview accounts.[3] In April 2021, documents obtained by the Legal Aid Society under New York's Freedom Of Information Law demonstrated that Clearview had collaborated with the NYPD for years, contrary to past NYPD denials.[50] Clearview met with senior NYPD leadership and entered into a vendor contract with the NYPD.[48] Clearview came under renewed scrutiny for enabling officers to conduct large numbers of searches without formal oversight or approval.[50][48]\n\nThe company was sent a cease and desist letter from the office of New Jersey Attorney General Gurbir Grewal after including a promotional video on its website with images of Grewal.[51] Clearview had claimed that its app played a role in a New Jersey police sting. Grewal confirmed the software was used to identify a child predator, but he also banned the use of Clearview in New Jersey. Tor Ekeland, a lawyer for Clearview, confirmed the marketing video was taken down the same day.[4][52]\n\nIn March 2020, Clearview pitched their technology to states for use in contact tracing to assist with the COVID-19 pandemic.[53][54] A reporter found Clearview's search could identify him while he covered his nose and mouth like a COVID mask would.[45] The idea brought criticism from US senators and other commentators because it seemed the crisis was being used to push unreliable tools that violate personal privacy.[55][56]\n\nContrary to Clearview's initial claims that its service was sold only to law enforcement, a data breach in early 2020 revealed that numerous commercial organizations were on Clearview's customer list. For example, Clearview marketed to private security firms and to casinos.[57] Additionally, Clearview planned expansion to many countries, including authoritarian regimes.[58]\n\nSenator Edward J. Markey wrote to Clearview and Ton-That, stating \"Widespread use of your technology could facilitate dangerous behavior and could effectively destroy individuals' ability to go about their daily lives anonymously.\" Markey asked Clearview to detail aspects of its business, in order to understand these privacy, bias, and security concerns.[32][59] Clearview responded through an attorney, declining to reveal information.[60] In response to this, Markey wrote a second letter, saying their response was unacceptable and contained dubious claims, and that he was concerned about Clearview \"selling its technology to authoritarian regimes\" and possible violations of COPPA.[8][61] Senator Markey wrote a third letter to the company with concerns, stating \"this health crisis cannot justify using unreliable surveillance tools that could undermine our privacy rights.\" Markey asked a series of questions about what government entities Clearview has been talking with, in addition to unanswered privacy concerns.[55]\n\nSenator Ron Wyden voiced concerns about Clearview and had meetings with Ton-That cancelled on three occasions.[62][8]\n\nIn April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.[63]\n\nTechnology [ edit ]\n\nAccuracy [ edit ]\n\nIn October 2021 Clearview submitted its algorithm to one of two facial recognition accuracy tests conducted by the National Institute of Standards and Technology (NIST) every few months. Clearview ranked amongst the top 10 of 300 facial recognition algorithms in a test to determine accuracy in matching two different photos of the same person. Clearview did not submit to the NIST test for matching an unknown face to a 10 billion image database, which more-closely matches the algorithm's intended purpose. This was the first third-party test of the software.[19]\n\nClearview, at various times throughout 2020, has claimed 98.6%, 99.6%, or 100% accuracy. However, these results are from tests conducted by people affiliated with the company and have not used representative samples of the population.[29][64][65]\n\nIn 2021, Clearview announced that it was developing \"deblur\" and \"mask removal\" tools to sharpen blurred images and envision the covered part of an individual's face. These tools would be implemented using machine learning models that fill in the missing details based on statistical patterns found in other images. Clearview acknowledged that deblurring an image and/or removing a mask could potentially make errors more frequent and would only be used to generate leads for police investigations.[35]\n\nAssistant Chief of Police of Miami, Armando Aguilar, said in 2023 that Clearview's AI tool had contributed to the resolution of several murder cases, and that his team had used the technology around 450 times a year. Aguilar emphasized that they do not make arrests based on Clearview's matches alone, and instead use the data as a lead and then proceed via conventional methods of case investigation.[24]\n\nSeveral cases of mistaken identity using Clearview facial recognition have been documented, but \"the lack of data and transparency around police use means the true figure is likely far higher.\" Ton-That claims the technology has approximately 100% accuracy, and attributes mistakes to potential poor policing practices. Ton-That's claimed accuracy level is based on mugshots and would be affected by the quality of the image uploaded.[24]\n\nData breaches [ edit ]\n\nClearview AI experienced a data breach in February 2020 which exposed its list of customers. Clearview's attorney, Tor Ekeland stated the security flaw was corrected.[66] In response to the leaks, the United States House Committee on Science, Space, and Technology sent a letter to the company requesting further insight into their bio-metric and security practices.[67]\n\nWhile Clearview's app is only supposed to be privately accessible to customers, the Android application package and iOS applications were found in unsecured Amazon S3 buckets.[68] The instructions showed how to load an enterprise (developer) certificate so the app could be installed without being published on the App Store. Clearview's access was suspended, as it was against Apple's terms of service for developers, and as a result the app was disabled.[69] In addition to application tracking (Google Analytics, Crashlytics), examination of the source code for the Android version found references to Google Play Services, requests for precise phone location data, voice search, sharing a free demo account to other users, augmented reality integration with Vuzix, and sending gallery photos or taking photos from the app itself. There were also references to scanning barcodes on a drivers license and to RealWear.[70]\n\nIn April 2020, Mossab Hussein of SpiderSilk, a security firm, discovered Clearview's source code repositories were exposed due to misconfigured user security settings. This included secret keys and credentials, including cloud storage and Slack tokens. The compiled apps and pre-release apps were accessible, allowing Hussein to run the macOS and iOS apps against Clearview's services. Hussein reported the breach to Clearview but refused to sign a non-disclosure agreement necessary for Clearview's bug bounty program. Ton-That reacted by calling Hussein's disclosure of the bug as an act of extortion. Hussein also found 70,000 videos in one storage bucket from a Rudin Management apartment building's entrance.[71]\n\nInsight Camera [ edit ]\n\nClearview also operates a secondary business, Insight Camera, which provides AI-enabled security cameras. It is targeted at \"retail, banking and residential buildings\". Two customers have used the technology, United Federation of Teachers and Rudin Management.[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.[74]\n\nCustomer list [ edit ]\n\nFollowing a data leak of Clearview's customer list, BuzzFeed confirmed that 2,200 organizations in 27 countries had accounts with activity. BuzzFeed has the exclusive right to publish this list and has chosen not publish it in its entirety.[10] Clearview AI claims that at least 600 of these users are police departments. These are primarily in the U.S. and Canada, but Clearview has expanded to other countries as well.[3] Although the company claims their services are for law enforcement, they have had contracts with Bank of America, Kohls, and Macy's. Several universities and high schools have done trials with Clearview.[10] The list below highlights particularly notable users.\n\nAmerican law enforcement and government\n\nInternational law enforcement\n\nLegal challenges [ edit ]\n\nClearview AI has had its business model challenged by several lawsuits in multiple jurisdictions. It responded by defending itself, settling in some cases, and exiting several markets.\n\nThe company's claim of a First Amendment right to public information has been disputed by privacy lawyers such as Scott Skinner-Thompson and Margot Kaminski, highlighting the problems and precedents surrounding persistent surveillance and anonymity.[34][89] Former New York City Police Commissioner and executive chairman of Teneo Risk Chief Bill Bratton challenged privacy concerns and recommended strict procedures for law enforcement usage in an op-ed in New York Daily News.[90]\n\nUnited States [ edit ]\n\nAfter the release of The New York Times January 2020 article, lawsuits were filed by the states of Illinois, California, Virginia and New York, citing violations of privacy and safety laws.[91] Most of the lawsuits were transferred to New York's Southern District.[92] Two lawsuits were filed in state courts; in Vermont by the attorney general and in Illinois on behalf of the American Civil Liberties Union (ACLU), which cited a statute that forbids the corporate use of residents' faceprints without explicit consent. Clearview countered that an Illinois law does not apply to a company based in New York.[21]\n\nIn response to a class action lawsuit filed in Illinois for violating the Biometric Information Privacy Act (BIPA), in May 2020 Clearview stated that they instituted a policy to stop working with non-government entities and to remove any photos geolocated in Illinois.[93][94][75] On May 28, 2020, ACLU and Edelson filed a new suit Clearview in Illinois using the BIPA.[95][96] Clearview agreed to a settlement in June 2024, offering 23% of the company (valued at $52 million at the time) rather than a cash settlement, which was likely to bankrupt the company.[97]\n\nIn May 2022, Clearview agreed to settle the 2020 lawsuit from the ACLU. The settlement prohibited the sale of its facial recognition database to private individuals and businesses.[98]\n\nIn the Vermont case, Clearview AI invoked Section 230 immunity. The court denied the use of Section 230 immunity in this case because Vermont's claims were \"based on the means by which Clearview acquired the photographs\" rather than third party content.[99]\n\nCanada [ edit ]\n\nIn July 2020, Clearview AI announced that it was exiting the Canadian market amidst joint investigations into the company and the use of its product by police forces.[100] Daniel Therrien, the Privacy Commissioner of Canada condemned Clearview AI's use of scraped biometric data: \"What Clearview does is mass surveillance and it is illegal. It is completely unacceptable for millions of people who will never be implicated in any crime to find themselves continually in a police lineup.\"[101] In June 2021, Therrien found that the Royal Canadian Mounted Police had broken Canadian privacy law through hundreds of illegal searches using Clearview AI.[102]\n\nEuropean Union and UK [ edit ]\n\nIn January 2021, Clearview AI's biometric photo database was deemed illegal in the European Union (EU) by the Hamburg Data Protection Authority (DPA). The deletion of an affected person's biometric data was ordered. The authority stated that the General Data Protection Regulation (GDPR) is applicable despite the fact that Clearview AI has no European branch.[103] In March 2020, they had requested Clearview AI's customer list, as data protection obligations would also apply to the customers.[104] The data protection advocacy organization NOYB criticized the DPA's decision as the DPA issued an order protecting only the individual complainant instead of an order banning the collection of any European resident's photos.[105]\n\nIn May 2021, the company had numerous legal complaints filed in Austria, France, Greece, Italy and the United Kingdom for violating European privacy laws in its method of documenting and collecting Internet data.[106] In November 2021, Clearview received a provisional notice by the UK's Information Commissioner's Office (ICO) to stop processing its citizens' data citing a range of alleged breaches. The company was also notified of a potential fine of approximately $22.6 million. Clearview claimed that the ICO's allegations were factually inaccurate as the company \"does not do business in the UK, and does not have any UK customers at this time\". The BBC reported on 23 May that the company had been fined \"more than £7.5m by the UK's privacy watchdog and told to delete the data of UK residents\".[107] Clearview was also ordered to delete all facial recognition data of UK residents. This fine marked the fourth of its type placed on Clearview, after similar orders and fines issued from Australia, France, and Italy.[9] However, in October 2023, this fine was overturned following an appeal based on the jurisdiction of the ICO over acts of foreign governments.[108]\n\nIn September 2024, Clearview AI was fined €30.5 million by the Dutch Data Protection Authority (DPA) for constructing what the agency described as an illegal database.[109] The DPA's ruling highlighted that Clearview AI unlawfully collected facial images, including those of Dutch citizens, without obtaining their consent. This practice constitutes a significant violation of the EU's GDPR due to the intrusive nature of facial recognition technology and the lack of transparency regarding the use of individuals' biometric data.[110]\n\nSee also [ edit ]",
            "url": "https://en.wikipedia.org/wiki/Clearview_AI#:~:text=Clearview's%20practices%20have%20led%20to,recognition%20services%20to%20government%20entities.",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "privacy",
                "recognition",
                "company",
                "used",
                "clearviews",
                "data",
                "2020",
                "ai",
                "clearview",
                "facial"
            ],
            "summary": "[21]Usage [ edit ]Clearview AI provides facial recognition software where users can upload an image of a face and match it against their database.\n[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.\n[62][8]In April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.\n[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.\nAmerican law enforcement and governmentInternational law enforcementLegal challenges [ edit ]Clearview AI has had its business model challenged by several lawsuits in multiple jurisdictions.",
            "metadata": {
                "source_domain": "en.wikipedia.org",
                "scrape_date": "2024-10-25T12:40:25.051701",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 23454
            }
        },
        {
            "title": "Hellenic DPA fines Clearview AI 20 million euros",
            "text": "Background information\n\nDate of final decision: 13 July 2022\n\nCross-border case or national case: National case\n\nController: Clearview AI Inc.\n\nLegal Reference: GDPR: Article 3: Territorial scope. Article 5(1)(a) and (2): Principles relating to processing of personal data. Article 6 (1)(a)(b)(c)(d)(e)(f): Lawfulness of processing. Article 9(1) and 9(2)(e): Processing of special categories of personal data. Article 12: Transparent information, communication and modalities for the exercise of the rights of the data subject. Article 14: Information to be provided where personal data have not been obtained from the data subject. Article 15: Right of access by the data subject. Article 17: Representatives of controllers not established in the Union.\n\nDecision: Infringement of the GDPR, Administrative fine.\n\nKey words: Web scraping, Images Database, Facial Recognition, Biometric Data, AI systems, Geolocation, Jurisdiction under EU law, Representative in the EU.\n\nSummary of the Decision\n\nOrigin of the case:\n\nThe Authority examined a complaint against Clearview AI Inc, lodged by the civil non-profit organization “Homo Digitalis” on behalf of a complainant, who claimed that s/he was not satisfied in relation to the right of access s/he exercised before the aforementioned company. With the complaint at issue it was also requested that the practices of the defendant company be examined on the whole from the point of view of the protection of personal data.\n\nKey Findings:\n\nThe Authority found that the company, which markets facial recognition services, violated the principles of lawfulness and transparency (art. 5 paragraphs 1(a) and (2), 6, 9 GDPR) and its obligations under Articles 12, 14, 15 and 27 of the GDPR.\n\nDecision:\n\nThe Hellenic DPA imposed a fine of twenty million euros (20,000,000) οn Clearview AI Inc for violating the principles of lawfulness and transparency.\n\nIn addition, the Authority ordered the company to comply so that it satisfies the complainant’s request for access to personal data, while imposing (on the same company) a prohibition on the collection and processing of personal data of subjects located in the Greek territory, using methods included in the facial recognition service. Finally, with this Decision, the Authority ordered Clearview AI Inc. to delete the personal data of those subjects located in Greece, which the defendant collects and processes using the aforementioned methods.\n\nFor further information: decision in national language",
            "url": "https://www.edpb.europa.eu/news/national-news/2022/hellenic-dpa-fines-clearview-ai-20-million-euros_en",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "fines",
                "euros",
                "20",
                "article",
                "dpa",
                "authority",
                "company",
                "subject",
                "personal",
                "data",
                "hellenic",
                "ai",
                "million",
                "processing",
                "clearview",
                "recognition"
            ],
            "summary": "Background informationDate of final decision: 13 July 2022Cross-border case or national case: National caseController: Clearview AI Inc.Legal Reference: GDPR: Article 3: Territorial scope.\nArticle 14: Information to be provided where personal data have not been obtained from the data subject.\nKey words: Web scraping, Images Database, Facial Recognition, Biometric Data, AI systems, Geolocation, Jurisdiction under EU law, Representative in the EU.\nDecision:The Hellenic DPA imposed a fine of twenty million euros (20,000,000) οn Clearview AI Inc for violating the principles of lawfulness and transparency.\nFinally, with this Decision, the Authority ordered Clearview AI Inc. to delete the personal data of those subjects located in Greece, which the defendant collects and processes using the aforementioned methods.",
            "metadata": {
                "source_domain": "www.edpb.europa.eu",
                "scrape_date": "2024-10-25T12:40:25.266986",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 2497
            }
        },
        {
            "title": "Statement on Clearview AI",
            "text": "Published 21 August 2024\n\nThe Office of the Australian Information Commissioner (OAIC) has been considering whether to take further action against Clearview AI, Inc., which was the subject of a determination under s 52(1A) of the Privacy Act 1988 (Cth) issued on 14 October 2021. That determination found that Clearview AI, through its collection of facial images and biometric templates from individuals in Australia using a facial recognition technology, contravened the Privacy Act, and breached several Australian Privacy Principles (APPs) in Schedule 1 of the Act, including by collecting the sensitive information of individuals without consent in breach of APP 3.3 and failing to take reasonable steps to implement practices, procedures and systems to comply with the APPs.\n\nNotably, the determination found that Clearview AI indiscriminately collected images of individuals’ faces from publicly available sources across the internet (including social media) to store in a database on the organisation’s servers. In the determination, the Australian Information Commissioner made several declarations, including for the organisation to cease collecting images from individuals in Australia. On 3 November 2021, Clearview AI commenced proceedings in the Administrative Appeals Tribunal (AAT) to challenge the determination. After the AAT found that Clearview AI had breached certain of the APPs, Clearview AI withdrew from the proceedings in August 2023, before the AAT could make orders regarding steps Clearview AI must take to remedy the breach. The original determination therefore still stands, as do the declarations contained therein, including that Clearview AI must not collect images from individuals in Australia and must delete all images it had previously collected from individuals in Australia.\n\nIn early 2024, there was some media reporting alleging that Clearview AI was continuing to collect images from individuals in Australia. That media reporting was not based on new information, but rather referenced statements made by Clearview AI in the course of the AAT proceedings in 2023. Nevertheless, it gave rise to questions about whether Clearview AI was complying with the terms of the Australian Information Commissioner’s 2021 determination.\n\nPrivacy Commissioner Carly Kind said, “I have given extensive consideration to the question of whether the OAIC should invest further resources in scrutinising the actions of Clearview AI, a company that has already been investigated by the OAIC and which has found itself the subject of regulatory investigations in at least three jurisdictions around the world as well as a class action in the United States. Considering all the relevant factors, I am not satisfied that further action is warranted in the particular case of Clearview AI at this time.\n\n“However, the practices engaged in by Clearview AI at the time of the determination were troubling and are increasingly common due to the drive towards the development of generative artificial intelligence (AI) models. In August 2023, alongside 11 other data protection and privacy regulators, the OAIC issued a statement on the need to address data scraping, articulating in particular the obligations on social media platforms and publicly accessible sites to take reasonable steps to protect personal information that is on their sites from unlawful data scraping.\n\n“All regulated entities, including organisations that fall within the jurisdiction of the Privacy Act by way of carrying on business in Australia, which engage in the practice of collecting, using or disclosing personal information in the context of artificial intelligence are required to comply with the Privacy Act. The OAIC will soon be issuing guidance for entities seeking to develop and train generative AI models, including how the APPs apply to the collection and use of personal information. We will also issue guidance for entities using commercially available AI products, including chatbots.\n\n“In the meantime, we reiterate that the determination against Clearview AI still stands.”",
            "url": "https://www.oaic.gov.au/news/media-centre/statement-on-clearview-ai",
            "authors": [],
            "publish_date": "2024-08-21T10:15:01+10:00",
            "keywords": [
                "privacy",
                "oaic",
                "individuals",
                "statement",
                "including",
                "information",
                "determination",
                "ai",
                "australia",
                "clearview",
                "images"
            ],
            "summary": "On 3 November 2021, Clearview AI commenced proceedings in the Administrative Appeals Tribunal (AAT) to challenge the determination.\nAfter the AAT found that Clearview AI had breached certain of the APPs, Clearview AI withdrew from the proceedings in August 2023, before the AAT could make orders regarding steps Clearview AI must take to remedy the breach.\nIn early 2024, there was some media reporting alleging that Clearview AI was continuing to collect images from individuals in Australia.\nConsidering all the relevant factors, I am not satisfied that further action is warranted in the particular case of Clearview AI at this time.\n“In the meantime, we reiterate that the determination against Clearview AI still stands.”",
            "metadata": {
                "source_domain": "www.oaic.gov.au",
                "scrape_date": "2024-10-25T12:40:25.314611",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 4090
            }
        },
        {
            "title": "News release: Clearview AI’s unlawful practices represented mass surveillance of Canadians, commissioners say",
            "text": "Note: A teleconference for journalists will be held this morning. See details below.\n\nClearview AI’s unlawful practices represented mass surveillance of Canadians, commissioners say\n\nFebruary 3, 2021 – Technology company Clearview AI’s scraping of billions of images of people from across the Internet represented mass surveillance and was a clear violation of the privacy rights of Canadians, an investigation has found.\n\nThe joint investigation by the Office of the Privacy Commissioner of Canada, the Commission d'accès à l'information du Québec, the Office of the Information and Privacy Commissioner for British Columbia and the Office of the Information and Privacy Commissioner of Alberta, concluded that the New-York-based technology company violated federal and provincial privacy laws.\n\nClearview AI’s technology allowed law enforcement and commercial organizations to match photographs of unknown people against the company’s databank of more than 3 billion images, including of Canadians and children, for investigation purposes. Commissioners found that this creates the risk of significant harm to individuals, the vast majority of whom have never been and will never be implicated in a crime.\n\nThe investigation found that Clearview had collected highly sensitive biometric information without the knowledge or consent of individuals. Furthermore, Clearview collected, used and disclosed Canadians’ personal information for inappropriate purposes, which cannot be rendered appropriate via consent.\n\nWhen presented with the investigative findings, Clearview argued that:\n\nCanadian privacy laws do not apply to its activities because the company does not have a “real and substantial connection” to Canada;\n\nConsent was not required because the information was publicly available;\n\nIndividuals who placed or permitted their images to be placed on websites that were scraped did not have substantial privacy concerns justifying an infringement of the company’s freedom of expression;\n\nGiven the significant potential benefit of Clearview's services to law enforcement and national security and the fact that significant harm is unlikely to occur for individuals, the balancing of privacy rights and Clearview’s business needs favoured the company’s entirely appropriate purposes; and\n\nClearview cannot be held responsible for offering services to law enforcement or any other entity that subsequently makes an error in its assessment of the person being investigated.\n\nCommissioners rejected these arguments. They were particularly concerned that the organization did not recognize that the mass collection of biometric information from billions of people, without express consent, violated the reasonable expectation of privacy of individuals and that the company was of the view that its business interests outweighed privacy rights.\n\nOn the applicability of Canadian laws, they noted that Clearview collected the images of Canadians and actively marketed its services to law enforcement agencies in Canada. The RCMP became a paying customer and a total of 48 accounts were created for law enforcement and other organizations across the country.\n\nThe investigation also noted the potential risks to individuals whose images were captured and included in Clearview’s biometric database. These potential harms include the risk of misidentification and exposure to potential data breaches.\n\nThe privacy authorities recommended that Clearview stop offering its facial recognition services to Canadian clients; stop collecting images of individuals in Canada; and delete all previously collected images and biometric facial arrays of individuals in Canada.\n\nShortly after the investigation began, Clearview agreed to stop providing its services in the Canadian market. It stopped offering trial accounts to Canadian organizations and discontinued services to its only remaining Canadian subscriber, the RCMP in July 2020.\n\nHowever, Clearview disagreed with the findings of the investigation and did not demonstrate a willingness to follow the other recommendations. Should Clearview maintain its refusal, the four authorities will pursue other actions available under their respective Acts to bring Clearview into compliance with Canadian laws.\n\nA related investigation by the Office of the Privacy Commissioner of Canada into the RCMP ’s use of Clearview AI’s facial recognition technology remains ongoing. The federal Commissioner's office, along with provincial counterparts, are currently developing guidance for law enforcement agencies on the use of facial recognition technologies. We expect to publish guidelines for consultation with stakeholders in the spring.\n\nQuotes:\n\n“What Clearview does is mass surveillance and it is illegal. It is completely unacceptable for millions of people who will never be implicated in any crime to find themselves continually in a police lineup. Yet the company continues to claim its purposes were appropriate, citing the requirement under federal privacy law that its business needs be balanced against privacy rights. Parliamentarians reviewing Bill C-11 may wish to send a clear message, through that bill, that where there is a conflict between commercial objectives and privacy protection, Canadians’ privacy rights should prevail.” – Daniel Therrien, Privacy Commissioner of Canada.\n\n“Clearview's massive collection of millions of images without the consent or knowledge of individuals for the purpose of marketing facial recognition services does not comply with Quebec's privacy or biometric legislation. The stance taken by Clearview that it is in compliance with the laws that apply to it, underscores the need for greater oversight of the use of this technology as well as providing regulatory authorities with additional tools of deterrence like those proposed in Bill 64.” – Diane Poitras, President of the Commission d'accès à l'information du Québec.\n\n“Our investigation reveals the vast amount of personal information collected without people’s knowledge or consent. It is unacceptable and deeply troubling that a company would create a giant database of our biometric data and sell it for profit without recognizing its invasive nature. The results of our work also point to the need to strengthen our privacy laws to properly protect the public.” – Michael McEvoy, Information and Privacy Commissioner for British Columbia.\n\n“As the use of facial recognition technology expands, significant issues around accuracy, automated decision making, proportionality and ethics persist. The Clearview investigation shows that across Canada we need to be discussing acceptable uses and regulation of facial recognition. Regulation would not only assist in upholding privacy rights, it would provide much needed certainty to all organizations thinking about using or developing the technology.” – Jill Clayton, Information and Privacy Commissioner of Alberta.\n\nRelated documents:\n\nNews conference details:\n\nDate: TODAY Wednesday, February 3, 2021\n\nTime: 11:30 a.m. ET (9:30 a.m. MT / 8:30 a.m. PT )\n\nFormat: Conference call with journalists. Brief statements followed by Q and A .\n\nParticipants:\n\nDaniel Therrien, Privacy Commissioner of Canada\n\nDiane Poitras, President of the Commission d'accès à l'information du Québec\n\nMichael McEvoy, Information and Privacy Commissioner for British Columbia\n\nJill Clayton, Information and Privacy Commissioner of Alberta\n\nCall-in information:\n\nAccredited journalists may call to join the news conference. For that number, please email communications@priv.gc.ca in advance of the news conference. (This line is available to media only.)\n\nContact:\n\nOffice of the Privacy Commissioner of Canada\n\nCommunications@priv.gc.ca\n\nCommission d'accès à l'information du Québec\n\nIsabelle.gosselin@cai.gouv.qc.ca\n\nOffice of the Information and Privacy Commissioner for British Columbia\n\nMMitchell@oipc.bc.ca\n\nOffice of the Information and Privacy Commissioner of Alberta\n\nSSibbald@oipc.ab.ca",
            "url": "https://www.priv.gc.ca/en/opc-news/news-and-announcements/2021/nr-c_210203/",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "unlawful",
                "surveillance",
                "canadians",
                "clearview",
                "technology",
                "say",
                "represented",
                "law",
                "investigation",
                "information",
                "release",
                "privacy",
                "practices",
                "commissioner",
                "individuals",
                "commissioners",
                "mass",
                "images",
                "services"
            ],
            "summary": "Clearview AI’s unlawful practices represented mass surveillance of Canadians, commissioners sayFebruary 3, 2021 – Technology company Clearview AI’s scraping of billions of images of people from across the Internet represented mass surveillance and was a clear violation of the privacy rights of Canadians, an investigation has found.\nYet the company continues to claim its purposes were appropriate, citing the requirement under federal privacy law that its business needs be balanced against privacy rights.\nThe Clearview investigation shows that across Canada we need to be discussing acceptable uses and regulation of facial recognition.\nParticipants:Daniel Therrien, Privacy Commissioner of CanadaDiane Poitras, President of the Commission d'accès à l'information du QuébecMichael McEvoy, Information and Privacy Commissioner for British ColumbiaJill Clayton, Information and Privacy Commissioner of AlbertaCall-in information:Accredited journalists may call to join the news conference.\nContact:Office of the Privacy Commissioner of CanadaCommunications@priv.gc.caCommission d'accès à l'information du QuébecIsabelle.gosselin@cai.gouv.qc.caOffice of the Information and Privacy Commissioner for British ColumbiaMMitchell@oipc.bc.caOffice of the Information and Privacy Commissioner of AlbertaSSibbald@oipc.ab.ca",
            "metadata": {
                "source_domain": "www.priv.gc.ca",
                "scrape_date": "2024-10-25T12:40:25.782806",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 7976
            }
        },
        {
            "title": "PIPEDA Findings #2021-001: Joint investigation of Clearview AI, Inc. by the Office of the Privacy Commissioner of Canada, the Commission d’accès à l’information du Québec, the Information and Privacy ",
            "text": "PIPEDA Findings #2021-001\n\nFebruary 2, 2021\n\nOverview\n\nThe Privacy Commissioner of Canada ( OPC ), the Commission d’accès à l’information du Québec ( CAI ), the Information and Privacy Commissioner for British Columbia ( OIPC BC ), and the Information and Privacy Commissioner of Alberta ( OIPC AB ), collectively referred to as “the Offices”, commenced a joint investigationFootnote 1 to examine whether Clearview AI, Inc.’s (“Clearview”) collection, use and disclosure of the personal information by means of its facial recognition tool complied with federal and provincial privacy laws applicable to the private sector.\n\nSpecifically, the Offices sought to determine whether Clearview:\n\nobtained requisite consent to collect, use and disclose personal information; and collected, used and disclosed personal information for an appropriate purpose Footnote 2.\n\nAdditionally, the CAI sought to determine whether Clearview had:\n\nReported the creation of a database of biometric characteristics or measurements.\n\nClearview’s facial recognition tool functions in four key sequential steps - Clearview:\n\n“scrapes” images of faces and associated data from publicly accessible online sources (including social media), and stores that information in its database; creates biometric identifiers in the form of numerical representations for each image; allows users to upload an image, which is then assessed against those biometric identifiers and matched to images in its database; and provides a list of results, containing all matching images and metadata. If a user clicks on any of these results, they are directed to the original source page of the image.\n\nThrough this process, Clearview amassed a database of over three billion images of faces and corresponding biometric identifiers, including those of a vast number of individuals in Canada, including children.\n\nClearview asserted that the tool is intended for use by law enforcement,Footnote 3 for legitimate law enforcement and investigative purposes. A variety of organizations, including private sector entities, used this service via a free-trial service.\n\nBiometric information is considered sensitive, in almost all circumstances, and facial recognition data is particularly sensitive. Furthermore, individuals who posted their images online, or whose images were posted by third party(ies), had no reasonable expectations that Clearview would collect, use and disclose their images for identification purposes. As such, express consent would generally be required. In Quebec, such use of biometric data requires express consent.\n\nClearview did not attempt to seek consent from the individuals whose information it collected. Clearview asserted that the information was “publicly available”, and thus exempt from consent requirements. Information collected from public websites, such as social media or professional profiles, and then used for an unrelated purpose, does not fall under the “publicly available” exception of PIPEDA , PIPA AB or PIPA BC . Nor is this information “public by law”, which would exempt it from Quebec’s Private Sector Law, and no exception of this nature exists for other biometric data under LCCJTI . Therefore, we found that Clearview was not exempt from the requirement to obtain consent.\n\nFurthermore, the Offices determined that Clearview collected, used and disclosed the personal information of individuals in Canada for inappropriate purposes, which cannot be rendered appropriate via consent. We found that the mass collection of images and creation of biometric facial recognition arrays by Clearview, for its stated purpose of providing a service to law enforcement personnel, and use by others via trial accounts, represents the mass identification and surveillance of individuals by a private entity in the course of commercial activity. We found Clearview’s purposes to be inappropriate where they: (i) are unrelated to the purposes for which those images were originally posted; (ii) will often be to the detriment of the individual whose images are captured; and (iii) create the risk of significant harm to those individuals, the vast majority of whom have never been and will never be implicated in a crime. Furthermore, it collected images in an unreasonable manner, via indiscriminate scraping of publicly accessible websites.\n\nWe identified certain other concerns on which we did not ultimately opine, but which we felt appropriate to raise in our report. This includes the fact that there were credible challenges to, and questions regarding, the efficacy and accuracy of facial recognition technologies generally, and regarding the reliability of Clearview’s testing results specifically.\n\nWe shared our preliminary findings and recommendations with Clearview, with a view to bringing it into compliance with federal and provincial private sector privacy law. We recommended that Clearview: (i) cease offering its facial recognition tool to clients in Canada; (ii) cease the collection, use and disclosure of images and biometric facial arrays collected from individuals in Canada; and (iii) delete images and biometric facial arrays collected from individuals in Canada in its possession.\n\nClearview expressly disagreed with our findings.\n\nIn disagreeing with our findings, Clearview alleged an absence of harms to individuals flowing from its activities. In our view, Clearview’s position fails to acknowledge: (i) the myriad of instances where false, or misapplied matches could result in reputational damage, and (ii) more fundamentally, the affront to individuals’ privacy rights and broad-based harm inflicted on all members of society, who find themselves under continual mass surveillance by Clearview based on its indiscriminate scraping and processing of their facial images.\n\nIn terms of remedies, noting that it had withdrawn from the Canadian market during our investigation, Clearview stated that it was “prepared to consider” remaining outside of the Canadian market for a further two years, while our Offices developed relevant guidance. Clearview suggested that it would be appropriate for our Offices to suspend our investigation and not issue this final report, and that during such a suspension, it “would be willing to take steps, on a best efforts and without prejudice basis, to try to limit the collection and distribution of the images that it is able to identify as Canadian” [emphasis added]. Clearview has not committed to following our recommendations. The Offices view it as inappropriate to suspend the investigation and not issue this Report. We therefore find the matter to be well-founded and restate the recommendations in our preliminary findings.\n\nAdditionally, the CAI determined that contrary to the requirements of the LCCJTI , Clearview had not advised the CAI that it had created a database of biometric characteristics, nor obtained the express consent from individuals that verifying or confirming their identity would be conducted using a facial recognition process.\n\nBackground\n\nThis report of investigation examines Clearview AI, Inc.’s (Clearview) compliance with Canada’s Personal Information Protection and Electronic Documents Act ( PIPEDA ), Quebec’s Act Respecting the Protection of Personal Information in the Private Sector (Quebec’s Private Sector Act), and Act to Establish a Legal Framework for Information Technology ( LCCJTI ), British Columbia’s Personal Information Protection Act ( PIPA BC ), and Alberta’s Personal Information Protection Act ( PIPA AB ) – referred to collectively as the Acts. Clearview is a technology company headquartered in the United States that developed and delivered its facial recognition Footnote 4 software and combined database solution (App) to clients around the world. Clearview’s App allows clients to upload a digital image of an individual’s face and run a search against it. The App then applies its algorithm to the digital image and runs the result against Clearview’s database to identify and display likely matches and associated source information. In January and February 2020, public reports Footnote 5 indicated that Clearview was populating its facial recognition database by collecting digital images from a variety of public websites, including but not limited to, Facebook, YouTube, Instagram, Twitter and Venmo, in apparent violation of those organizations’ terms of service and without the consent of individuals. It was further indicated that these digital images were then indefinitely stored in Clearview’s database to be sourced and served as results for facial recognition searches. In February 2020, multiple reports Footnote 6 surfaced confirming that a number of Canadian law enforcement agencies and private organizations Footnote 7 had used Clearview’s services in order to identify individuals. Satisfied that reasonable grounds existed to investigate these matters, in February 2020, the Office of the Privacy Commissioner of Canada ( OPC ), the Commission d’accès à l’information du Québec ( CAI ), the Information and Privacy Commissioner for British Columbia ( OIPC BC ), and the Information and Privacy Commissioner of Alberta ( OIPC AB ), collectively referred to as the Offices, each initiated investigations pursuant to s. 11(2) of PIPEDA , s. 81 of Quebec’s Private Sector Act, s. 36(1)(a) of PIPA BC , and s. 36(1)(a) of PIPA AB respectively. The Offices decided to conduct the investigation jointly in order to maximize their expertise and their resources, while avoiding duplication of their efforts and those of Clearview.\n\nIssues\n\nThe issues in this investigation were: Whether Clearview was required under the Acts to get consent for its collection, use and disclosure of personal information and if so, whether it did; and Whether Clearview collected, used and/or disclosed personal information for a purpose that a reasonable person would consider appropriate in the circumstances, for a purpose that was reasonable and to fulfill a legitimate need? Footnote 8 The following Quebec-specific issue was also examined: Did Clearview previously disclose to the CAI the creation of a database of biometric characteristics or measurements? During the course of the investigation, specifically after the letter of intention referred to in paragraph 11 below, Clearview also asserted that our Offices do not have jurisdiction over the Clearview activities in question. We address this issue in our analysis, prior to considering the issues identified above.\n\nMethodology\n\nIn addition to conducting extensive open-source research, the investigative team (the team) analyzed representations provided by Clearview and records relating to its activities. The team also examined representations from a number of third parties identified as possible users of Clearview’s service. Between February and November 2020, Clearview provided multiple sets of written representations to our Offices. Furthermore, we gave Clearview multiple opportunities to meet with us to make inquiries and provide additional evidence. We conducted two such meetings in June 2020. Upon completion of the evidence-gathering phase of the joint investigation, our Offices issued a letter of intention to Clearview on October 29 2020, which set out and explained the rationale for our preliminary findings, identified several orders and recommendations under consideration and invited Clearview to respond. We then met with Clearview on November 17 to clarify our views, provide an opportunity to ask any questions, and discuss potential remedies to resolve the matter. On November 20, Clearview provided a written response articulating its disagreement with our preliminary findings and orders and recommendations under consideration. In this letter, Clearview set out a variety of new arguments, and provided new information which our Offices considered and assessed before producing this report of findings.\n\nClearview’s representations and our investigation\n\nThis section reflects initial representations provided by Clearview up to the point of the issuance of our letter of intention. Further representations provided by Clearview in its response to our letter of intention are included under our analysis of each issue.\n\nOverview of Clearview’s facial recognition implementation\n\nIn its submissions, Clearview explained that its facial recognition technology is based on five primary components: (i) image crawler, (ii) image store, (iii) metadata store, (iv) neural network and (v) vector database. The image crawler is an automated tool that searches public web pages and collects any images that it identifies as containing faces along with associated metadata such as the title, source link and description. This process is commonly referred to as “scraping.” The images and metadata collected through this scraping process are indefinitely stored on Clearview’s servers in the image and metadata stores respectively. The neural network underpins the algorithm that analyzes digital images of faces and turns them into numerical representations referred to as “vectors”. Clearview’s vectors consist of 512 data points that represent the various unique lines that make up a face. Clearview then stores all of these vectors in their vector database, where they are associated with the images stored on Clearview’s server. Every image in the database has a vector associated with it in order to allow identification and matching. When an App user wishes to identify an individual, they are required to upload an image of their target into the App and run a search. The neural network then analyzes the image and produces a vector. This vector is then compared against all vectors stored in Clearview’s database, with the App pulling any matching images from the vector database and providing them to the user, along with any associated metadata, as search results. Clearview stated that images uploaded by users are stored separately from images obtained from scraping, and do not show up in any search results. Clearview advised that its search results are displayed in a list containing thumbnail images that appear to be a match for the individual, the name of the image, description and source link. The user must then click the associated source link to be re-directed to the web page where the image was originally collected, in order to obtain additional information. Clearview stated that it “[does] not possess or maintain any information about names, addresses, nationality, date of birth [or] location” associated with the images in its database.\n\nClearview’s privacy practices regarding consent\n\nClearview originally stated that it does not seek consent from individuals whose information it collects. Rather, Clearview stated that in its view, the images it collected were publicly available and therefore it did not require the knowledge or consent of individuals to collect their information. In support of this position, Clearview stated that it only collected images from publicly-viewable web pages, and did not collect any images protected by privacy settings, such as those associated with certain social media accounts, or from pages that enabled “robots.txt”. Footnote 9 Clearview has confirmed that their image crawler is configured to respect whatever instructions are present in the robots.txt file.\n\nClearview’s purposes\n\nIn its initial representations, Clearview advised our Offices that its App was intended to be for the sole and exclusive use of law enforcement. This was reflected in Clearview’s terms of service, which state that “Users may use [the] Service for legitimate law enforcement and investigative purposes” and that “users may not use the Service for any reason other than law enforcement or investigative purposes.” In response to our letter of intention, Clearview advised that previously, its terms of service also extended access to “security professionals”. Clearview asserted that their technology provides “substantial, concrete benefits to public safety by dramatically increasing law enforcement’s ability to identify and investigate suspects, victims and witnesses.” Clearview pointed to numerous successes in cases ranging from “murder, armed robbery and child sexual exploitation to terrorism, major narcotics trafficking and multi-million dollar fraud.” When asked to speak to potential harms to Canadians that could arise from its technology, Clearview stated that any such harms were only hypothetical. Clearview stated that any “harm that a person would suffer from a Clearview search of their image is comparable to the harm that the person suffers when a Google search of his or her name is performed.” Clearview further indicated that no single user could browse their full database as results were only provided for matches, thus mitigating any risk. Clearview stated that even if its database were to be compromised and released, the images therein are all already accessible online, and thus not sensitive, and the vectors that it uses for biometric matching are hashed, Footnote 10 so they are useless outside of the Clearview App. While Clearview originally allowed a variety of public and private organizations to create accounts, we note that in response to our investigation, Clearview stated that it had suspended access to all users in Canada, outside the RCMP , in March 2020. Following further engagement with our Offices during the investigation, Clearview voluntarily exited the Canadian market in July 2020.\n\nComparison with other organizations\n\nClearview asserted that its App is essentially an image search engine and asked our Offices why we were “treating them differently from other search engines”. This investigation focuses on Clearview's practices and not on those of the search engines cited by Clearview. Our Offices initiate and conduct investigations into organizations on the basis of each case’s own particular set of facts. As such, we do not express an opinion on the obligations of any other organizations in this report.\n\nAnalysis\n\nClearview’s jurisdictional challenge\n\nAt the latter stages of our investigation, subsequent to receiving the letter of intention from our Offices seeking a response to the preliminary findings in this matter, Clearview argued that none of our Offices have jurisdiction over its activities, asserting that “[n]one of Clearview’s activities take place in Canada” and that it “is of the view in the circumstances that none of the statutes invoked apply and that no connecting factors create a real and substantial link to Canada.” Clearview submitted that PIPEDA does not apply “because there is no real and substantial connection to Canada.” Specifically, Clearview argued that the circumstances in the matter at hand were such that no real and substantial connection with Canada existed: the content referred to in Clearview’s platform was not “uniquely Canadian” and that it has content from “several other countries all over the world”; Clearview’s services were “not directly and solely directed at Canadians” and that “not many Canadians would have used [its] services”, asserting that “beyond the trial users, the only allegation is that one Canadian entity, the RCMP , would have used Clearview’s services”; and “there [appeared] to be no evidence that Clearview’s services are mainly felt by Canadians”. Clearview further argued that it is not subject to any provincial privacy laws as in its view: it did not collect, use or disclose personal information “within the provinces of Alberta, Quebec or British Columbia, but rather in the United States”; there was “no evidence or allegation” that Clearview did business within said provinces; and collection, use or disclosure had to take place entirely within each province to be applicable under the acts, and that there is “no evidence or allegation” that this took place.\n\nOPC ’s jurisdiction\n\nThe OPC notes that PIPEDA applies to organizations outside of Canada where a “real and substantial connection” to Canada exists. Footnote 11 In our view, the circumstances in this matter clearly demonstrate that a real and substantial connection to Canada exists. In coming to this conclusion, we considered the relevant connecting factors that flow from the jurisprudence, including the factors set out in A.T. v. Globe24h: (1) the location of the target audience of the website, (2) the source of the content on the website, (3) the location of the website operator, and (4) the location of the host server. Footnote 12 Regarding the location of Clearview’s target audience: While Clearview claims that its activity in Canada was limited, this is at odds with the fact that it actively marketed its services to Canadian organizations through promotional material, testimonials from Canadian law enforcement professionals, and agency-specific presentations and trials. Furthermore, Clearview publicly declared Canada to be part of its core market in statements to the media Footnote 13 and its own promotional materials. Footnote 14 The fact that only one agency became a paying customer is, in our view, immaterial. The colour and character of Clearview’s activities were commercial in nature, with trials existing for the express purpose of enticing the purchase of accounts. Clearview’s representations confirmed that 48 accounts (trial or otherwise) were created for law enforcement agencies and organizations across Canada, and thousands of searches were conducted through these accounts. In particular, we note that various provincial law enforcement agencies used trial accounts of the App for several months, with the number of searches conducted per trial account ranging from tens, to hundreds, or in one case, thousands. Furthermore, dismissing the RCMP as only “one Canadian entity” ignores the fact that the RCMP is Canada’s national law enforcement agency, operating all over Canada with national, federal, provincial, and municipal policing mandates. Regarding the source of Clearview’s content: It is not a requirement that Clearview’s content be exclusively derived from Canadian sources for there to be a real and substantial connection to Canada. As set out in Lawson v. Accusearch Inc., it is not necessary to identify specific Canadian sources of content to determine we have jurisdiction. Clearview’s assertion that it collects images without regard to geography or source does not preclude our jurisdiction when a substantial amount of its content is sourced from Canada. The exact number of images derived from individuals in Canada is unknown due to the fact that Clearview does not retain the national source. However, the indiscriminate nature of Clearview’s scraping renders it a relative certainty that it collected millions of images of individuals in Canada, Footnote 15 and used them to derive biometric image vectors for its database, including to market to Canadian law enforcement agencies. Finally, regarding the location of Clearview’s website operations and host server: We note that Clearview’s activities take place exclusively through a website or app. As referenced in paragraph 54 of A.T. v. Globe24h.com, a physical presence in Canada is not required to establish a real and substantial connection when considering websites under PIPEDA , as telecommunications occur “both here and there.” Clearview’s operations necessitate the transmission and receipt of personal information between Canada and the USA, both when collecting information and disclosing it through its software. As set out by the Supreme Court of Canada Footnote 16: “Receipt may be no less “significant” a connecting factor than the point of origin (not to mention the physical location of the host server, which may be in a third country).”\n\nProvincial jurisdiction\n\nWe further reject Clearview’s assertion that it is not subject to PIPA AB , PIPA BC or Quebec’s Private Sector Act (the Provincial Acts), respectively, and are of the view that Clearview’s activities fall under the jurisdiction of both the OPC and the provinces. Footnote 17 Provincial privacy legislation applies to any private sector organization that collects, uses and discloses information of individuals within that province. Clearview’s practice of indiscriminate scraping has undoubtedly resulted in the collection of the personal information of individuals within Quebec, Alberta and British Columbia, whose residents collectively account for nearly half of the Canadian population. In addition, provincial and municipal law enforcement agencies located within the provinces and subject to provincial oversight were targeted and used trial accounts of Clearview’s software, in the course of which they provided, and Clearview collected, personal information in the form of photographs of individuals. Footnote 18 Clearview is a commercial enterprise that collected, used, and disclosed personal information of individuals within Quebec, Alberta and British Columbia with the intention of selling a product to law enforcement agencies within the provinces. The fact that a company is located outside of Quebec, Alberta and British Columbia, does not mean it can evade obligations under Quebec’s Private Sector Act, PIPA AB and PIPA BC . Indeed, whenever a company collects the personal information of individuals located within a province, regardless of where the company is located, the Provincial Acts apply. Footnote 19 Considering the above, the Offices do not accept Clearview’s assertion that provincial legislation does not apply and are of the view that: the Provincial Acts apply, as previously stated; the Provincial Acts do not prevent the achievement of PIPEDA ’s objective, nor do they result in operational conflict or conflict of intent; each Provincial Act has been found to be substantially similar to PIPEDA . Footnote 20\n\nIssue 1: Did Clearview obtain requisite consent?\n\nIn our view, Clearview did not obtain consent required for its collection, use and disclosure of personal information through the App. In coming to this determination, we note that Clearview made no attempt whatsoever to obtain consent from individuals, given its erroneous interpretation of Canadian privacy law, which sets out when information is “publicly available” or “public under the law”. The Acts state that the consent of the individual is required for the collection, use or disclosure of personal information unless an exception applies. Footnote 21 The type of consent required will vary depending on the circumstances and the type of information involved. The Guidelines for obtaining meaningful consent Footnote 22 (the Guidelines) jointly issued by the OPC , OIPC AB and OIPC BC provide that “organizations must generally obtain express consent” when: (i) the information being collected, used or disclosed is sensitive; (ii) the collection, use or disclosure is outside of the reasonable expectations of the individual; and/or (iii) the collection, use or disclosure creates a meaningful residual risk of significant harm. Beyond Clearview’s collection of images, we also note that its creation of biometric information in the form of vectors constituted a distinct and additional collection and use of personal information, as previously found by the OPC , OIPC AB and OIPC BC in the matter of Cadillac Fairview. Footnote 23 With respect to biometric characteristics and measurements, Quebec’s LCCJTI specifically requires the express consent of the person concerned. Consent is described as express when it is explicit and unequivocal. To give express consent, a person must perform a positive action that clearly demonstrates his or her agreement. Footnote 24 To perform such an action, the person must be informed about what his or her consent entails. Footnote 25 The consent must be free, enlightened, given for specific purposes and limited in time. Footnote 26 In our view, biometric information is sensitive in almost all circumstances. It is intrinsically, and in most instances permanently, linked to the individual. It is distinctive, unlikely to vary over time, difficult to change and largely unique to the individual. That being said, within the category of biometric information, there are degrees of sensitivity. It is our view that facial biometric information is particularly sensitive. Possession of a facial recognition template can allow for identification of an individual through comparison against a vast array of images readily available on the Internet, as demonstrated in the matter at hand, or via surreptitious surveillance. For these reasons, it is our view that in the absence of an applicable exception, Clearview should have obtained express opt-in consent before it collected the images of any individual in Canada. In its submissions, Clearview acknowledged that it did not seek consent from the individuals whose information it collected, used or disclosed. Clearview argued that the information it collected was “publicly available” and that there was thus no reasonable expectation of privacy. Our Offices note that PIPEDA , PIPA BC and PIPA AB have exceptions to the requirement for consent where the personal information at issue is publicly available as set out in section 7(1)(d) of PIPEDA , sections 12(1)(e), 15(1)(e) and 18(1)(e) of PIPA BC , and sections 14(e), 17(e) and 20(j) of PIPA AB . The definition of “publicly available” is provided by each Act’s regulations Footnote 27 and is distinct from a common understanding of “publicly accessible” information. Information from sources such as social media or professional profiles, collected from public websites and then used for an unrelated purpose, does not fall under the “publicly available” exception of PIPEDA . Footnote 28 Similarly, the respective regulations of both PIPA AB and PIPA BC Footnote 29 prescribe sources of public information that include directories, registries, and publications. Social media websites and search engines are not listed as prescribed sources of publicly available information under either of these Acts. As such, collection from these sources would only be authorized with consent and only if the purposes are what a reasonable person would consider appropriate. Footnote 30 Quebec’s Private Sector Act and LCCJTI do not distinguish, and make no allowance for, “publicly available information.” However, Quebec’s Private Sector Act does not apply to information “which by law is public.” There are no Quebec statutes under which personal information is deemed to be public solely based on the fact that it has been posted on social media or the Web. Moreover, the CAI has previously ruled that, even where personal information has been posted on a public website, it does not mean that the information may be used for other purposes without the consent of the person concerned. Footnote 31 The fact that images are published on a website does not necessarily mean that their author has consented to their use by a third party. As such, our Offices do not recognize the personal information collected, used or disclosed by Clearview to be “publicly available” as envisioned by the Acts, or as information “which by law is public,” and thus the exception does not apply. As Clearview made no attempt to obtain consent, and no exception from the requirement to obtain consent is found to be applicable, we find that Clearview contravened sections 6.1 as well Principle 4.3 of Schedule 1 of PIPEDA , section 7 of PIPA AB , sections 6-8 of PIPA BC , sections 6 and 12-14 of Quebec’s Private Sector Act and section 44 of the LCCJTI .\n\nClearview’s response regarding consent\n\nIn its response, Clearview stated that: “With respect to the consent obligation under federal and provincial legislation, and assuming, without waiving the lack of jurisdiction invoked above that such laws apply, Clearview submits that the exception for publications which are publicly available applies. Information collected by Clearview is nothing more than information available to the public.” Clearview argued that its collection of information qualified under the exception set out in regulation for “personal information that appears in a publication, including a magazine, book or newspaper, in printed or electronic form, that is available to the public, where the individual has provided the information.” Footnote 32 In regard to Quebec’s legislation, which does not contain such exceptions, Clearview argued that the exception must necessarily be implied. It argued that otherwise, “the legislation is invalid because it breaches the Quebec and Canadian Charter guarantees of freedom of expression.” The respondent further argued that the regulatory definition of publicly available information “is not distinct from the common understanding of the words” and that while Parliament “did define some categories of items that may be included in what is said to be public, it did not restrict the definition with respect to publication,” stating that: “In Clearview’s submission, the definition [of a publication] could hardly be broader. As a result, personal information located on public blogs, public social media or any other public websites are included in the “publicly available” exception as they are included in the definition of a publication. Therefore, the collection of such information does not require consent.” In support of its position, Clearview cited the Federal Court of Appeal’s decision in Lukács v. Canada, Footnote 33 stating that “this decision makes it clear that these terms are not narrow and include any publication that is “available or accessible by the citizenry at large.” Clearview further submitted that the expectation of privacy for information in the public view “is or should be reduced” and that a broad interpretation of publicly available information should be preferred, stating: “Even if the regulation and its exceptions are ambiguous, and require an exercise in interpretation, they must be interpreted in accordance with the Canadian Charter. Restricting the free flow of publicly available information is contrary to the constitutional protection of freedom of expression. For this reason, exceptions to this principle must be narrowly construed and a broad interpretation of publicly available must be preferred so as not to unduly limit freedom of expression.” Finally, Clearview argued that: “In these circumstances, […] the positive effects of protecting personal information do not outweigh the negative effects on Clearview's freedom of expression. There is no pressing and substantial concern justifying an infringement on freedom of expression given the lack of a reasonable expectation of privacy in images that individuals themselves have already either placed or permitted to be placed in the public domain.” Based on these arguments, Clearview asserted that it did not contravene any of the Acts, as all of the information it collected and used was exempted as publicly available. As we note in paragraph 36, Clearview did not make any attempt to seek consent from individuals. Instead Clearview relies entirely on its argument that the personal information it collected, used and disclosed was publicly available and thus exempted from consent requirements. In considering Clearview’s submissions, our Offices have concluded that this view is incorrect, and that the exemption does not apply in the circumstances of this case. As set out in PIPEDA and confirmed in Turner v. Telus Communications Inc. Footnote 34, information will only be deemed “publicly available” if both publicly available and specified by the regulations. Clearview further argued that a “plain language” interpretation of the regulations was appropriate, and that it followed that a broad definition of the term “publication,” should be applied when considering whether the exemption applies. Clearview further argued that such a broad interpretation would be in accordance with the Canadian Charter of Rights and Freedoms (the Charter), namely freedom of expression. We do not accept this to be the case based on the facts, law or available jurisprudence as outlined below. It is our view that Lukács c. Canada is not applicable to the matter at hand, as it concerns the application of the Privacy Act, which is distinct from PIPEDA . In particular, we note that unlike in the Privacy Act, the meaning of “publicly available information” and what qualifies as a “publication” is specifically defined in PIPEDA , PIPA AB Footnote 35 and PIPA BC Footnote 36 by regulation (the Regulations). The Regulations thus take precedence. When interpreting the Regulations, we note that as privacy legislation is considered by the courts to be quasi-constitutional, Footnote 37 the rights accorded under them should be given a broad, purposive and liberal interpretation, and restrictions on those rights should be interpreted narrowly. Footnote 38 Since the Regulations create an exemption to a core privacy protection – the requirement for collection, use and disclosure of personal information to be with consent - they should be interpreted narrowly. With this in mind, we do not accept Clearview’s arguments in favour of a wider “plain language” interpretation. For example, social media, from which Clearview obtained a significant proportion of the images in its database, is not specified as a “publication” in the language of the PIPEDA regulations. It is the OPC ’s view that social media web pages differ substantially from the sources identified in the PIPEDA regulations. As the OPC previously found in the matter of Profile Technology, Footnote 39 there are a number of key differences between online information sources such as social media, and the examples of “publications” included in 1(e): social media web pages contain dynamic content, with new information being added, changed or deleted in real-time; and individuals exercise a level of direct control, a fundamental component of privacy protection, over their social media accounts, and over accessibility to associated content over time – for example, via privacy settings. In addition, the OIPC BC also takes the position that social media websites are not prescribed sources of “publicly available” information, and any collection from these sources would only be authorized with consent and only if the purposes are what a reasonable person would consider appropriate. Ultimately, Clearview’s assertions that publication necessarily includes “public blogs, public social media or any other public websites,” taken to their natural conclusion, imply that all publicly accessible content on the Internet is a publication in some form or other. This would create an extremely broad exemption that undermines the control users may otherwise maintain over their information at the source. In this regard, it has been noted that control is a fundamental component of privacy protection. Footnote 40 Even if such web pages were to be considered “publications” in the meaning of the Regulations, which we do not accept, s. 1 (e) of the PIPEDA Regulations and s. 7(e) of the PIPA AB Regulations specify that the exception only applies “where the individual has provided the information,” or where “it is reasonable to assume that the individual that the information is about provided that information,” respectively. As Clearview engages in mass collection of images through automated tools, it is inevitable that in many instances, the images would have instead been uploaded by a third party. Clearview argued that Quebec’s Private Sector Act implicitly includes an exclusion for “publicly available” personal information—because if it did not it would violate the freedom of expression. The CAI is of the view that argument cannot be accepted for the following reasons: The text of the Act clearly indicates that only information that is public “by law” is excluded, which does not include information that is otherwise available to the public in the absence of a law designating it as public. As a quasi-constitutional law that takes precedence over other legislation in Quebec, and has the purpose of clarifying the exercise of rights conferred by the Civil Code of Québec, specifically the right to privacy, any exceptions must be interpreted restrictively. Therefore, there exists no implied exclusion from Quebec’s Private Sector Act for publicly available information not designated as public by law. Because Clearview did not inform the AG as required by section 76 of the Code of Civil Procedure, the Commission cannot consider claims raised by Clearview suggesting that the Act respecting the private sector is inoperative. Indeed, such a review cannot take place if the Attorney General of Quebec has not been informed or been given an opportunity to make representations. Nor does it suffice to raise a freedom of expression violation. Clearview has neither explained nor demonstrated how its activities constitute the expression of a message relating to the pursuit of truth, participation in the community or individual self-fulfillment and human flourishing. Footnote 41\n\nIssue 2: Was Clearview collecting, using or disclosing personal information for an appropriate purpose?\n\nIn our view, for the reasons outlined below, Clearview’s purpose for collecting, using or disclosing personal information was neither appropriate nor legitimate. In accordance with the OPC ’s Guidance on inappropriate data practices: Interpretation and application of subsection 5(3), Footnote 42 the OPC considers the factors Footnote 43 set out by the courts in order to assist in determining whether a reasonable person would find that an organization’s collection, use and disclosure of information is for an appropriate purpose in the circumstances. These factors are to be applied in a contextual manner, which suggests flexibility and variability in accordance with the circumstances. Footnote 44 In applying s. 5(3), the courts have determined that the OPC is required to engage in a “balancing of interests” between the individual’s right to privacy and the commercial needs of the organization concerned. Footnote 45 This balancing of interests must be “viewed through the eyes of a reasonable person.” Footnote 46 Similar factors are also considered by OIPC BC in determining whether the purpose is reasonable. Footnote 47 Section 2 of PIPA AB says that in determining whether a thing or matter is reasonable or unreasonable, the standard to be applied is “what a reasonable person would consider appropriate in the circumstances”. Orders issued by the OIPC AB have also identified a number of questions for determining whether the collection of personal information in an instance was for a reasonable purpose, Footnote 48 including whether the collection of personal information was carried out in a reasonable manner. Finally, in analyzing whether Clearview had a serious and legitimate reason to establish a file on another person under section 4 of Quebec’s Private Sector Act, the CAI considers the lawfulness of the objective sought and its compliance with the law, justice and fairness. Footnote 49 We find that the collection of images and creation of biometric facial recognition arrays by Clearview, for its stated purpose of providing a service to law enforcement personnel, and use by others via trial accounts, represents the mass identification and surveillance of individuals by a private entity in the course of commercial activity. In our view, for the reasons outlined below, a reasonable person would not consider this purpose to be appropriate, reasonable, or legitimate in the circumstances, within the meaning of subsection 5(3) of the PIPEDA , sections 11, 14 and 17 of PIPA BC , Footnote 50 sections 11, 16 and 19 of PIPA AB and section 4 of Quebec’s Private Sector Act. As previously indicated, our Offices find the information at issue (facial biometrics generated from digital images) to be of a sensitive nature. Biometric information is distinctive, unlikely to vary over time, difficult to change and largely unique to the individual. Facial biometric data is particularly sensitive given that it is a key to an individual’s identity, supporting the ability to identify and surveil individuals. We further note that the additional contextual information provided via source links (that is, social media and websites) can include significant personal information of varying levels of sensitivity. Further, Clearview’s collection of information includes the mass indiscriminate collection of the personal information of minors, which would be considered particularly sensitive. It is our view that Clearview does not, in the circumstances, have an appropriate purpose, for: the mass and indiscriminate scraping of images from millions of individuals across Canada, including children, amongst over 3 billion images scraped world-wide; the development of biometric facial recognition arrays based on these images, and the retention of this information even after the source image or link has been removed from the Internet; or the subsequent use and disclosure of that information for its own commercial purposes; where such purposes: are unrelated to the purposes for which the images were originally posted (for example, social media or professional networking); are often to the detriment of the individual (for example, investigation, potential prosecution, embarrassment, etc.); and create the risk of significant harm to individuals whose images are captured by Clearview (including harms associated with misidentification or exposure to potential data breaches), where the vast majority of those individuals have never been and will never be implicated in a crime, or identified to assist in the resolution of a serious crime. Furthermore, Clearview’s collection of sensitive biometric personal information, as described above, was not, in our view, carried out in a legal manner. Clearview collects the information to populate its facial recognition database without obtaining express consent of the individuals in question, as required by the Acts, or any form of knowledge or consent for that matter. Clearview did not collect the information directly from the individuals in question. Nor did it have any relationship with the third parties whose websites it scraped, who could have, hypothetically, obtained consent for Clearview’s purposes. In fact, several of these third parties have made credible allegations that Clearview was not authorized to collect the information from their websites. As such, Clearview achieved its purposes via collection that inherently contravened Canadian privacy laws. Therefore, those purposes cannot in our view be considered appropriate. Consequently, we find that Clearview contravened: subsection 5(3) of the PIPEDA , section 4 of Quebec’s Private Sector Act, sections 11, 14 and 17 of PIPA BC and sections 11, 16 and 19 of PIPA AB .\n\nClearview’s Response Regarding Appropriate Purposes\n\nClearview disagreed with our preliminary characterization of its purposes and stated that its collection of information was to “enable law enforcement agencies to obtain information quickly and accurately in the course of an ongoing investigation” and that a reasonable person would consider this purpose to be “appropriate, reasonable and legitimate in the circumstances.” Clearview re-iterated its view that this information was publicly available and thus not sensitive. Clearview asserted that: “the difference between the purposes for which the images were originally posted and the ones for which Clearview used, collected, or disclosed them is irrelevant. If the purposes underlying Clearview's actions are appropriate and legitimate, it is reasonable to believe that Clearview has complied with this section of the law even if such images are not used, collected or disclosed for the same reason they were posted originally.” Clearview also asserted that any detriment to individuals resulting from the use of its services could not be imputed to Clearview, stating that: “Prosecution by law enforcement agencies using Clearview's services is in no way a direct and unique consequence of the services offered. Clearview cannot be held responsible for offering services to an entity that subsequently makes an error in its assessment of the person being investigated. Many factors will be taken into account by law enforcement agencies when doing their work. Clearview provides potential matches – just as witnesses provide potential identification in a line-up or eye-witness testimony. Law enforcement officials must ultimately determine the suitable use to be made of such information in the course of their investigations.” Clearview argued that a characterization of its purposes as detrimental to individuals was incorrect, stating: “Clearview's objectives are not to the detriment of individuals, but rather to the benefit of the community and the public interest by assisting law enforcement agencies responsible for public safety in their inquiries. Limiting such a service would arguably be at the expense of the public interest. Clearview facilitates research by providing a platform that contains all the information needed, information that is already available but dispersed on several third-party websites.” Clearview further argued that the only potential harm to most individuals would be that a link to a photo might be sent to a law enforcement agency, which in their view could not be described as significant. It opined that such potential harm was not disproportionate to the “benefits and objectives to which [Clearview] contributes.” Clearview concluded by referencing the purpose clause of PIPEDA , stating that: “when determining whether there are appropriate purposes involved, one must evaluate the balance between the privacy right of an individual and the need of organizations to collect, use or disclose personal information.” and that: “Given the significant potential benefit of Clearview's services to law enforcement and national security on the one hand, and the fact that significant harm is unlikely to occur on the other, especially considering that the information held is already publicly available and is distributed to law enforcement agencies for legitimate investigative purposes only, Clearview’s purposes are entirely appropriate.” We are not convinced by Clearview’s arguments, which cite the same jurisprudence that we have relied on. We remain of the view, based on our analysis outlined above in paragraphs 73 to 78, that Clearview is collecting sensitive biometric personal information, for purposes that a reasonable person would not consider appropriate in the circumstances. Whereas law enforcement agencies rely on the broad collection authority for their operations found in public-sector privacy legislation, these actions are circumscribed by the Charter and Clearview enjoys no such collection authority as a private organization. Although some of the information collected may have ultimately been used for law enforcement, Clearview’s real purpose for the collection is a commercial for-profit enterprise and not law enforcement. Footnote 51 Finally, we note that Clearview emphasizes the absence of harms to individuals flowing from its activities. In taking this position, Clearview fails to acknowledge: (i) the myriad of instances where false, or misapplied matches could result in reputational damage to individuals, and (ii) more fundamentally, the affront to individuals’ privacy rights and broad-based harm inflicted on all members of society, who find themselves under continual mass surveillance by Clearview based on its indiscriminate scraping and processing of their facial images.\n\nAdditional concerns in relation to appropriate purposes\n\nWe note a number of additional issues. We will not specifically opine on them, but we continue to have significant concerns about them in the context of Clearview’s facial recognition practices.\n\nAccuracy\n\nWhile our Offices did not complete a technical assessment of the accuracy of Clearview’s facial recognition technology, we recognize a number of concerns related to facial recognition technology, generally. Our Offices accept that facial recognition technologies may be used to render many services to society and individuals, and have a number of legitimate uses in business and government. For example we recognize that facial recognition can assist businesses with identity authentication, or law enforcement agencies in the investigation of serious and complex crimes. However, while facial recognition technology, and Clearview’s technology in particular, may be effective in certain circumstances, we note that there are significant concerns regarding the efficacy and accuracy of facial recognition technologies, in particular with respect to certain demographics. Despite advances in the sophistication of facial recognition technology through the increase of computational capacity, the improvement of underlying algorithms and the availability of huge volumes of data, such technologies are not perfect and can result in misidentification. This can be the result of a variety of factors, including the quality of photos/videos and the performance of algorithms used to compare facial characteristics. In particular, our Offices take note of claims of accuracy concerns stemming from a variety of studies and investigations of facial recognition algorithms found in a number of technology solutions. Accuracy issues in facial recognition technology can take two general forms: (i) failure to identify an individual whose face is recorded in the reference database, referred to as a “false-negative”; or (ii) matching faces that actually belong to two different individuals, referred to as a “false positive.” While the former is an issue primarily for the users of facial recognition technology, the latter presents compelling risks of harm to individuals, particularly when facial recognition is used in the context of law enforcement. Footnote 52 In particular, we refer to reports that facial recognition technology has been found to have significantly higher incidences of false positives or misidentifications when assessing the faces of people of colour, and especially women of colour, which could result in discriminatory treatment for those individuals. Footnote 53 For example, research conducted by NIST (National Institute of Standards and Technology) found that the rate of false positives for Asian and Black individuals was often greater than that for Caucasians, by a factor of 10 to 100 times. Footnote 54 Harms resulting from such misidentification can range from individuals being excluded from opportunities, to individuals being investigated and detained based on incorrect information. Such harms would generally be classified as significant. Footnote 55 We note that Clearview commissioned an independent panel to complete an accuracy test of their technology, which it claimed was based on the methodology of a previous test conducted by the American Civil Liberties Union ( ACLU ). A copy of the results from this test was provided in Clearview’s representations, and reported a 100% accuracy rate for Clearview’s technology. During our investigation we found that significant concerns, regarding the testing methodology and conclusions, had been raised by a variety of researchers, including the ACLU ’s own team, who characterized the study as “misleading,” and lodged a complaint with Clearview. Footnote 56 In its submissions, Clearview argued that the ACLU and other critics had failed to demonstrate how the results of the test were misleading. It reiterated that in testing, Clearview’s App correctly matched all the images it searched for, with no inaccuracies. While our Office will not opine on the merits of such complaints, we do note the persistent theme of concerns raised in relation to the opacity of Clearview’s technology, which is proprietary and inaccessible to the majority of researchers, make it difficult to make determinations on accuracy.\n\nCollection in contravention of contractual terms\n\nWe note that Clearview has received cease-and-desist letters from Google, Facebook, Twitter, YouTube and LinkedIn regarding their practice of collecting information in violation of terms of service. Footnote 57 Clearview represented that it has responded to these cease-and-desist requests by asserting a First Amendment right to scrape “public” information under the U.S. Constitution. Clearview also asserted that contractual terms have no bearing on our investigation or the appropriateness of its purposes. While we do not opine on whether or not one or more contractual violations occurred, to the extent that Clearview scraped personal information in contravention of platforms’ contractual terms, it would in our view, be relevant as a further factor in considering the inappropriateness of Clearview’s purposes, in the circumstances.\n\nRisk of harm arising from breach\n\nThe large amount of sensitive biometric information held by Clearview would in our view, make it a high value target for malicious actors. Clearview argued that “risk of harm from breach is not an appropriate consideration when assessing the purposes of Clearview’s actions, as this would go well beyond the scope of the law, which is to establish rules that recognize the right of privacy of individuals,” claiming that this risk is present in “almost all areas of society.” It further argued that even if such risks were taken into account, there was no risk of significant harm or likelihood of the information being stolen. While we will not opine on Clearview’s safeguards, which are outside the scope of this investigation, we do note that Clearview publicly announced that it was breached on two occasions within the past year. Once in February 2020 when its client list was leaked, Footnote 58 and again in April 2020 when its source code and pilot project video were obtained and partially leaked. Footnote 59 In our view, Clearview’s collection and subsequent use of billions of images and facial arrays which are linked to source data, represents a significant risk to tens of millions of individuals in Canada should it be compromised.\n\nIssue 3: Did Clearview satisfy its biometric obligations in Quebec?\n\nWhen a company builds a biometrics system in Quebec, it must comply with the rules set out in Quebec’s Private Sector Act and the LCCJTI . Indeed, it must in particular: obtain the express consent of the person concerned, in line with s. 44 of the LCCJTI ; and disclose the creation or existence of the biometrics system to the CAI in line with s. 45 of the LCCJTI . It is apparent from the investigation that Clearview failed to obtain the express consent of the persons concerned, as Clearview has acknowledged that no attempt to seek consent was made. Furthermore, the company failed to disclose the existence of its biometrics system to the CAI .\n\nClearview’s response regarding Quebec’s biometric law\n\nClearview argues that it did not build a biometric system in Quebec, since its activities take place in the United States. Noting that a provincial statute cannot apply extraterritorially in the absence of the express or implied will of the legislature, Clearview concludes that the LCCJTI cannot apply to it, because that would give the law extraterritorial scope that no provision could confer on it, whether explicitly or implicitly. The CAI does not share Clearview’s opinion with respect to the LCCJTI . Indeed, since Clearview does not deny having built a biometric system, the CAI is of the opinion that, even if the biometric system is located outside of Quebec, Clearview has nevertheless collected images in the course of operating a business in Quebec and must therefore obtain the express consent of these individuals before verifying or confirming their identity. The essence of the LCCJTI provisions at issue are respect for the privacy of the individuals concerned and the protection of their personal information. The intention that this mandatory obligation be applied to all persons is made very clear in the French version by the use of the word “ nul ”. The extraterritorial effects are incidental. Clearview, by offering its services within the territorial boundaries of the province and collecting and using the personal information of Quebecers, is operating a business in Quebec. Accordingly, Clearview is subject to the applicable legislation in the jurisdiction in which it is carrying out its activities, namely, the province of Quebec. Footnote 60 Clearview’s physical location and the site of its principal activities are therefore incidental and do not shelter it from the application of the LCCJTI . Therefore, Clearview must obtain the express consent of individuals before verifying or confirming their identity ( s. 44 of the LCCJTI ), as noted in paragraph 40. The sensitivity of the information collected, used or disclosed and the impact that the use of this information may have on the privacy of the individuals concerned requires that they be informed and express their consent. A biometric system cannot be used without the knowledge of the individuals involved. Footnote 61 Clearview was also required to disclose its database of biometric characteristics and measurements to the Commission, in accordance with section 45 of the LCCJTI . Consequently, the CAI finds that Clearview contravened sections 44 and 45 of the LCCJTI .\n\nRecommendations\n\nIn our letter of intention, we shared with Clearview that we could order or recommend to: cease offering the facial recognition services that have been the subject of this investigation to clients in Canada; cease the collection, use and disclosure of images and biometric facial arrays collected from individuals in Canada; and delete images and biometric facial arrays collected from individuals in Canada in its possession. With respect to the first recommendation, we asked Clearview to confirm that it would not resume its offer to provide the facial recognition services in Canada in the future. We also sought Clearview’s commitments explaining how and when it would implement the second and third recommendations.\n\nClearview’s response to our conclusions\n\nAs detailed in this report, Clearview expressly disagreed with our conclusions. Despite this, noting that following engagement with our Offices, it had voluntarily withdrawn from the Canadian market earlier in the investigation, Clearview indicated that it was “prepared to consider maintaining this status for a further two years, in order to allow the various Commissioners to provide detailed and meaningful guidelines as to how Canadian law proposes to deal with artificial intelligence.” Clearview suggested that as it was not “currently active” in Canada, our Offices should suspend our investigation and refrain from issuing a report or making a final determination on this matter. Clearview indicated that “during such a suspension, [it] would be willing to take steps, on a best efforts and without prejudice basis, to try to limit the collection and distribution of the images that it is able to identify as Canadian…” As of the time of writing this report, Clearview had not committed to following our recommendations or orders under consideration, and the Offices deemed it appropriate to issue this report.\n\nConclusions",
            "url": "https://www.priv.gc.ca/en/opc-actions-and-decisions/investigations/investigations-into-businesses/2021/pipeda-2021-001/",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "personal",
                "pipeda",
                "findings",
                "clearview",
                "office",
                "facial",
                "law",
                "québec",
                "investigation",
                "joint",
                "information",
                "privacy",
                "linformation",
                "individuals",
                "consent",
                "images",
                "à",
                "footnote",
                "clearviews"
            ],
            "summary": "BackgroundThis report of investigation examines Clearview AI, Inc.’s (Clearview) compliance with Canada’s Personal Information Protection and Electronic Documents Act ( PIPEDA ), Quebec’s Act Respecting the Protection of Personal Information in the Private Sector (Quebec’s Private Sector Act), and Act to Establish a Legal Framework for Information Technology ( LCCJTI ), British Columbia’s Personal Information Protection Act ( PIPA BC ), and Alberta’s Personal Information Protection Act ( PIPA AB ) – referred to collectively as the Acts.\nWe further note that the additional contextual information provided via source links (that is, social media and websites) can include significant personal information of varying levels of sensitivity.\nFurther, Clearview’s collection of information includes the mass indiscriminate collection of the personal information of minors, which would be considered particularly sensitive.\nWe will not specifically opine on them, but we continue to have significant concerns about them in the context of Clearview’s facial recognition practices.\nThe essence of the LCCJTI provisions at issue are respect for the privacy of the individuals concerned and the protection of their personal information.",
            "metadata": {
                "source_domain": "www.priv.gc.ca",
                "scrape_date": "2024-10-25T12:40:26.615273",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 63449
            }
        },
        {
            "title": "PIPEDA Findings #2021-001: Joint investigation of Clearview AI, Inc. by the Office of the Privacy Commissioner of Canada, the Commission d’accès à l’information du Québec, the Information and Privacy ",
            "text": "PIPEDA Findings #2021-001\n\nFebruary 2, 2021\n\nOverview\n\nThe Privacy Commissioner of Canada ( OPC ), the Commission d’accès à l’information du Québec ( CAI ), the Information and Privacy Commissioner for British Columbia ( OIPC BC ), and the Information and Privacy Commissioner of Alberta ( OIPC AB ), collectively referred to as “the Offices”, commenced a joint investigationFootnote 1 to examine whether Clearview AI, Inc.’s (“Clearview”) collection, use and disclosure of the personal information by means of its facial recognition tool complied with federal and provincial privacy laws applicable to the private sector.\n\nSpecifically, the Offices sought to determine whether Clearview:\n\nobtained requisite consent to collect, use and disclose personal information; and collected, used and disclosed personal information for an appropriate purpose Footnote 2.\n\nAdditionally, the CAI sought to determine whether Clearview had:\n\nReported the creation of a database of biometric characteristics or measurements.\n\nClearview’s facial recognition tool functions in four key sequential steps - Clearview:\n\n“scrapes” images of faces and associated data from publicly accessible online sources (including social media), and stores that information in its database; creates biometric identifiers in the form of numerical representations for each image; allows users to upload an image, which is then assessed against those biometric identifiers and matched to images in its database; and provides a list of results, containing all matching images and metadata. If a user clicks on any of these results, they are directed to the original source page of the image.\n\nThrough this process, Clearview amassed a database of over three billion images of faces and corresponding biometric identifiers, including those of a vast number of individuals in Canada, including children.\n\nClearview asserted that the tool is intended for use by law enforcement,Footnote 3 for legitimate law enforcement and investigative purposes. A variety of organizations, including private sector entities, used this service via a free-trial service.\n\nBiometric information is considered sensitive, in almost all circumstances, and facial recognition data is particularly sensitive. Furthermore, individuals who posted their images online, or whose images were posted by third party(ies), had no reasonable expectations that Clearview would collect, use and disclose their images for identification purposes. As such, express consent would generally be required. In Quebec, such use of biometric data requires express consent.\n\nClearview did not attempt to seek consent from the individuals whose information it collected. Clearview asserted that the information was “publicly available”, and thus exempt from consent requirements. Information collected from public websites, such as social media or professional profiles, and then used for an unrelated purpose, does not fall under the “publicly available” exception of PIPEDA , PIPA AB or PIPA BC . Nor is this information “public by law”, which would exempt it from Quebec’s Private Sector Law, and no exception of this nature exists for other biometric data under LCCJTI . Therefore, we found that Clearview was not exempt from the requirement to obtain consent.\n\nFurthermore, the Offices determined that Clearview collected, used and disclosed the personal information of individuals in Canada for inappropriate purposes, which cannot be rendered appropriate via consent. We found that the mass collection of images and creation of biometric facial recognition arrays by Clearview, for its stated purpose of providing a service to law enforcement personnel, and use by others via trial accounts, represents the mass identification and surveillance of individuals by a private entity in the course of commercial activity. We found Clearview’s purposes to be inappropriate where they: (i) are unrelated to the purposes for which those images were originally posted; (ii) will often be to the detriment of the individual whose images are captured; and (iii) create the risk of significant harm to those individuals, the vast majority of whom have never been and will never be implicated in a crime. Furthermore, it collected images in an unreasonable manner, via indiscriminate scraping of publicly accessible websites.\n\nWe identified certain other concerns on which we did not ultimately opine, but which we felt appropriate to raise in our report. This includes the fact that there were credible challenges to, and questions regarding, the efficacy and accuracy of facial recognition technologies generally, and regarding the reliability of Clearview’s testing results specifically.\n\nWe shared our preliminary findings and recommendations with Clearview, with a view to bringing it into compliance with federal and provincial private sector privacy law. We recommended that Clearview: (i) cease offering its facial recognition tool to clients in Canada; (ii) cease the collection, use and disclosure of images and biometric facial arrays collected from individuals in Canada; and (iii) delete images and biometric facial arrays collected from individuals in Canada in its possession.\n\nClearview expressly disagreed with our findings.\n\nIn disagreeing with our findings, Clearview alleged an absence of harms to individuals flowing from its activities. In our view, Clearview’s position fails to acknowledge: (i) the myriad of instances where false, or misapplied matches could result in reputational damage, and (ii) more fundamentally, the affront to individuals’ privacy rights and broad-based harm inflicted on all members of society, who find themselves under continual mass surveillance by Clearview based on its indiscriminate scraping and processing of their facial images.\n\nIn terms of remedies, noting that it had withdrawn from the Canadian market during our investigation, Clearview stated that it was “prepared to consider” remaining outside of the Canadian market for a further two years, while our Offices developed relevant guidance. Clearview suggested that it would be appropriate for our Offices to suspend our investigation and not issue this final report, and that during such a suspension, it “would be willing to take steps, on a best efforts and without prejudice basis, to try to limit the collection and distribution of the images that it is able to identify as Canadian” [emphasis added]. Clearview has not committed to following our recommendations. The Offices view it as inappropriate to suspend the investigation and not issue this Report. We therefore find the matter to be well-founded and restate the recommendations in our preliminary findings.\n\nAdditionally, the CAI determined that contrary to the requirements of the LCCJTI , Clearview had not advised the CAI that it had created a database of biometric characteristics, nor obtained the express consent from individuals that verifying or confirming their identity would be conducted using a facial recognition process.\n\nBackground\n\nThis report of investigation examines Clearview AI, Inc.’s (Clearview) compliance with Canada’s Personal Information Protection and Electronic Documents Act ( PIPEDA ), Quebec’s Act Respecting the Protection of Personal Information in the Private Sector (Quebec’s Private Sector Act), and Act to Establish a Legal Framework for Information Technology ( LCCJTI ), British Columbia’s Personal Information Protection Act ( PIPA BC ), and Alberta’s Personal Information Protection Act ( PIPA AB ) – referred to collectively as the Acts. Clearview is a technology company headquartered in the United States that developed and delivered its facial recognition Footnote 4 software and combined database solution (App) to clients around the world. Clearview’s App allows clients to upload a digital image of an individual’s face and run a search against it. The App then applies its algorithm to the digital image and runs the result against Clearview’s database to identify and display likely matches and associated source information. In January and February 2020, public reports Footnote 5 indicated that Clearview was populating its facial recognition database by collecting digital images from a variety of public websites, including but not limited to, Facebook, YouTube, Instagram, Twitter and Venmo, in apparent violation of those organizations’ terms of service and without the consent of individuals. It was further indicated that these digital images were then indefinitely stored in Clearview’s database to be sourced and served as results for facial recognition searches. In February 2020, multiple reports Footnote 6 surfaced confirming that a number of Canadian law enforcement agencies and private organizations Footnote 7 had used Clearview’s services in order to identify individuals. Satisfied that reasonable grounds existed to investigate these matters, in February 2020, the Office of the Privacy Commissioner of Canada ( OPC ), the Commission d’accès à l’information du Québec ( CAI ), the Information and Privacy Commissioner for British Columbia ( OIPC BC ), and the Information and Privacy Commissioner of Alberta ( OIPC AB ), collectively referred to as the Offices, each initiated investigations pursuant to s. 11(2) of PIPEDA , s. 81 of Quebec’s Private Sector Act, s. 36(1)(a) of PIPA BC , and s. 36(1)(a) of PIPA AB respectively. The Offices decided to conduct the investigation jointly in order to maximize their expertise and their resources, while avoiding duplication of their efforts and those of Clearview.\n\nIssues\n\nThe issues in this investigation were: Whether Clearview was required under the Acts to get consent for its collection, use and disclosure of personal information and if so, whether it did; and Whether Clearview collected, used and/or disclosed personal information for a purpose that a reasonable person would consider appropriate in the circumstances, for a purpose that was reasonable and to fulfill a legitimate need? Footnote 8 The following Quebec-specific issue was also examined: Did Clearview previously disclose to the CAI the creation of a database of biometric characteristics or measurements? During the course of the investigation, specifically after the letter of intention referred to in paragraph 11 below, Clearview also asserted that our Offices do not have jurisdiction over the Clearview activities in question. We address this issue in our analysis, prior to considering the issues identified above.\n\nMethodology\n\nIn addition to conducting extensive open-source research, the investigative team (the team) analyzed representations provided by Clearview and records relating to its activities. The team also examined representations from a number of third parties identified as possible users of Clearview’s service. Between February and November 2020, Clearview provided multiple sets of written representations to our Offices. Furthermore, we gave Clearview multiple opportunities to meet with us to make inquiries and provide additional evidence. We conducted two such meetings in June 2020. Upon completion of the evidence-gathering phase of the joint investigation, our Offices issued a letter of intention to Clearview on October 29 2020, which set out and explained the rationale for our preliminary findings, identified several orders and recommendations under consideration and invited Clearview to respond. We then met with Clearview on November 17 to clarify our views, provide an opportunity to ask any questions, and discuss potential remedies to resolve the matter. On November 20, Clearview provided a written response articulating its disagreement with our preliminary findings and orders and recommendations under consideration. In this letter, Clearview set out a variety of new arguments, and provided new information which our Offices considered and assessed before producing this report of findings.\n\nClearview’s representations and our investigation\n\nThis section reflects initial representations provided by Clearview up to the point of the issuance of our letter of intention. Further representations provided by Clearview in its response to our letter of intention are included under our analysis of each issue.\n\nOverview of Clearview’s facial recognition implementation\n\nIn its submissions, Clearview explained that its facial recognition technology is based on five primary components: (i) image crawler, (ii) image store, (iii) metadata store, (iv) neural network and (v) vector database. The image crawler is an automated tool that searches public web pages and collects any images that it identifies as containing faces along with associated metadata such as the title, source link and description. This process is commonly referred to as “scraping.” The images and metadata collected through this scraping process are indefinitely stored on Clearview’s servers in the image and metadata stores respectively. The neural network underpins the algorithm that analyzes digital images of faces and turns them into numerical representations referred to as “vectors”. Clearview’s vectors consist of 512 data points that represent the various unique lines that make up a face. Clearview then stores all of these vectors in their vector database, where they are associated with the images stored on Clearview’s server. Every image in the database has a vector associated with it in order to allow identification and matching. When an App user wishes to identify an individual, they are required to upload an image of their target into the App and run a search. The neural network then analyzes the image and produces a vector. This vector is then compared against all vectors stored in Clearview’s database, with the App pulling any matching images from the vector database and providing them to the user, along with any associated metadata, as search results. Clearview stated that images uploaded by users are stored separately from images obtained from scraping, and do not show up in any search results. Clearview advised that its search results are displayed in a list containing thumbnail images that appear to be a match for the individual, the name of the image, description and source link. The user must then click the associated source link to be re-directed to the web page where the image was originally collected, in order to obtain additional information. Clearview stated that it “[does] not possess or maintain any information about names, addresses, nationality, date of birth [or] location” associated with the images in its database.\n\nClearview’s privacy practices regarding consent\n\nClearview originally stated that it does not seek consent from individuals whose information it collects. Rather, Clearview stated that in its view, the images it collected were publicly available and therefore it did not require the knowledge or consent of individuals to collect their information. In support of this position, Clearview stated that it only collected images from publicly-viewable web pages, and did not collect any images protected by privacy settings, such as those associated with certain social media accounts, or from pages that enabled “robots.txt”. Footnote 9 Clearview has confirmed that their image crawler is configured to respect whatever instructions are present in the robots.txt file.\n\nClearview’s purposes\n\nIn its initial representations, Clearview advised our Offices that its App was intended to be for the sole and exclusive use of law enforcement. This was reflected in Clearview’s terms of service, which state that “Users may use [the] Service for legitimate law enforcement and investigative purposes” and that “users may not use the Service for any reason other than law enforcement or investigative purposes.” In response to our letter of intention, Clearview advised that previously, its terms of service also extended access to “security professionals”. Clearview asserted that their technology provides “substantial, concrete benefits to public safety by dramatically increasing law enforcement’s ability to identify and investigate suspects, victims and witnesses.” Clearview pointed to numerous successes in cases ranging from “murder, armed robbery and child sexual exploitation to terrorism, major narcotics trafficking and multi-million dollar fraud.” When asked to speak to potential harms to Canadians that could arise from its technology, Clearview stated that any such harms were only hypothetical. Clearview stated that any “harm that a person would suffer from a Clearview search of their image is comparable to the harm that the person suffers when a Google search of his or her name is performed.” Clearview further indicated that no single user could browse their full database as results were only provided for matches, thus mitigating any risk. Clearview stated that even if its database were to be compromised and released, the images therein are all already accessible online, and thus not sensitive, and the vectors that it uses for biometric matching are hashed, Footnote 10 so they are useless outside of the Clearview App. While Clearview originally allowed a variety of public and private organizations to create accounts, we note that in response to our investigation, Clearview stated that it had suspended access to all users in Canada, outside the RCMP , in March 2020. Following further engagement with our Offices during the investigation, Clearview voluntarily exited the Canadian market in July 2020.\n\nComparison with other organizations\n\nClearview asserted that its App is essentially an image search engine and asked our Offices why we were “treating them differently from other search engines”. This investigation focuses on Clearview's practices and not on those of the search engines cited by Clearview. Our Offices initiate and conduct investigations into organizations on the basis of each case’s own particular set of facts. As such, we do not express an opinion on the obligations of any other organizations in this report.\n\nAnalysis\n\nClearview’s jurisdictional challenge\n\nAt the latter stages of our investigation, subsequent to receiving the letter of intention from our Offices seeking a response to the preliminary findings in this matter, Clearview argued that none of our Offices have jurisdiction over its activities, asserting that “[n]one of Clearview’s activities take place in Canada” and that it “is of the view in the circumstances that none of the statutes invoked apply and that no connecting factors create a real and substantial link to Canada.” Clearview submitted that PIPEDA does not apply “because there is no real and substantial connection to Canada.” Specifically, Clearview argued that the circumstances in the matter at hand were such that no real and substantial connection with Canada existed: the content referred to in Clearview’s platform was not “uniquely Canadian” and that it has content from “several other countries all over the world”; Clearview’s services were “not directly and solely directed at Canadians” and that “not many Canadians would have used [its] services”, asserting that “beyond the trial users, the only allegation is that one Canadian entity, the RCMP , would have used Clearview’s services”; and “there [appeared] to be no evidence that Clearview’s services are mainly felt by Canadians”. Clearview further argued that it is not subject to any provincial privacy laws as in its view: it did not collect, use or disclose personal information “within the provinces of Alberta, Quebec or British Columbia, but rather in the United States”; there was “no evidence or allegation” that Clearview did business within said provinces; and collection, use or disclosure had to take place entirely within each province to be applicable under the acts, and that there is “no evidence or allegation” that this took place.\n\nOPC ’s jurisdiction\n\nThe OPC notes that PIPEDA applies to organizations outside of Canada where a “real and substantial connection” to Canada exists. Footnote 11 In our view, the circumstances in this matter clearly demonstrate that a real and substantial connection to Canada exists. In coming to this conclusion, we considered the relevant connecting factors that flow from the jurisprudence, including the factors set out in A.T. v. Globe24h: (1) the location of the target audience of the website, (2) the source of the content on the website, (3) the location of the website operator, and (4) the location of the host server. Footnote 12 Regarding the location of Clearview’s target audience: While Clearview claims that its activity in Canada was limited, this is at odds with the fact that it actively marketed its services to Canadian organizations through promotional material, testimonials from Canadian law enforcement professionals, and agency-specific presentations and trials. Furthermore, Clearview publicly declared Canada to be part of its core market in statements to the media Footnote 13 and its own promotional materials. Footnote 14 The fact that only one agency became a paying customer is, in our view, immaterial. The colour and character of Clearview’s activities were commercial in nature, with trials existing for the express purpose of enticing the purchase of accounts. Clearview’s representations confirmed that 48 accounts (trial or otherwise) were created for law enforcement agencies and organizations across Canada, and thousands of searches were conducted through these accounts. In particular, we note that various provincial law enforcement agencies used trial accounts of the App for several months, with the number of searches conducted per trial account ranging from tens, to hundreds, or in one case, thousands. Furthermore, dismissing the RCMP as only “one Canadian entity” ignores the fact that the RCMP is Canada’s national law enforcement agency, operating all over Canada with national, federal, provincial, and municipal policing mandates. Regarding the source of Clearview’s content: It is not a requirement that Clearview’s content be exclusively derived from Canadian sources for there to be a real and substantial connection to Canada. As set out in Lawson v. Accusearch Inc., it is not necessary to identify specific Canadian sources of content to determine we have jurisdiction. Clearview’s assertion that it collects images without regard to geography or source does not preclude our jurisdiction when a substantial amount of its content is sourced from Canada. The exact number of images derived from individuals in Canada is unknown due to the fact that Clearview does not retain the national source. However, the indiscriminate nature of Clearview’s scraping renders it a relative certainty that it collected millions of images of individuals in Canada, Footnote 15 and used them to derive biometric image vectors for its database, including to market to Canadian law enforcement agencies. Finally, regarding the location of Clearview’s website operations and host server: We note that Clearview’s activities take place exclusively through a website or app. As referenced in paragraph 54 of A.T. v. Globe24h.com, a physical presence in Canada is not required to establish a real and substantial connection when considering websites under PIPEDA , as telecommunications occur “both here and there.” Clearview’s operations necessitate the transmission and receipt of personal information between Canada and the USA, both when collecting information and disclosing it through its software. As set out by the Supreme Court of Canada Footnote 16: “Receipt may be no less “significant” a connecting factor than the point of origin (not to mention the physical location of the host server, which may be in a third country).”\n\nProvincial jurisdiction\n\nWe further reject Clearview’s assertion that it is not subject to PIPA AB , PIPA BC or Quebec’s Private Sector Act (the Provincial Acts), respectively, and are of the view that Clearview’s activities fall under the jurisdiction of both the OPC and the provinces. Footnote 17 Provincial privacy legislation applies to any private sector organization that collects, uses and discloses information of individuals within that province. Clearview’s practice of indiscriminate scraping has undoubtedly resulted in the collection of the personal information of individuals within Quebec, Alberta and British Columbia, whose residents collectively account for nearly half of the Canadian population. In addition, provincial and municipal law enforcement agencies located within the provinces and subject to provincial oversight were targeted and used trial accounts of Clearview’s software, in the course of which they provided, and Clearview collected, personal information in the form of photographs of individuals. Footnote 18 Clearview is a commercial enterprise that collected, used, and disclosed personal information of individuals within Quebec, Alberta and British Columbia with the intention of selling a product to law enforcement agencies within the provinces. The fact that a company is located outside of Quebec, Alberta and British Columbia, does not mean it can evade obligations under Quebec’s Private Sector Act, PIPA AB and PIPA BC . Indeed, whenever a company collects the personal information of individuals located within a province, regardless of where the company is located, the Provincial Acts apply. Footnote 19 Considering the above, the Offices do not accept Clearview’s assertion that provincial legislation does not apply and are of the view that: the Provincial Acts apply, as previously stated; the Provincial Acts do not prevent the achievement of PIPEDA ’s objective, nor do they result in operational conflict or conflict of intent; each Provincial Act has been found to be substantially similar to PIPEDA . Footnote 20\n\nIssue 1: Did Clearview obtain requisite consent?\n\nIn our view, Clearview did not obtain consent required for its collection, use and disclosure of personal information through the App. In coming to this determination, we note that Clearview made no attempt whatsoever to obtain consent from individuals, given its erroneous interpretation of Canadian privacy law, which sets out when information is “publicly available” or “public under the law”. The Acts state that the consent of the individual is required for the collection, use or disclosure of personal information unless an exception applies. Footnote 21 The type of consent required will vary depending on the circumstances and the type of information involved. The Guidelines for obtaining meaningful consent Footnote 22 (the Guidelines) jointly issued by the OPC , OIPC AB and OIPC BC provide that “organizations must generally obtain express consent” when: (i) the information being collected, used or disclosed is sensitive; (ii) the collection, use or disclosure is outside of the reasonable expectations of the individual; and/or (iii) the collection, use or disclosure creates a meaningful residual risk of significant harm. Beyond Clearview’s collection of images, we also note that its creation of biometric information in the form of vectors constituted a distinct and additional collection and use of personal information, as previously found by the OPC , OIPC AB and OIPC BC in the matter of Cadillac Fairview. Footnote 23 With respect to biometric characteristics and measurements, Quebec’s LCCJTI specifically requires the express consent of the person concerned. Consent is described as express when it is explicit and unequivocal. To give express consent, a person must perform a positive action that clearly demonstrates his or her agreement. Footnote 24 To perform such an action, the person must be informed about what his or her consent entails. Footnote 25 The consent must be free, enlightened, given for specific purposes and limited in time. Footnote 26 In our view, biometric information is sensitive in almost all circumstances. It is intrinsically, and in most instances permanently, linked to the individual. It is distinctive, unlikely to vary over time, difficult to change and largely unique to the individual. That being said, within the category of biometric information, there are degrees of sensitivity. It is our view that facial biometric information is particularly sensitive. Possession of a facial recognition template can allow for identification of an individual through comparison against a vast array of images readily available on the Internet, as demonstrated in the matter at hand, or via surreptitious surveillance. For these reasons, it is our view that in the absence of an applicable exception, Clearview should have obtained express opt-in consent before it collected the images of any individual in Canada. In its submissions, Clearview acknowledged that it did not seek consent from the individuals whose information it collected, used or disclosed. Clearview argued that the information it collected was “publicly available” and that there was thus no reasonable expectation of privacy. Our Offices note that PIPEDA , PIPA BC and PIPA AB have exceptions to the requirement for consent where the personal information at issue is publicly available as set out in section 7(1)(d) of PIPEDA , sections 12(1)(e), 15(1)(e) and 18(1)(e) of PIPA BC , and sections 14(e), 17(e) and 20(j) of PIPA AB . The definition of “publicly available” is provided by each Act’s regulations Footnote 27 and is distinct from a common understanding of “publicly accessible” information. Information from sources such as social media or professional profiles, collected from public websites and then used for an unrelated purpose, does not fall under the “publicly available” exception of PIPEDA . Footnote 28 Similarly, the respective regulations of both PIPA AB and PIPA BC Footnote 29 prescribe sources of public information that include directories, registries, and publications. Social media websites and search engines are not listed as prescribed sources of publicly available information under either of these Acts. As such, collection from these sources would only be authorized with consent and only if the purposes are what a reasonable person would consider appropriate. Footnote 30 Quebec’s Private Sector Act and LCCJTI do not distinguish, and make no allowance for, “publicly available information.” However, Quebec’s Private Sector Act does not apply to information “which by law is public.” There are no Quebec statutes under which personal information is deemed to be public solely based on the fact that it has been posted on social media or the Web. Moreover, the CAI has previously ruled that, even where personal information has been posted on a public website, it does not mean that the information may be used for other purposes without the consent of the person concerned. Footnote 31 The fact that images are published on a website does not necessarily mean that their author has consented to their use by a third party. As such, our Offices do not recognize the personal information collected, used or disclosed by Clearview to be “publicly available” as envisioned by the Acts, or as information “which by law is public,” and thus the exception does not apply. As Clearview made no attempt to obtain consent, and no exception from the requirement to obtain consent is found to be applicable, we find that Clearview contravened sections 6.1 as well Principle 4.3 of Schedule 1 of PIPEDA , section 7 of PIPA AB , sections 6-8 of PIPA BC , sections 6 and 12-14 of Quebec’s Private Sector Act and section 44 of the LCCJTI .\n\nClearview’s response regarding consent\n\nIn its response, Clearview stated that: “With respect to the consent obligation under federal and provincial legislation, and assuming, without waiving the lack of jurisdiction invoked above that such laws apply, Clearview submits that the exception for publications which are publicly available applies. Information collected by Clearview is nothing more than information available to the public.” Clearview argued that its collection of information qualified under the exception set out in regulation for “personal information that appears in a publication, including a magazine, book or newspaper, in printed or electronic form, that is available to the public, where the individual has provided the information.” Footnote 32 In regard to Quebec’s legislation, which does not contain such exceptions, Clearview argued that the exception must necessarily be implied. It argued that otherwise, “the legislation is invalid because it breaches the Quebec and Canadian Charter guarantees of freedom of expression.” The respondent further argued that the regulatory definition of publicly available information “is not distinct from the common understanding of the words” and that while Parliament “did define some categories of items that may be included in what is said to be public, it did not restrict the definition with respect to publication,” stating that: “In Clearview’s submission, the definition [of a publication] could hardly be broader. As a result, personal information located on public blogs, public social media or any other public websites are included in the “publicly available” exception as they are included in the definition of a publication. Therefore, the collection of such information does not require consent.” In support of its position, Clearview cited the Federal Court of Appeal’s decision in Lukács v. Canada, Footnote 33 stating that “this decision makes it clear that these terms are not narrow and include any publication that is “available or accessible by the citizenry at large.” Clearview further submitted that the expectation of privacy for information in the public view “is or should be reduced” and that a broad interpretation of publicly available information should be preferred, stating: “Even if the regulation and its exceptions are ambiguous, and require an exercise in interpretation, they must be interpreted in accordance with the Canadian Charter. Restricting the free flow of publicly available information is contrary to the constitutional protection of freedom of expression. For this reason, exceptions to this principle must be narrowly construed and a broad interpretation of publicly available must be preferred so as not to unduly limit freedom of expression.” Finally, Clearview argued that: “In these circumstances, […] the positive effects of protecting personal information do not outweigh the negative effects on Clearview's freedom of expression. There is no pressing and substantial concern justifying an infringement on freedom of expression given the lack of a reasonable expectation of privacy in images that individuals themselves have already either placed or permitted to be placed in the public domain.” Based on these arguments, Clearview asserted that it did not contravene any of the Acts, as all of the information it collected and used was exempted as publicly available. As we note in paragraph 36, Clearview did not make any attempt to seek consent from individuals. Instead Clearview relies entirely on its argument that the personal information it collected, used and disclosed was publicly available and thus exempted from consent requirements. In considering Clearview’s submissions, our Offices have concluded that this view is incorrect, and that the exemption does not apply in the circumstances of this case. As set out in PIPEDA and confirmed in Turner v. Telus Communications Inc. Footnote 34, information will only be deemed “publicly available” if both publicly available and specified by the regulations. Clearview further argued that a “plain language” interpretation of the regulations was appropriate, and that it followed that a broad definition of the term “publication,” should be applied when considering whether the exemption applies. Clearview further argued that such a broad interpretation would be in accordance with the Canadian Charter of Rights and Freedoms (the Charter), namely freedom of expression. We do not accept this to be the case based on the facts, law or available jurisprudence as outlined below. It is our view that Lukács c. Canada is not applicable to the matter at hand, as it concerns the application of the Privacy Act, which is distinct from PIPEDA . In particular, we note that unlike in the Privacy Act, the meaning of “publicly available information” and what qualifies as a “publication” is specifically defined in PIPEDA , PIPA AB Footnote 35 and PIPA BC Footnote 36 by regulation (the Regulations). The Regulations thus take precedence. When interpreting the Regulations, we note that as privacy legislation is considered by the courts to be quasi-constitutional, Footnote 37 the rights accorded under them should be given a broad, purposive and liberal interpretation, and restrictions on those rights should be interpreted narrowly. Footnote 38 Since the Regulations create an exemption to a core privacy protection – the requirement for collection, use and disclosure of personal information to be with consent - they should be interpreted narrowly. With this in mind, we do not accept Clearview’s arguments in favour of a wider “plain language” interpretation. For example, social media, from which Clearview obtained a significant proportion of the images in its database, is not specified as a “publication” in the language of the PIPEDA regulations. It is the OPC ’s view that social media web pages differ substantially from the sources identified in the PIPEDA regulations. As the OPC previously found in the matter of Profile Technology, Footnote 39 there are a number of key differences between online information sources such as social media, and the examples of “publications” included in 1(e): social media web pages contain dynamic content, with new information being added, changed or deleted in real-time; and individuals exercise a level of direct control, a fundamental component of privacy protection, over their social media accounts, and over accessibility to associated content over time – for example, via privacy settings. In addition, the OIPC BC also takes the position that social media websites are not prescribed sources of “publicly available” information, and any collection from these sources would only be authorized with consent and only if the purposes are what a reasonable person would consider appropriate. Ultimately, Clearview’s assertions that publication necessarily includes “public blogs, public social media or any other public websites,” taken to their natural conclusion, imply that all publicly accessible content on the Internet is a publication in some form or other. This would create an extremely broad exemption that undermines the control users may otherwise maintain over their information at the source. In this regard, it has been noted that control is a fundamental component of privacy protection. Footnote 40 Even if such web pages were to be considered “publications” in the meaning of the Regulations, which we do not accept, s. 1 (e) of the PIPEDA Regulations and s. 7(e) of the PIPA AB Regulations specify that the exception only applies “where the individual has provided the information,” or where “it is reasonable to assume that the individual that the information is about provided that information,” respectively. As Clearview engages in mass collection of images through automated tools, it is inevitable that in many instances, the images would have instead been uploaded by a third party. Clearview argued that Quebec’s Private Sector Act implicitly includes an exclusion for “publicly available” personal information—because if it did not it would violate the freedom of expression. The CAI is of the view that argument cannot be accepted for the following reasons: The text of the Act clearly indicates that only information that is public “by law” is excluded, which does not include information that is otherwise available to the public in the absence of a law designating it as public. As a quasi-constitutional law that takes precedence over other legislation in Quebec, and has the purpose of clarifying the exercise of rights conferred by the Civil Code of Québec, specifically the right to privacy, any exceptions must be interpreted restrictively. Therefore, there exists no implied exclusion from Quebec’s Private Sector Act for publicly available information not designated as public by law. Because Clearview did not inform the AG as required by section 76 of the Code of Civil Procedure, the Commission cannot consider claims raised by Clearview suggesting that the Act respecting the private sector is inoperative. Indeed, such a review cannot take place if the Attorney General of Quebec has not been informed or been given an opportunity to make representations. Nor does it suffice to raise a freedom of expression violation. Clearview has neither explained nor demonstrated how its activities constitute the expression of a message relating to the pursuit of truth, participation in the community or individual self-fulfillment and human flourishing. Footnote 41\n\nIssue 2: Was Clearview collecting, using or disclosing personal information for an appropriate purpose?\n\nIn our view, for the reasons outlined below, Clearview’s purpose for collecting, using or disclosing personal information was neither appropriate nor legitimate. In accordance with the OPC ’s Guidance on inappropriate data practices: Interpretation and application of subsection 5(3), Footnote 42 the OPC considers the factors Footnote 43 set out by the courts in order to assist in determining whether a reasonable person would find that an organization’s collection, use and disclosure of information is for an appropriate purpose in the circumstances. These factors are to be applied in a contextual manner, which suggests flexibility and variability in accordance with the circumstances. Footnote 44 In applying s. 5(3), the courts have determined that the OPC is required to engage in a “balancing of interests” between the individual’s right to privacy and the commercial needs of the organization concerned. Footnote 45 This balancing of interests must be “viewed through the eyes of a reasonable person.” Footnote 46 Similar factors are also considered by OIPC BC in determining whether the purpose is reasonable. Footnote 47 Section 2 of PIPA AB says that in determining whether a thing or matter is reasonable or unreasonable, the standard to be applied is “what a reasonable person would consider appropriate in the circumstances”. Orders issued by the OIPC AB have also identified a number of questions for determining whether the collection of personal information in an instance was for a reasonable purpose, Footnote 48 including whether the collection of personal information was carried out in a reasonable manner. Finally, in analyzing whether Clearview had a serious and legitimate reason to establish a file on another person under section 4 of Quebec’s Private Sector Act, the CAI considers the lawfulness of the objective sought and its compliance with the law, justice and fairness. Footnote 49 We find that the collection of images and creation of biometric facial recognition arrays by Clearview, for its stated purpose of providing a service to law enforcement personnel, and use by others via trial accounts, represents the mass identification and surveillance of individuals by a private entity in the course of commercial activity. In our view, for the reasons outlined below, a reasonable person would not consider this purpose to be appropriate, reasonable, or legitimate in the circumstances, within the meaning of subsection 5(3) of the PIPEDA , sections 11, 14 and 17 of PIPA BC , Footnote 50 sections 11, 16 and 19 of PIPA AB and section 4 of Quebec’s Private Sector Act. As previously indicated, our Offices find the information at issue (facial biometrics generated from digital images) to be of a sensitive nature. Biometric information is distinctive, unlikely to vary over time, difficult to change and largely unique to the individual. Facial biometric data is particularly sensitive given that it is a key to an individual’s identity, supporting the ability to identify and surveil individuals. We further note that the additional contextual information provided via source links (that is, social media and websites) can include significant personal information of varying levels of sensitivity. Further, Clearview’s collection of information includes the mass indiscriminate collection of the personal information of minors, which would be considered particularly sensitive. It is our view that Clearview does not, in the circumstances, have an appropriate purpose, for: the mass and indiscriminate scraping of images from millions of individuals across Canada, including children, amongst over 3 billion images scraped world-wide; the development of biometric facial recognition arrays based on these images, and the retention of this information even after the source image or link has been removed from the Internet; or the subsequent use and disclosure of that information for its own commercial purposes; where such purposes: are unrelated to the purposes for which the images were originally posted (for example, social media or professional networking); are often to the detriment of the individual (for example, investigation, potential prosecution, embarrassment, etc.); and create the risk of significant harm to individuals whose images are captured by Clearview (including harms associated with misidentification or exposure to potential data breaches), where the vast majority of those individuals have never been and will never be implicated in a crime, or identified to assist in the resolution of a serious crime. Furthermore, Clearview’s collection of sensitive biometric personal information, as described above, was not, in our view, carried out in a legal manner. Clearview collects the information to populate its facial recognition database without obtaining express consent of the individuals in question, as required by the Acts, or any form of knowledge or consent for that matter. Clearview did not collect the information directly from the individuals in question. Nor did it have any relationship with the third parties whose websites it scraped, who could have, hypothetically, obtained consent for Clearview’s purposes. In fact, several of these third parties have made credible allegations that Clearview was not authorized to collect the information from their websites. As such, Clearview achieved its purposes via collection that inherently contravened Canadian privacy laws. Therefore, those purposes cannot in our view be considered appropriate. Consequently, we find that Clearview contravened: subsection 5(3) of the PIPEDA , section 4 of Quebec’s Private Sector Act, sections 11, 14 and 17 of PIPA BC and sections 11, 16 and 19 of PIPA AB .\n\nClearview’s Response Regarding Appropriate Purposes\n\nClearview disagreed with our preliminary characterization of its purposes and stated that its collection of information was to “enable law enforcement agencies to obtain information quickly and accurately in the course of an ongoing investigation” and that a reasonable person would consider this purpose to be “appropriate, reasonable and legitimate in the circumstances.” Clearview re-iterated its view that this information was publicly available and thus not sensitive. Clearview asserted that: “the difference between the purposes for which the images were originally posted and the ones for which Clearview used, collected, or disclosed them is irrelevant. If the purposes underlying Clearview's actions are appropriate and legitimate, it is reasonable to believe that Clearview has complied with this section of the law even if such images are not used, collected or disclosed for the same reason they were posted originally.” Clearview also asserted that any detriment to individuals resulting from the use of its services could not be imputed to Clearview, stating that: “Prosecution by law enforcement agencies using Clearview's services is in no way a direct and unique consequence of the services offered. Clearview cannot be held responsible for offering services to an entity that subsequently makes an error in its assessment of the person being investigated. Many factors will be taken into account by law enforcement agencies when doing their work. Clearview provides potential matches – just as witnesses provide potential identification in a line-up or eye-witness testimony. Law enforcement officials must ultimately determine the suitable use to be made of such information in the course of their investigations.” Clearview argued that a characterization of its purposes as detrimental to individuals was incorrect, stating: “Clearview's objectives are not to the detriment of individuals, but rather to the benefit of the community and the public interest by assisting law enforcement agencies responsible for public safety in their inquiries. Limiting such a service would arguably be at the expense of the public interest. Clearview facilitates research by providing a platform that contains all the information needed, information that is already available but dispersed on several third-party websites.” Clearview further argued that the only potential harm to most individuals would be that a link to a photo might be sent to a law enforcement agency, which in their view could not be described as significant. It opined that such potential harm was not disproportionate to the “benefits and objectives to which [Clearview] contributes.” Clearview concluded by referencing the purpose clause of PIPEDA , stating that: “when determining whether there are appropriate purposes involved, one must evaluate the balance between the privacy right of an individual and the need of organizations to collect, use or disclose personal information.” and that: “Given the significant potential benefit of Clearview's services to law enforcement and national security on the one hand, and the fact that significant harm is unlikely to occur on the other, especially considering that the information held is already publicly available and is distributed to law enforcement agencies for legitimate investigative purposes only, Clearview’s purposes are entirely appropriate.” We are not convinced by Clearview’s arguments, which cite the same jurisprudence that we have relied on. We remain of the view, based on our analysis outlined above in paragraphs 73 to 78, that Clearview is collecting sensitive biometric personal information, for purposes that a reasonable person would not consider appropriate in the circumstances. Whereas law enforcement agencies rely on the broad collection authority for their operations found in public-sector privacy legislation, these actions are circumscribed by the Charter and Clearview enjoys no such collection authority as a private organization. Although some of the information collected may have ultimately been used for law enforcement, Clearview’s real purpose for the collection is a commercial for-profit enterprise and not law enforcement. Footnote 51 Finally, we note that Clearview emphasizes the absence of harms to individuals flowing from its activities. In taking this position, Clearview fails to acknowledge: (i) the myriad of instances where false, or misapplied matches could result in reputational damage to individuals, and (ii) more fundamentally, the affront to individuals’ privacy rights and broad-based harm inflicted on all members of society, who find themselves under continual mass surveillance by Clearview based on its indiscriminate scraping and processing of their facial images.\n\nAdditional concerns in relation to appropriate purposes\n\nWe note a number of additional issues. We will not specifically opine on them, but we continue to have significant concerns about them in the context of Clearview’s facial recognition practices.\n\nAccuracy\n\nWhile our Offices did not complete a technical assessment of the accuracy of Clearview’s facial recognition technology, we recognize a number of concerns related to facial recognition technology, generally. Our Offices accept that facial recognition technologies may be used to render many services to society and individuals, and have a number of legitimate uses in business and government. For example we recognize that facial recognition can assist businesses with identity authentication, or law enforcement agencies in the investigation of serious and complex crimes. However, while facial recognition technology, and Clearview’s technology in particular, may be effective in certain circumstances, we note that there are significant concerns regarding the efficacy and accuracy of facial recognition technologies, in particular with respect to certain demographics. Despite advances in the sophistication of facial recognition technology through the increase of computational capacity, the improvement of underlying algorithms and the availability of huge volumes of data, such technologies are not perfect and can result in misidentification. This can be the result of a variety of factors, including the quality of photos/videos and the performance of algorithms used to compare facial characteristics. In particular, our Offices take note of claims of accuracy concerns stemming from a variety of studies and investigations of facial recognition algorithms found in a number of technology solutions. Accuracy issues in facial recognition technology can take two general forms: (i) failure to identify an individual whose face is recorded in the reference database, referred to as a “false-negative”; or (ii) matching faces that actually belong to two different individuals, referred to as a “false positive.” While the former is an issue primarily for the users of facial recognition technology, the latter presents compelling risks of harm to individuals, particularly when facial recognition is used in the context of law enforcement. Footnote 52 In particular, we refer to reports that facial recognition technology has been found to have significantly higher incidences of false positives or misidentifications when assessing the faces of people of colour, and especially women of colour, which could result in discriminatory treatment for those individuals. Footnote 53 For example, research conducted by NIST (National Institute of Standards and Technology) found that the rate of false positives for Asian and Black individuals was often greater than that for Caucasians, by a factor of 10 to 100 times. Footnote 54 Harms resulting from such misidentification can range from individuals being excluded from opportunities, to individuals being investigated and detained based on incorrect information. Such harms would generally be classified as significant. Footnote 55 We note that Clearview commissioned an independent panel to complete an accuracy test of their technology, which it claimed was based on the methodology of a previous test conducted by the American Civil Liberties Union ( ACLU ). A copy of the results from this test was provided in Clearview’s representations, and reported a 100% accuracy rate for Clearview’s technology. During our investigation we found that significant concerns, regarding the testing methodology and conclusions, had been raised by a variety of researchers, including the ACLU ’s own team, who characterized the study as “misleading,” and lodged a complaint with Clearview. Footnote 56 In its submissions, Clearview argued that the ACLU and other critics had failed to demonstrate how the results of the test were misleading. It reiterated that in testing, Clearview’s App correctly matched all the images it searched for, with no inaccuracies. While our Office will not opine on the merits of such complaints, we do note the persistent theme of concerns raised in relation to the opacity of Clearview’s technology, which is proprietary and inaccessible to the majority of researchers, make it difficult to make determinations on accuracy.\n\nCollection in contravention of contractual terms\n\nWe note that Clearview has received cease-and-desist letters from Google, Facebook, Twitter, YouTube and LinkedIn regarding their practice of collecting information in violation of terms of service. Footnote 57 Clearview represented that it has responded to these cease-and-desist requests by asserting a First Amendment right to scrape “public” information under the U.S. Constitution. Clearview also asserted that contractual terms have no bearing on our investigation or the appropriateness of its purposes. While we do not opine on whether or not one or more contractual violations occurred, to the extent that Clearview scraped personal information in contravention of platforms’ contractual terms, it would in our view, be relevant as a further factor in considering the inappropriateness of Clearview’s purposes, in the circumstances.\n\nRisk of harm arising from breach\n\nThe large amount of sensitive biometric information held by Clearview would in our view, make it a high value target for malicious actors. Clearview argued that “risk of harm from breach is not an appropriate consideration when assessing the purposes of Clearview’s actions, as this would go well beyond the scope of the law, which is to establish rules that recognize the right of privacy of individuals,” claiming that this risk is present in “almost all areas of society.” It further argued that even if such risks were taken into account, there was no risk of significant harm or likelihood of the information being stolen. While we will not opine on Clearview’s safeguards, which are outside the scope of this investigation, we do note that Clearview publicly announced that it was breached on two occasions within the past year. Once in February 2020 when its client list was leaked, Footnote 58 and again in April 2020 when its source code and pilot project video were obtained and partially leaked. Footnote 59 In our view, Clearview’s collection and subsequent use of billions of images and facial arrays which are linked to source data, represents a significant risk to tens of millions of individuals in Canada should it be compromised.\n\nIssue 3: Did Clearview satisfy its biometric obligations in Quebec?\n\nWhen a company builds a biometrics system in Quebec, it must comply with the rules set out in Quebec’s Private Sector Act and the LCCJTI . Indeed, it must in particular: obtain the express consent of the person concerned, in line with s. 44 of the LCCJTI ; and disclose the creation or existence of the biometrics system to the CAI in line with s. 45 of the LCCJTI . It is apparent from the investigation that Clearview failed to obtain the express consent of the persons concerned, as Clearview has acknowledged that no attempt to seek consent was made. Furthermore, the company failed to disclose the existence of its biometrics system to the CAI .\n\nClearview’s response regarding Quebec’s biometric law\n\nClearview argues that it did not build a biometric system in Quebec, since its activities take place in the United States. Noting that a provincial statute cannot apply extraterritorially in the absence of the express or implied will of the legislature, Clearview concludes that the LCCJTI cannot apply to it, because that would give the law extraterritorial scope that no provision could confer on it, whether explicitly or implicitly. The CAI does not share Clearview’s opinion with respect to the LCCJTI . Indeed, since Clearview does not deny having built a biometric system, the CAI is of the opinion that, even if the biometric system is located outside of Quebec, Clearview has nevertheless collected images in the course of operating a business in Quebec and must therefore obtain the express consent of these individuals before verifying or confirming their identity. The essence of the LCCJTI provisions at issue are respect for the privacy of the individuals concerned and the protection of their personal information. The intention that this mandatory obligation be applied to all persons is made very clear in the French version by the use of the word “ nul ”. The extraterritorial effects are incidental. Clearview, by offering its services within the territorial boundaries of the province and collecting and using the personal information of Quebecers, is operating a business in Quebec. Accordingly, Clearview is subject to the applicable legislation in the jurisdiction in which it is carrying out its activities, namely, the province of Quebec. Footnote 60 Clearview’s physical location and the site of its principal activities are therefore incidental and do not shelter it from the application of the LCCJTI . Therefore, Clearview must obtain the express consent of individuals before verifying or confirming their identity ( s. 44 of the LCCJTI ), as noted in paragraph 40. The sensitivity of the information collected, used or disclosed and the impact that the use of this information may have on the privacy of the individuals concerned requires that they be informed and express their consent. A biometric system cannot be used without the knowledge of the individuals involved. Footnote 61 Clearview was also required to disclose its database of biometric characteristics and measurements to the Commission, in accordance with section 45 of the LCCJTI . Consequently, the CAI finds that Clearview contravened sections 44 and 45 of the LCCJTI .\n\nRecommendations\n\nIn our letter of intention, we shared with Clearview that we could order or recommend to: cease offering the facial recognition services that have been the subject of this investigation to clients in Canada; cease the collection, use and disclosure of images and biometric facial arrays collected from individuals in Canada; and delete images and biometric facial arrays collected from individuals in Canada in its possession. With respect to the first recommendation, we asked Clearview to confirm that it would not resume its offer to provide the facial recognition services in Canada in the future. We also sought Clearview’s commitments explaining how and when it would implement the second and third recommendations.\n\nClearview’s response to our conclusions\n\nAs detailed in this report, Clearview expressly disagreed with our conclusions. Despite this, noting that following engagement with our Offices, it had voluntarily withdrawn from the Canadian market earlier in the investigation, Clearview indicated that it was “prepared to consider maintaining this status for a further two years, in order to allow the various Commissioners to provide detailed and meaningful guidelines as to how Canadian law proposes to deal with artificial intelligence.” Clearview suggested that as it was not “currently active” in Canada, our Offices should suspend our investigation and refrain from issuing a report or making a final determination on this matter. Clearview indicated that “during such a suspension, [it] would be willing to take steps, on a best efforts and without prejudice basis, to try to limit the collection and distribution of the images that it is able to identify as Canadian…” As of the time of writing this report, Clearview had not committed to following our recommendations or orders under consideration, and the Offices deemed it appropriate to issue this report.\n\nConclusions",
            "url": "https://www.priv.gc.ca/en/opc-actions-and-decisions/investigations/investigations-into-businesses/2021/pipeda-2021-001/#toc1",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "personal",
                "pipeda",
                "findings",
                "clearview",
                "office",
                "facial",
                "law",
                "québec",
                "investigation",
                "joint",
                "information",
                "privacy",
                "linformation",
                "individuals",
                "consent",
                "images",
                "à",
                "footnote",
                "clearviews"
            ],
            "summary": "BackgroundThis report of investigation examines Clearview AI, Inc.’s (Clearview) compliance with Canada’s Personal Information Protection and Electronic Documents Act ( PIPEDA ), Quebec’s Act Respecting the Protection of Personal Information in the Private Sector (Quebec’s Private Sector Act), and Act to Establish a Legal Framework for Information Technology ( LCCJTI ), British Columbia’s Personal Information Protection Act ( PIPA BC ), and Alberta’s Personal Information Protection Act ( PIPA AB ) – referred to collectively as the Acts.\nWe further note that the additional contextual information provided via source links (that is, social media and websites) can include significant personal information of varying levels of sensitivity.\nFurther, Clearview’s collection of information includes the mass indiscriminate collection of the personal information of minors, which would be considered particularly sensitive.\nWe will not specifically opine on them, but we continue to have significant concerns about them in the context of Clearview’s facial recognition practices.\nThe essence of the LCCJTI provisions at issue are respect for the privacy of the individuals concerned and the protection of their personal information.",
            "metadata": {
                "source_domain": "www.priv.gc.ca",
                "scrape_date": "2024-10-25T12:40:27.198350",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 63449
            }
        },
        {
            "title": "PIPEDA Findings #2021-001: Joint investigation of Clearview AI, Inc. by the Office of the Privacy Commissioner of Canada, the Commission d’accès à l’information du Québec, the Information and Privacy ",
            "text": "PIPEDA Findings #2021-001\n\nFebruary 2, 2021\n\nOverview\n\nThe Privacy Commissioner of Canada ( OPC ), the Commission d’accès à l’information du Québec ( CAI ), the Information and Privacy Commissioner for British Columbia ( OIPC BC ), and the Information and Privacy Commissioner of Alberta ( OIPC AB ), collectively referred to as “the Offices”, commenced a joint investigationFootnote 1 to examine whether Clearview AI, Inc.’s (“Clearview”) collection, use and disclosure of the personal information by means of its facial recognition tool complied with federal and provincial privacy laws applicable to the private sector.\n\nSpecifically, the Offices sought to determine whether Clearview:\n\nobtained requisite consent to collect, use and disclose personal information; and collected, used and disclosed personal information for an appropriate purpose Footnote 2.\n\nAdditionally, the CAI sought to determine whether Clearview had:\n\nReported the creation of a database of biometric characteristics or measurements.\n\nClearview’s facial recognition tool functions in four key sequential steps - Clearview:\n\n“scrapes” images of faces and associated data from publicly accessible online sources (including social media), and stores that information in its database; creates biometric identifiers in the form of numerical representations for each image; allows users to upload an image, which is then assessed against those biometric identifiers and matched to images in its database; and provides a list of results, containing all matching images and metadata. If a user clicks on any of these results, they are directed to the original source page of the image.\n\nThrough this process, Clearview amassed a database of over three billion images of faces and corresponding biometric identifiers, including those of a vast number of individuals in Canada, including children.\n\nClearview asserted that the tool is intended for use by law enforcement,Footnote 3 for legitimate law enforcement and investigative purposes. A variety of organizations, including private sector entities, used this service via a free-trial service.\n\nBiometric information is considered sensitive, in almost all circumstances, and facial recognition data is particularly sensitive. Furthermore, individuals who posted their images online, or whose images were posted by third party(ies), had no reasonable expectations that Clearview would collect, use and disclose their images for identification purposes. As such, express consent would generally be required. In Quebec, such use of biometric data requires express consent.\n\nClearview did not attempt to seek consent from the individuals whose information it collected. Clearview asserted that the information was “publicly available”, and thus exempt from consent requirements. Information collected from public websites, such as social media or professional profiles, and then used for an unrelated purpose, does not fall under the “publicly available” exception of PIPEDA , PIPA AB or PIPA BC . Nor is this information “public by law”, which would exempt it from Quebec’s Private Sector Law, and no exception of this nature exists for other biometric data under LCCJTI . Therefore, we found that Clearview was not exempt from the requirement to obtain consent.\n\nFurthermore, the Offices determined that Clearview collected, used and disclosed the personal information of individuals in Canada for inappropriate purposes, which cannot be rendered appropriate via consent. We found that the mass collection of images and creation of biometric facial recognition arrays by Clearview, for its stated purpose of providing a service to law enforcement personnel, and use by others via trial accounts, represents the mass identification and surveillance of individuals by a private entity in the course of commercial activity. We found Clearview’s purposes to be inappropriate where they: (i) are unrelated to the purposes for which those images were originally posted; (ii) will often be to the detriment of the individual whose images are captured; and (iii) create the risk of significant harm to those individuals, the vast majority of whom have never been and will never be implicated in a crime. Furthermore, it collected images in an unreasonable manner, via indiscriminate scraping of publicly accessible websites.\n\nWe identified certain other concerns on which we did not ultimately opine, but which we felt appropriate to raise in our report. This includes the fact that there were credible challenges to, and questions regarding, the efficacy and accuracy of facial recognition technologies generally, and regarding the reliability of Clearview’s testing results specifically.\n\nWe shared our preliminary findings and recommendations with Clearview, with a view to bringing it into compliance with federal and provincial private sector privacy law. We recommended that Clearview: (i) cease offering its facial recognition tool to clients in Canada; (ii) cease the collection, use and disclosure of images and biometric facial arrays collected from individuals in Canada; and (iii) delete images and biometric facial arrays collected from individuals in Canada in its possession.\n\nClearview expressly disagreed with our findings.\n\nIn disagreeing with our findings, Clearview alleged an absence of harms to individuals flowing from its activities. In our view, Clearview’s position fails to acknowledge: (i) the myriad of instances where false, or misapplied matches could result in reputational damage, and (ii) more fundamentally, the affront to individuals’ privacy rights and broad-based harm inflicted on all members of society, who find themselves under continual mass surveillance by Clearview based on its indiscriminate scraping and processing of their facial images.\n\nIn terms of remedies, noting that it had withdrawn from the Canadian market during our investigation, Clearview stated that it was “prepared to consider” remaining outside of the Canadian market for a further two years, while our Offices developed relevant guidance. Clearview suggested that it would be appropriate for our Offices to suspend our investigation and not issue this final report, and that during such a suspension, it “would be willing to take steps, on a best efforts and without prejudice basis, to try to limit the collection and distribution of the images that it is able to identify as Canadian” [emphasis added]. Clearview has not committed to following our recommendations. The Offices view it as inappropriate to suspend the investigation and not issue this Report. We therefore find the matter to be well-founded and restate the recommendations in our preliminary findings.\n\nAdditionally, the CAI determined that contrary to the requirements of the LCCJTI , Clearview had not advised the CAI that it had created a database of biometric characteristics, nor obtained the express consent from individuals that verifying or confirming their identity would be conducted using a facial recognition process.\n\nBackground\n\nThis report of investigation examines Clearview AI, Inc.’s (Clearview) compliance with Canada’s Personal Information Protection and Electronic Documents Act ( PIPEDA ), Quebec’s Act Respecting the Protection of Personal Information in the Private Sector (Quebec’s Private Sector Act), and Act to Establish a Legal Framework for Information Technology ( LCCJTI ), British Columbia’s Personal Information Protection Act ( PIPA BC ), and Alberta’s Personal Information Protection Act ( PIPA AB ) – referred to collectively as the Acts. Clearview is a technology company headquartered in the United States that developed and delivered its facial recognition Footnote 4 software and combined database solution (App) to clients around the world. Clearview’s App allows clients to upload a digital image of an individual’s face and run a search against it. The App then applies its algorithm to the digital image and runs the result against Clearview’s database to identify and display likely matches and associated source information. In January and February 2020, public reports Footnote 5 indicated that Clearview was populating its facial recognition database by collecting digital images from a variety of public websites, including but not limited to, Facebook, YouTube, Instagram, Twitter and Venmo, in apparent violation of those organizations’ terms of service and without the consent of individuals. It was further indicated that these digital images were then indefinitely stored in Clearview’s database to be sourced and served as results for facial recognition searches. In February 2020, multiple reports Footnote 6 surfaced confirming that a number of Canadian law enforcement agencies and private organizations Footnote 7 had used Clearview’s services in order to identify individuals. Satisfied that reasonable grounds existed to investigate these matters, in February 2020, the Office of the Privacy Commissioner of Canada ( OPC ), the Commission d’accès à l’information du Québec ( CAI ), the Information and Privacy Commissioner for British Columbia ( OIPC BC ), and the Information and Privacy Commissioner of Alberta ( OIPC AB ), collectively referred to as the Offices, each initiated investigations pursuant to s. 11(2) of PIPEDA , s. 81 of Quebec’s Private Sector Act, s. 36(1)(a) of PIPA BC , and s. 36(1)(a) of PIPA AB respectively. The Offices decided to conduct the investigation jointly in order to maximize their expertise and their resources, while avoiding duplication of their efforts and those of Clearview.\n\nIssues\n\nThe issues in this investigation were: Whether Clearview was required under the Acts to get consent for its collection, use and disclosure of personal information and if so, whether it did; and Whether Clearview collected, used and/or disclosed personal information for a purpose that a reasonable person would consider appropriate in the circumstances, for a purpose that was reasonable and to fulfill a legitimate need? Footnote 8 The following Quebec-specific issue was also examined: Did Clearview previously disclose to the CAI the creation of a database of biometric characteristics or measurements? During the course of the investigation, specifically after the letter of intention referred to in paragraph 11 below, Clearview also asserted that our Offices do not have jurisdiction over the Clearview activities in question. We address this issue in our analysis, prior to considering the issues identified above.\n\nMethodology\n\nIn addition to conducting extensive open-source research, the investigative team (the team) analyzed representations provided by Clearview and records relating to its activities. The team also examined representations from a number of third parties identified as possible users of Clearview’s service. Between February and November 2020, Clearview provided multiple sets of written representations to our Offices. Furthermore, we gave Clearview multiple opportunities to meet with us to make inquiries and provide additional evidence. We conducted two such meetings in June 2020. Upon completion of the evidence-gathering phase of the joint investigation, our Offices issued a letter of intention to Clearview on October 29 2020, which set out and explained the rationale for our preliminary findings, identified several orders and recommendations under consideration and invited Clearview to respond. We then met with Clearview on November 17 to clarify our views, provide an opportunity to ask any questions, and discuss potential remedies to resolve the matter. On November 20, Clearview provided a written response articulating its disagreement with our preliminary findings and orders and recommendations under consideration. In this letter, Clearview set out a variety of new arguments, and provided new information which our Offices considered and assessed before producing this report of findings.\n\nClearview’s representations and our investigation\n\nThis section reflects initial representations provided by Clearview up to the point of the issuance of our letter of intention. Further representations provided by Clearview in its response to our letter of intention are included under our analysis of each issue.\n\nOverview of Clearview’s facial recognition implementation\n\nIn its submissions, Clearview explained that its facial recognition technology is based on five primary components: (i) image crawler, (ii) image store, (iii) metadata store, (iv) neural network and (v) vector database. The image crawler is an automated tool that searches public web pages and collects any images that it identifies as containing faces along with associated metadata such as the title, source link and description. This process is commonly referred to as “scraping.” The images and metadata collected through this scraping process are indefinitely stored on Clearview’s servers in the image and metadata stores respectively. The neural network underpins the algorithm that analyzes digital images of faces and turns them into numerical representations referred to as “vectors”. Clearview’s vectors consist of 512 data points that represent the various unique lines that make up a face. Clearview then stores all of these vectors in their vector database, where they are associated with the images stored on Clearview’s server. Every image in the database has a vector associated with it in order to allow identification and matching. When an App user wishes to identify an individual, they are required to upload an image of their target into the App and run a search. The neural network then analyzes the image and produces a vector. This vector is then compared against all vectors stored in Clearview’s database, with the App pulling any matching images from the vector database and providing them to the user, along with any associated metadata, as search results. Clearview stated that images uploaded by users are stored separately from images obtained from scraping, and do not show up in any search results. Clearview advised that its search results are displayed in a list containing thumbnail images that appear to be a match for the individual, the name of the image, description and source link. The user must then click the associated source link to be re-directed to the web page where the image was originally collected, in order to obtain additional information. Clearview stated that it “[does] not possess or maintain any information about names, addresses, nationality, date of birth [or] location” associated with the images in its database.\n\nClearview’s privacy practices regarding consent\n\nClearview originally stated that it does not seek consent from individuals whose information it collects. Rather, Clearview stated that in its view, the images it collected were publicly available and therefore it did not require the knowledge or consent of individuals to collect their information. In support of this position, Clearview stated that it only collected images from publicly-viewable web pages, and did not collect any images protected by privacy settings, such as those associated with certain social media accounts, or from pages that enabled “robots.txt”. Footnote 9 Clearview has confirmed that their image crawler is configured to respect whatever instructions are present in the robots.txt file.\n\nClearview’s purposes\n\nIn its initial representations, Clearview advised our Offices that its App was intended to be for the sole and exclusive use of law enforcement. This was reflected in Clearview’s terms of service, which state that “Users may use [the] Service for legitimate law enforcement and investigative purposes” and that “users may not use the Service for any reason other than law enforcement or investigative purposes.” In response to our letter of intention, Clearview advised that previously, its terms of service also extended access to “security professionals”. Clearview asserted that their technology provides “substantial, concrete benefits to public safety by dramatically increasing law enforcement’s ability to identify and investigate suspects, victims and witnesses.” Clearview pointed to numerous successes in cases ranging from “murder, armed robbery and child sexual exploitation to terrorism, major narcotics trafficking and multi-million dollar fraud.” When asked to speak to potential harms to Canadians that could arise from its technology, Clearview stated that any such harms were only hypothetical. Clearview stated that any “harm that a person would suffer from a Clearview search of their image is comparable to the harm that the person suffers when a Google search of his or her name is performed.” Clearview further indicated that no single user could browse their full database as results were only provided for matches, thus mitigating any risk. Clearview stated that even if its database were to be compromised and released, the images therein are all already accessible online, and thus not sensitive, and the vectors that it uses for biometric matching are hashed, Footnote 10 so they are useless outside of the Clearview App. While Clearview originally allowed a variety of public and private organizations to create accounts, we note that in response to our investigation, Clearview stated that it had suspended access to all users in Canada, outside the RCMP , in March 2020. Following further engagement with our Offices during the investigation, Clearview voluntarily exited the Canadian market in July 2020.\n\nComparison with other organizations\n\nClearview asserted that its App is essentially an image search engine and asked our Offices why we were “treating them differently from other search engines”. This investigation focuses on Clearview's practices and not on those of the search engines cited by Clearview. Our Offices initiate and conduct investigations into organizations on the basis of each case’s own particular set of facts. As such, we do not express an opinion on the obligations of any other organizations in this report.\n\nAnalysis\n\nClearview’s jurisdictional challenge\n\nAt the latter stages of our investigation, subsequent to receiving the letter of intention from our Offices seeking a response to the preliminary findings in this matter, Clearview argued that none of our Offices have jurisdiction over its activities, asserting that “[n]one of Clearview’s activities take place in Canada” and that it “is of the view in the circumstances that none of the statutes invoked apply and that no connecting factors create a real and substantial link to Canada.” Clearview submitted that PIPEDA does not apply “because there is no real and substantial connection to Canada.” Specifically, Clearview argued that the circumstances in the matter at hand were such that no real and substantial connection with Canada existed: the content referred to in Clearview’s platform was not “uniquely Canadian” and that it has content from “several other countries all over the world”; Clearview’s services were “not directly and solely directed at Canadians” and that “not many Canadians would have used [its] services”, asserting that “beyond the trial users, the only allegation is that one Canadian entity, the RCMP , would have used Clearview’s services”; and “there [appeared] to be no evidence that Clearview’s services are mainly felt by Canadians”. Clearview further argued that it is not subject to any provincial privacy laws as in its view: it did not collect, use or disclose personal information “within the provinces of Alberta, Quebec or British Columbia, but rather in the United States”; there was “no evidence or allegation” that Clearview did business within said provinces; and collection, use or disclosure had to take place entirely within each province to be applicable under the acts, and that there is “no evidence or allegation” that this took place.\n\nOPC ’s jurisdiction\n\nThe OPC notes that PIPEDA applies to organizations outside of Canada where a “real and substantial connection” to Canada exists. Footnote 11 In our view, the circumstances in this matter clearly demonstrate that a real and substantial connection to Canada exists. In coming to this conclusion, we considered the relevant connecting factors that flow from the jurisprudence, including the factors set out in A.T. v. Globe24h: (1) the location of the target audience of the website, (2) the source of the content on the website, (3) the location of the website operator, and (4) the location of the host server. Footnote 12 Regarding the location of Clearview’s target audience: While Clearview claims that its activity in Canada was limited, this is at odds with the fact that it actively marketed its services to Canadian organizations through promotional material, testimonials from Canadian law enforcement professionals, and agency-specific presentations and trials. Furthermore, Clearview publicly declared Canada to be part of its core market in statements to the media Footnote 13 and its own promotional materials. Footnote 14 The fact that only one agency became a paying customer is, in our view, immaterial. The colour and character of Clearview’s activities were commercial in nature, with trials existing for the express purpose of enticing the purchase of accounts. Clearview’s representations confirmed that 48 accounts (trial or otherwise) were created for law enforcement agencies and organizations across Canada, and thousands of searches were conducted through these accounts. In particular, we note that various provincial law enforcement agencies used trial accounts of the App for several months, with the number of searches conducted per trial account ranging from tens, to hundreds, or in one case, thousands. Furthermore, dismissing the RCMP as only “one Canadian entity” ignores the fact that the RCMP is Canada’s national law enforcement agency, operating all over Canada with national, federal, provincial, and municipal policing mandates. Regarding the source of Clearview’s content: It is not a requirement that Clearview’s content be exclusively derived from Canadian sources for there to be a real and substantial connection to Canada. As set out in Lawson v. Accusearch Inc., it is not necessary to identify specific Canadian sources of content to determine we have jurisdiction. Clearview’s assertion that it collects images without regard to geography or source does not preclude our jurisdiction when a substantial amount of its content is sourced from Canada. The exact number of images derived from individuals in Canada is unknown due to the fact that Clearview does not retain the national source. However, the indiscriminate nature of Clearview’s scraping renders it a relative certainty that it collected millions of images of individuals in Canada, Footnote 15 and used them to derive biometric image vectors for its database, including to market to Canadian law enforcement agencies. Finally, regarding the location of Clearview’s website operations and host server: We note that Clearview’s activities take place exclusively through a website or app. As referenced in paragraph 54 of A.T. v. Globe24h.com, a physical presence in Canada is not required to establish a real and substantial connection when considering websites under PIPEDA , as telecommunications occur “both here and there.” Clearview’s operations necessitate the transmission and receipt of personal information between Canada and the USA, both when collecting information and disclosing it through its software. As set out by the Supreme Court of Canada Footnote 16: “Receipt may be no less “significant” a connecting factor than the point of origin (not to mention the physical location of the host server, which may be in a third country).”\n\nProvincial jurisdiction\n\nWe further reject Clearview’s assertion that it is not subject to PIPA AB , PIPA BC or Quebec’s Private Sector Act (the Provincial Acts), respectively, and are of the view that Clearview’s activities fall under the jurisdiction of both the OPC and the provinces. Footnote 17 Provincial privacy legislation applies to any private sector organization that collects, uses and discloses information of individuals within that province. Clearview’s practice of indiscriminate scraping has undoubtedly resulted in the collection of the personal information of individuals within Quebec, Alberta and British Columbia, whose residents collectively account for nearly half of the Canadian population. In addition, provincial and municipal law enforcement agencies located within the provinces and subject to provincial oversight were targeted and used trial accounts of Clearview’s software, in the course of which they provided, and Clearview collected, personal information in the form of photographs of individuals. Footnote 18 Clearview is a commercial enterprise that collected, used, and disclosed personal information of individuals within Quebec, Alberta and British Columbia with the intention of selling a product to law enforcement agencies within the provinces. The fact that a company is located outside of Quebec, Alberta and British Columbia, does not mean it can evade obligations under Quebec’s Private Sector Act, PIPA AB and PIPA BC . Indeed, whenever a company collects the personal information of individuals located within a province, regardless of where the company is located, the Provincial Acts apply. Footnote 19 Considering the above, the Offices do not accept Clearview’s assertion that provincial legislation does not apply and are of the view that: the Provincial Acts apply, as previously stated; the Provincial Acts do not prevent the achievement of PIPEDA ’s objective, nor do they result in operational conflict or conflict of intent; each Provincial Act has been found to be substantially similar to PIPEDA . Footnote 20\n\nIssue 1: Did Clearview obtain requisite consent?\n\nIn our view, Clearview did not obtain consent required for its collection, use and disclosure of personal information through the App. In coming to this determination, we note that Clearview made no attempt whatsoever to obtain consent from individuals, given its erroneous interpretation of Canadian privacy law, which sets out when information is “publicly available” or “public under the law”. The Acts state that the consent of the individual is required for the collection, use or disclosure of personal information unless an exception applies. Footnote 21 The type of consent required will vary depending on the circumstances and the type of information involved. The Guidelines for obtaining meaningful consent Footnote 22 (the Guidelines) jointly issued by the OPC , OIPC AB and OIPC BC provide that “organizations must generally obtain express consent” when: (i) the information being collected, used or disclosed is sensitive; (ii) the collection, use or disclosure is outside of the reasonable expectations of the individual; and/or (iii) the collection, use or disclosure creates a meaningful residual risk of significant harm. Beyond Clearview’s collection of images, we also note that its creation of biometric information in the form of vectors constituted a distinct and additional collection and use of personal information, as previously found by the OPC , OIPC AB and OIPC BC in the matter of Cadillac Fairview. Footnote 23 With respect to biometric characteristics and measurements, Quebec’s LCCJTI specifically requires the express consent of the person concerned. Consent is described as express when it is explicit and unequivocal. To give express consent, a person must perform a positive action that clearly demonstrates his or her agreement. Footnote 24 To perform such an action, the person must be informed about what his or her consent entails. Footnote 25 The consent must be free, enlightened, given for specific purposes and limited in time. Footnote 26 In our view, biometric information is sensitive in almost all circumstances. It is intrinsically, and in most instances permanently, linked to the individual. It is distinctive, unlikely to vary over time, difficult to change and largely unique to the individual. That being said, within the category of biometric information, there are degrees of sensitivity. It is our view that facial biometric information is particularly sensitive. Possession of a facial recognition template can allow for identification of an individual through comparison against a vast array of images readily available on the Internet, as demonstrated in the matter at hand, or via surreptitious surveillance. For these reasons, it is our view that in the absence of an applicable exception, Clearview should have obtained express opt-in consent before it collected the images of any individual in Canada. In its submissions, Clearview acknowledged that it did not seek consent from the individuals whose information it collected, used or disclosed. Clearview argued that the information it collected was “publicly available” and that there was thus no reasonable expectation of privacy. Our Offices note that PIPEDA , PIPA BC and PIPA AB have exceptions to the requirement for consent where the personal information at issue is publicly available as set out in section 7(1)(d) of PIPEDA , sections 12(1)(e), 15(1)(e) and 18(1)(e) of PIPA BC , and sections 14(e), 17(e) and 20(j) of PIPA AB . The definition of “publicly available” is provided by each Act’s regulations Footnote 27 and is distinct from a common understanding of “publicly accessible” information. Information from sources such as social media or professional profiles, collected from public websites and then used for an unrelated purpose, does not fall under the “publicly available” exception of PIPEDA . Footnote 28 Similarly, the respective regulations of both PIPA AB and PIPA BC Footnote 29 prescribe sources of public information that include directories, registries, and publications. Social media websites and search engines are not listed as prescribed sources of publicly available information under either of these Acts. As such, collection from these sources would only be authorized with consent and only if the purposes are what a reasonable person would consider appropriate. Footnote 30 Quebec’s Private Sector Act and LCCJTI do not distinguish, and make no allowance for, “publicly available information.” However, Quebec’s Private Sector Act does not apply to information “which by law is public.” There are no Quebec statutes under which personal information is deemed to be public solely based on the fact that it has been posted on social media or the Web. Moreover, the CAI has previously ruled that, even where personal information has been posted on a public website, it does not mean that the information may be used for other purposes without the consent of the person concerned. Footnote 31 The fact that images are published on a website does not necessarily mean that their author has consented to their use by a third party. As such, our Offices do not recognize the personal information collected, used or disclosed by Clearview to be “publicly available” as envisioned by the Acts, or as information “which by law is public,” and thus the exception does not apply. As Clearview made no attempt to obtain consent, and no exception from the requirement to obtain consent is found to be applicable, we find that Clearview contravened sections 6.1 as well Principle 4.3 of Schedule 1 of PIPEDA , section 7 of PIPA AB , sections 6-8 of PIPA BC , sections 6 and 12-14 of Quebec’s Private Sector Act and section 44 of the LCCJTI .\n\nClearview’s response regarding consent\n\nIn its response, Clearview stated that: “With respect to the consent obligation under federal and provincial legislation, and assuming, without waiving the lack of jurisdiction invoked above that such laws apply, Clearview submits that the exception for publications which are publicly available applies. Information collected by Clearview is nothing more than information available to the public.” Clearview argued that its collection of information qualified under the exception set out in regulation for “personal information that appears in a publication, including a magazine, book or newspaper, in printed or electronic form, that is available to the public, where the individual has provided the information.” Footnote 32 In regard to Quebec’s legislation, which does not contain such exceptions, Clearview argued that the exception must necessarily be implied. It argued that otherwise, “the legislation is invalid because it breaches the Quebec and Canadian Charter guarantees of freedom of expression.” The respondent further argued that the regulatory definition of publicly available information “is not distinct from the common understanding of the words” and that while Parliament “did define some categories of items that may be included in what is said to be public, it did not restrict the definition with respect to publication,” stating that: “In Clearview’s submission, the definition [of a publication] could hardly be broader. As a result, personal information located on public blogs, public social media or any other public websites are included in the “publicly available” exception as they are included in the definition of a publication. Therefore, the collection of such information does not require consent.” In support of its position, Clearview cited the Federal Court of Appeal’s decision in Lukács v. Canada, Footnote 33 stating that “this decision makes it clear that these terms are not narrow and include any publication that is “available or accessible by the citizenry at large.” Clearview further submitted that the expectation of privacy for information in the public view “is or should be reduced” and that a broad interpretation of publicly available information should be preferred, stating: “Even if the regulation and its exceptions are ambiguous, and require an exercise in interpretation, they must be interpreted in accordance with the Canadian Charter. Restricting the free flow of publicly available information is contrary to the constitutional protection of freedom of expression. For this reason, exceptions to this principle must be narrowly construed and a broad interpretation of publicly available must be preferred so as not to unduly limit freedom of expression.” Finally, Clearview argued that: “In these circumstances, […] the positive effects of protecting personal information do not outweigh the negative effects on Clearview's freedom of expression. There is no pressing and substantial concern justifying an infringement on freedom of expression given the lack of a reasonable expectation of privacy in images that individuals themselves have already either placed or permitted to be placed in the public domain.” Based on these arguments, Clearview asserted that it did not contravene any of the Acts, as all of the information it collected and used was exempted as publicly available. As we note in paragraph 36, Clearview did not make any attempt to seek consent from individuals. Instead Clearview relies entirely on its argument that the personal information it collected, used and disclosed was publicly available and thus exempted from consent requirements. In considering Clearview’s submissions, our Offices have concluded that this view is incorrect, and that the exemption does not apply in the circumstances of this case. As set out in PIPEDA and confirmed in Turner v. Telus Communications Inc. Footnote 34, information will only be deemed “publicly available” if both publicly available and specified by the regulations. Clearview further argued that a “plain language” interpretation of the regulations was appropriate, and that it followed that a broad definition of the term “publication,” should be applied when considering whether the exemption applies. Clearview further argued that such a broad interpretation would be in accordance with the Canadian Charter of Rights and Freedoms (the Charter), namely freedom of expression. We do not accept this to be the case based on the facts, law or available jurisprudence as outlined below. It is our view that Lukács c. Canada is not applicable to the matter at hand, as it concerns the application of the Privacy Act, which is distinct from PIPEDA . In particular, we note that unlike in the Privacy Act, the meaning of “publicly available information” and what qualifies as a “publication” is specifically defined in PIPEDA , PIPA AB Footnote 35 and PIPA BC Footnote 36 by regulation (the Regulations). The Regulations thus take precedence. When interpreting the Regulations, we note that as privacy legislation is considered by the courts to be quasi-constitutional, Footnote 37 the rights accorded under them should be given a broad, purposive and liberal interpretation, and restrictions on those rights should be interpreted narrowly. Footnote 38 Since the Regulations create an exemption to a core privacy protection – the requirement for collection, use and disclosure of personal information to be with consent - they should be interpreted narrowly. With this in mind, we do not accept Clearview’s arguments in favour of a wider “plain language” interpretation. For example, social media, from which Clearview obtained a significant proportion of the images in its database, is not specified as a “publication” in the language of the PIPEDA regulations. It is the OPC ’s view that social media web pages differ substantially from the sources identified in the PIPEDA regulations. As the OPC previously found in the matter of Profile Technology, Footnote 39 there are a number of key differences between online information sources such as social media, and the examples of “publications” included in 1(e): social media web pages contain dynamic content, with new information being added, changed or deleted in real-time; and individuals exercise a level of direct control, a fundamental component of privacy protection, over their social media accounts, and over accessibility to associated content over time – for example, via privacy settings. In addition, the OIPC BC also takes the position that social media websites are not prescribed sources of “publicly available” information, and any collection from these sources would only be authorized with consent and only if the purposes are what a reasonable person would consider appropriate. Ultimately, Clearview’s assertions that publication necessarily includes “public blogs, public social media or any other public websites,” taken to their natural conclusion, imply that all publicly accessible content on the Internet is a publication in some form or other. This would create an extremely broad exemption that undermines the control users may otherwise maintain over their information at the source. In this regard, it has been noted that control is a fundamental component of privacy protection. Footnote 40 Even if such web pages were to be considered “publications” in the meaning of the Regulations, which we do not accept, s. 1 (e) of the PIPEDA Regulations and s. 7(e) of the PIPA AB Regulations specify that the exception only applies “where the individual has provided the information,” or where “it is reasonable to assume that the individual that the information is about provided that information,” respectively. As Clearview engages in mass collection of images through automated tools, it is inevitable that in many instances, the images would have instead been uploaded by a third party. Clearview argued that Quebec’s Private Sector Act implicitly includes an exclusion for “publicly available” personal information—because if it did not it would violate the freedom of expression. The CAI is of the view that argument cannot be accepted for the following reasons: The text of the Act clearly indicates that only information that is public “by law” is excluded, which does not include information that is otherwise available to the public in the absence of a law designating it as public. As a quasi-constitutional law that takes precedence over other legislation in Quebec, and has the purpose of clarifying the exercise of rights conferred by the Civil Code of Québec, specifically the right to privacy, any exceptions must be interpreted restrictively. Therefore, there exists no implied exclusion from Quebec’s Private Sector Act for publicly available information not designated as public by law. Because Clearview did not inform the AG as required by section 76 of the Code of Civil Procedure, the Commission cannot consider claims raised by Clearview suggesting that the Act respecting the private sector is inoperative. Indeed, such a review cannot take place if the Attorney General of Quebec has not been informed or been given an opportunity to make representations. Nor does it suffice to raise a freedom of expression violation. Clearview has neither explained nor demonstrated how its activities constitute the expression of a message relating to the pursuit of truth, participation in the community or individual self-fulfillment and human flourishing. Footnote 41\n\nIssue 2: Was Clearview collecting, using or disclosing personal information for an appropriate purpose?\n\nIn our view, for the reasons outlined below, Clearview’s purpose for collecting, using or disclosing personal information was neither appropriate nor legitimate. In accordance with the OPC ’s Guidance on inappropriate data practices: Interpretation and application of subsection 5(3), Footnote 42 the OPC considers the factors Footnote 43 set out by the courts in order to assist in determining whether a reasonable person would find that an organization’s collection, use and disclosure of information is for an appropriate purpose in the circumstances. These factors are to be applied in a contextual manner, which suggests flexibility and variability in accordance with the circumstances. Footnote 44 In applying s. 5(3), the courts have determined that the OPC is required to engage in a “balancing of interests” between the individual’s right to privacy and the commercial needs of the organization concerned. Footnote 45 This balancing of interests must be “viewed through the eyes of a reasonable person.” Footnote 46 Similar factors are also considered by OIPC BC in determining whether the purpose is reasonable. Footnote 47 Section 2 of PIPA AB says that in determining whether a thing or matter is reasonable or unreasonable, the standard to be applied is “what a reasonable person would consider appropriate in the circumstances”. Orders issued by the OIPC AB have also identified a number of questions for determining whether the collection of personal information in an instance was for a reasonable purpose, Footnote 48 including whether the collection of personal information was carried out in a reasonable manner. Finally, in analyzing whether Clearview had a serious and legitimate reason to establish a file on another person under section 4 of Quebec’s Private Sector Act, the CAI considers the lawfulness of the objective sought and its compliance with the law, justice and fairness. Footnote 49 We find that the collection of images and creation of biometric facial recognition arrays by Clearview, for its stated purpose of providing a service to law enforcement personnel, and use by others via trial accounts, represents the mass identification and surveillance of individuals by a private entity in the course of commercial activity. In our view, for the reasons outlined below, a reasonable person would not consider this purpose to be appropriate, reasonable, or legitimate in the circumstances, within the meaning of subsection 5(3) of the PIPEDA , sections 11, 14 and 17 of PIPA BC , Footnote 50 sections 11, 16 and 19 of PIPA AB and section 4 of Quebec’s Private Sector Act. As previously indicated, our Offices find the information at issue (facial biometrics generated from digital images) to be of a sensitive nature. Biometric information is distinctive, unlikely to vary over time, difficult to change and largely unique to the individual. Facial biometric data is particularly sensitive given that it is a key to an individual’s identity, supporting the ability to identify and surveil individuals. We further note that the additional contextual information provided via source links (that is, social media and websites) can include significant personal information of varying levels of sensitivity. Further, Clearview’s collection of information includes the mass indiscriminate collection of the personal information of minors, which would be considered particularly sensitive. It is our view that Clearview does not, in the circumstances, have an appropriate purpose, for: the mass and indiscriminate scraping of images from millions of individuals across Canada, including children, amongst over 3 billion images scraped world-wide; the development of biometric facial recognition arrays based on these images, and the retention of this information even after the source image or link has been removed from the Internet; or the subsequent use and disclosure of that information for its own commercial purposes; where such purposes: are unrelated to the purposes for which the images were originally posted (for example, social media or professional networking); are often to the detriment of the individual (for example, investigation, potential prosecution, embarrassment, etc.); and create the risk of significant harm to individuals whose images are captured by Clearview (including harms associated with misidentification or exposure to potential data breaches), where the vast majority of those individuals have never been and will never be implicated in a crime, or identified to assist in the resolution of a serious crime. Furthermore, Clearview’s collection of sensitive biometric personal information, as described above, was not, in our view, carried out in a legal manner. Clearview collects the information to populate its facial recognition database without obtaining express consent of the individuals in question, as required by the Acts, or any form of knowledge or consent for that matter. Clearview did not collect the information directly from the individuals in question. Nor did it have any relationship with the third parties whose websites it scraped, who could have, hypothetically, obtained consent for Clearview’s purposes. In fact, several of these third parties have made credible allegations that Clearview was not authorized to collect the information from their websites. As such, Clearview achieved its purposes via collection that inherently contravened Canadian privacy laws. Therefore, those purposes cannot in our view be considered appropriate. Consequently, we find that Clearview contravened: subsection 5(3) of the PIPEDA , section 4 of Quebec’s Private Sector Act, sections 11, 14 and 17 of PIPA BC and sections 11, 16 and 19 of PIPA AB .\n\nClearview’s Response Regarding Appropriate Purposes\n\nClearview disagreed with our preliminary characterization of its purposes and stated that its collection of information was to “enable law enforcement agencies to obtain information quickly and accurately in the course of an ongoing investigation” and that a reasonable person would consider this purpose to be “appropriate, reasonable and legitimate in the circumstances.” Clearview re-iterated its view that this information was publicly available and thus not sensitive. Clearview asserted that: “the difference between the purposes for which the images were originally posted and the ones for which Clearview used, collected, or disclosed them is irrelevant. If the purposes underlying Clearview's actions are appropriate and legitimate, it is reasonable to believe that Clearview has complied with this section of the law even if such images are not used, collected or disclosed for the same reason they were posted originally.” Clearview also asserted that any detriment to individuals resulting from the use of its services could not be imputed to Clearview, stating that: “Prosecution by law enforcement agencies using Clearview's services is in no way a direct and unique consequence of the services offered. Clearview cannot be held responsible for offering services to an entity that subsequently makes an error in its assessment of the person being investigated. Many factors will be taken into account by law enforcement agencies when doing their work. Clearview provides potential matches – just as witnesses provide potential identification in a line-up or eye-witness testimony. Law enforcement officials must ultimately determine the suitable use to be made of such information in the course of their investigations.” Clearview argued that a characterization of its purposes as detrimental to individuals was incorrect, stating: “Clearview's objectives are not to the detriment of individuals, but rather to the benefit of the community and the public interest by assisting law enforcement agencies responsible for public safety in their inquiries. Limiting such a service would arguably be at the expense of the public interest. Clearview facilitates research by providing a platform that contains all the information needed, information that is already available but dispersed on several third-party websites.” Clearview further argued that the only potential harm to most individuals would be that a link to a photo might be sent to a law enforcement agency, which in their view could not be described as significant. It opined that such potential harm was not disproportionate to the “benefits and objectives to which [Clearview] contributes.” Clearview concluded by referencing the purpose clause of PIPEDA , stating that: “when determining whether there are appropriate purposes involved, one must evaluate the balance between the privacy right of an individual and the need of organizations to collect, use or disclose personal information.” and that: “Given the significant potential benefit of Clearview's services to law enforcement and national security on the one hand, and the fact that significant harm is unlikely to occur on the other, especially considering that the information held is already publicly available and is distributed to law enforcement agencies for legitimate investigative purposes only, Clearview’s purposes are entirely appropriate.” We are not convinced by Clearview’s arguments, which cite the same jurisprudence that we have relied on. We remain of the view, based on our analysis outlined above in paragraphs 73 to 78, that Clearview is collecting sensitive biometric personal information, for purposes that a reasonable person would not consider appropriate in the circumstances. Whereas law enforcement agencies rely on the broad collection authority for their operations found in public-sector privacy legislation, these actions are circumscribed by the Charter and Clearview enjoys no such collection authority as a private organization. Although some of the information collected may have ultimately been used for law enforcement, Clearview’s real purpose for the collection is a commercial for-profit enterprise and not law enforcement. Footnote 51 Finally, we note that Clearview emphasizes the absence of harms to individuals flowing from its activities. In taking this position, Clearview fails to acknowledge: (i) the myriad of instances where false, or misapplied matches could result in reputational damage to individuals, and (ii) more fundamentally, the affront to individuals’ privacy rights and broad-based harm inflicted on all members of society, who find themselves under continual mass surveillance by Clearview based on its indiscriminate scraping and processing of their facial images.\n\nAdditional concerns in relation to appropriate purposes\n\nWe note a number of additional issues. We will not specifically opine on them, but we continue to have significant concerns about them in the context of Clearview’s facial recognition practices.\n\nAccuracy\n\nWhile our Offices did not complete a technical assessment of the accuracy of Clearview’s facial recognition technology, we recognize a number of concerns related to facial recognition technology, generally. Our Offices accept that facial recognition technologies may be used to render many services to society and individuals, and have a number of legitimate uses in business and government. For example we recognize that facial recognition can assist businesses with identity authentication, or law enforcement agencies in the investigation of serious and complex crimes. However, while facial recognition technology, and Clearview’s technology in particular, may be effective in certain circumstances, we note that there are significant concerns regarding the efficacy and accuracy of facial recognition technologies, in particular with respect to certain demographics. Despite advances in the sophistication of facial recognition technology through the increase of computational capacity, the improvement of underlying algorithms and the availability of huge volumes of data, such technologies are not perfect and can result in misidentification. This can be the result of a variety of factors, including the quality of photos/videos and the performance of algorithms used to compare facial characteristics. In particular, our Offices take note of claims of accuracy concerns stemming from a variety of studies and investigations of facial recognition algorithms found in a number of technology solutions. Accuracy issues in facial recognition technology can take two general forms: (i) failure to identify an individual whose face is recorded in the reference database, referred to as a “false-negative”; or (ii) matching faces that actually belong to two different individuals, referred to as a “false positive.” While the former is an issue primarily for the users of facial recognition technology, the latter presents compelling risks of harm to individuals, particularly when facial recognition is used in the context of law enforcement. Footnote 52 In particular, we refer to reports that facial recognition technology has been found to have significantly higher incidences of false positives or misidentifications when assessing the faces of people of colour, and especially women of colour, which could result in discriminatory treatment for those individuals. Footnote 53 For example, research conducted by NIST (National Institute of Standards and Technology) found that the rate of false positives for Asian and Black individuals was often greater than that for Caucasians, by a factor of 10 to 100 times. Footnote 54 Harms resulting from such misidentification can range from individuals being excluded from opportunities, to individuals being investigated and detained based on incorrect information. Such harms would generally be classified as significant. Footnote 55 We note that Clearview commissioned an independent panel to complete an accuracy test of their technology, which it claimed was based on the methodology of a previous test conducted by the American Civil Liberties Union ( ACLU ). A copy of the results from this test was provided in Clearview’s representations, and reported a 100% accuracy rate for Clearview’s technology. During our investigation we found that significant concerns, regarding the testing methodology and conclusions, had been raised by a variety of researchers, including the ACLU ’s own team, who characterized the study as “misleading,” and lodged a complaint with Clearview. Footnote 56 In its submissions, Clearview argued that the ACLU and other critics had failed to demonstrate how the results of the test were misleading. It reiterated that in testing, Clearview’s App correctly matched all the images it searched for, with no inaccuracies. While our Office will not opine on the merits of such complaints, we do note the persistent theme of concerns raised in relation to the opacity of Clearview’s technology, which is proprietary and inaccessible to the majority of researchers, make it difficult to make determinations on accuracy.\n\nCollection in contravention of contractual terms\n\nWe note that Clearview has received cease-and-desist letters from Google, Facebook, Twitter, YouTube and LinkedIn regarding their practice of collecting information in violation of terms of service. Footnote 57 Clearview represented that it has responded to these cease-and-desist requests by asserting a First Amendment right to scrape “public” information under the U.S. Constitution. Clearview also asserted that contractual terms have no bearing on our investigation or the appropriateness of its purposes. While we do not opine on whether or not one or more contractual violations occurred, to the extent that Clearview scraped personal information in contravention of platforms’ contractual terms, it would in our view, be relevant as a further factor in considering the inappropriateness of Clearview’s purposes, in the circumstances.\n\nRisk of harm arising from breach\n\nThe large amount of sensitive biometric information held by Clearview would in our view, make it a high value target for malicious actors. Clearview argued that “risk of harm from breach is not an appropriate consideration when assessing the purposes of Clearview’s actions, as this would go well beyond the scope of the law, which is to establish rules that recognize the right of privacy of individuals,” claiming that this risk is present in “almost all areas of society.” It further argued that even if such risks were taken into account, there was no risk of significant harm or likelihood of the information being stolen. While we will not opine on Clearview’s safeguards, which are outside the scope of this investigation, we do note that Clearview publicly announced that it was breached on two occasions within the past year. Once in February 2020 when its client list was leaked, Footnote 58 and again in April 2020 when its source code and pilot project video were obtained and partially leaked. Footnote 59 In our view, Clearview’s collection and subsequent use of billions of images and facial arrays which are linked to source data, represents a significant risk to tens of millions of individuals in Canada should it be compromised.\n\nIssue 3: Did Clearview satisfy its biometric obligations in Quebec?\n\nWhen a company builds a biometrics system in Quebec, it must comply with the rules set out in Quebec’s Private Sector Act and the LCCJTI . Indeed, it must in particular: obtain the express consent of the person concerned, in line with s. 44 of the LCCJTI ; and disclose the creation or existence of the biometrics system to the CAI in line with s. 45 of the LCCJTI . It is apparent from the investigation that Clearview failed to obtain the express consent of the persons concerned, as Clearview has acknowledged that no attempt to seek consent was made. Furthermore, the company failed to disclose the existence of its biometrics system to the CAI .\n\nClearview’s response regarding Quebec’s biometric law\n\nClearview argues that it did not build a biometric system in Quebec, since its activities take place in the United States. Noting that a provincial statute cannot apply extraterritorially in the absence of the express or implied will of the legislature, Clearview concludes that the LCCJTI cannot apply to it, because that would give the law extraterritorial scope that no provision could confer on it, whether explicitly or implicitly. The CAI does not share Clearview’s opinion with respect to the LCCJTI . Indeed, since Clearview does not deny having built a biometric system, the CAI is of the opinion that, even if the biometric system is located outside of Quebec, Clearview has nevertheless collected images in the course of operating a business in Quebec and must therefore obtain the express consent of these individuals before verifying or confirming their identity. The essence of the LCCJTI provisions at issue are respect for the privacy of the individuals concerned and the protection of their personal information. The intention that this mandatory obligation be applied to all persons is made very clear in the French version by the use of the word “ nul ”. The extraterritorial effects are incidental. Clearview, by offering its services within the territorial boundaries of the province and collecting and using the personal information of Quebecers, is operating a business in Quebec. Accordingly, Clearview is subject to the applicable legislation in the jurisdiction in which it is carrying out its activities, namely, the province of Quebec. Footnote 60 Clearview’s physical location and the site of its principal activities are therefore incidental and do not shelter it from the application of the LCCJTI . Therefore, Clearview must obtain the express consent of individuals before verifying or confirming their identity ( s. 44 of the LCCJTI ), as noted in paragraph 40. The sensitivity of the information collected, used or disclosed and the impact that the use of this information may have on the privacy of the individuals concerned requires that they be informed and express their consent. A biometric system cannot be used without the knowledge of the individuals involved. Footnote 61 Clearview was also required to disclose its database of biometric characteristics and measurements to the Commission, in accordance with section 45 of the LCCJTI . Consequently, the CAI finds that Clearview contravened sections 44 and 45 of the LCCJTI .\n\nRecommendations\n\nIn our letter of intention, we shared with Clearview that we could order or recommend to: cease offering the facial recognition services that have been the subject of this investigation to clients in Canada; cease the collection, use and disclosure of images and biometric facial arrays collected from individuals in Canada; and delete images and biometric facial arrays collected from individuals in Canada in its possession. With respect to the first recommendation, we asked Clearview to confirm that it would not resume its offer to provide the facial recognition services in Canada in the future. We also sought Clearview’s commitments explaining how and when it would implement the second and third recommendations.\n\nClearview’s response to our conclusions\n\nAs detailed in this report, Clearview expressly disagreed with our conclusions. Despite this, noting that following engagement with our Offices, it had voluntarily withdrawn from the Canadian market earlier in the investigation, Clearview indicated that it was “prepared to consider maintaining this status for a further two years, in order to allow the various Commissioners to provide detailed and meaningful guidelines as to how Canadian law proposes to deal with artificial intelligence.” Clearview suggested that as it was not “currently active” in Canada, our Offices should suspend our investigation and refrain from issuing a report or making a final determination on this matter. Clearview indicated that “during such a suspension, [it] would be willing to take steps, on a best efforts and without prejudice basis, to try to limit the collection and distribution of the images that it is able to identify as Canadian…” As of the time of writing this report, Clearview had not committed to following our recommendations or orders under consideration, and the Offices deemed it appropriate to issue this report.\n\nConclusions",
            "url": "https://www.priv.gc.ca/en/opc-actions-and-decisions/investigations/investigations-into-businesses/2021/pipeda-2021-001/#toc2",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "personal",
                "pipeda",
                "findings",
                "clearview",
                "office",
                "facial",
                "law",
                "québec",
                "investigation",
                "joint",
                "information",
                "privacy",
                "linformation",
                "individuals",
                "consent",
                "images",
                "à",
                "footnote",
                "clearviews"
            ],
            "summary": "BackgroundThis report of investigation examines Clearview AI, Inc.’s (Clearview) compliance with Canada’s Personal Information Protection and Electronic Documents Act ( PIPEDA ), Quebec’s Act Respecting the Protection of Personal Information in the Private Sector (Quebec’s Private Sector Act), and Act to Establish a Legal Framework for Information Technology ( LCCJTI ), British Columbia’s Personal Information Protection Act ( PIPA BC ), and Alberta’s Personal Information Protection Act ( PIPA AB ) – referred to collectively as the Acts.\nWe further note that the additional contextual information provided via source links (that is, social media and websites) can include significant personal information of varying levels of sensitivity.\nFurther, Clearview’s collection of information includes the mass indiscriminate collection of the personal information of minors, which would be considered particularly sensitive.\nWe will not specifically opine on them, but we continue to have significant concerns about them in the context of Clearview’s facial recognition practices.\nThe essence of the LCCJTI provisions at issue are respect for the privacy of the individuals concerned and the protection of their personal information.",
            "metadata": {
                "source_domain": "www.priv.gc.ca",
                "scrape_date": "2024-10-25T12:40:27.793590",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 63449
            }
        },
        {
            "title": "PIPEDA Findings #2021-001: Joint investigation of Clearview AI, Inc. by the Office of the Privacy Commissioner of Canada, the Commission d’accès à l’information du Québec, the Information and Privacy ",
            "text": "PIPEDA Findings #2021-001\n\nFebruary 2, 2021\n\nOverview\n\nThe Privacy Commissioner of Canada ( OPC ), the Commission d’accès à l’information du Québec ( CAI ), the Information and Privacy Commissioner for British Columbia ( OIPC BC ), and the Information and Privacy Commissioner of Alberta ( OIPC AB ), collectively referred to as “the Offices”, commenced a joint investigationFootnote 1 to examine whether Clearview AI, Inc.’s (“Clearview”) collection, use and disclosure of the personal information by means of its facial recognition tool complied with federal and provincial privacy laws applicable to the private sector.\n\nSpecifically, the Offices sought to determine whether Clearview:\n\nobtained requisite consent to collect, use and disclose personal information; and collected, used and disclosed personal information for an appropriate purpose Footnote 2.\n\nAdditionally, the CAI sought to determine whether Clearview had:\n\nReported the creation of a database of biometric characteristics or measurements.\n\nClearview’s facial recognition tool functions in four key sequential steps - Clearview:\n\n“scrapes” images of faces and associated data from publicly accessible online sources (including social media), and stores that information in its database; creates biometric identifiers in the form of numerical representations for each image; allows users to upload an image, which is then assessed against those biometric identifiers and matched to images in its database; and provides a list of results, containing all matching images and metadata. If a user clicks on any of these results, they are directed to the original source page of the image.\n\nThrough this process, Clearview amassed a database of over three billion images of faces and corresponding biometric identifiers, including those of a vast number of individuals in Canada, including children.\n\nClearview asserted that the tool is intended for use by law enforcement,Footnote 3 for legitimate law enforcement and investigative purposes. A variety of organizations, including private sector entities, used this service via a free-trial service.\n\nBiometric information is considered sensitive, in almost all circumstances, and facial recognition data is particularly sensitive. Furthermore, individuals who posted their images online, or whose images were posted by third party(ies), had no reasonable expectations that Clearview would collect, use and disclose their images for identification purposes. As such, express consent would generally be required. In Quebec, such use of biometric data requires express consent.\n\nClearview did not attempt to seek consent from the individuals whose information it collected. Clearview asserted that the information was “publicly available”, and thus exempt from consent requirements. Information collected from public websites, such as social media or professional profiles, and then used for an unrelated purpose, does not fall under the “publicly available” exception of PIPEDA , PIPA AB or PIPA BC . Nor is this information “public by law”, which would exempt it from Quebec’s Private Sector Law, and no exception of this nature exists for other biometric data under LCCJTI . Therefore, we found that Clearview was not exempt from the requirement to obtain consent.\n\nFurthermore, the Offices determined that Clearview collected, used and disclosed the personal information of individuals in Canada for inappropriate purposes, which cannot be rendered appropriate via consent. We found that the mass collection of images and creation of biometric facial recognition arrays by Clearview, for its stated purpose of providing a service to law enforcement personnel, and use by others via trial accounts, represents the mass identification and surveillance of individuals by a private entity in the course of commercial activity. We found Clearview’s purposes to be inappropriate where they: (i) are unrelated to the purposes for which those images were originally posted; (ii) will often be to the detriment of the individual whose images are captured; and (iii) create the risk of significant harm to those individuals, the vast majority of whom have never been and will never be implicated in a crime. Furthermore, it collected images in an unreasonable manner, via indiscriminate scraping of publicly accessible websites.\n\nWe identified certain other concerns on which we did not ultimately opine, but which we felt appropriate to raise in our report. This includes the fact that there were credible challenges to, and questions regarding, the efficacy and accuracy of facial recognition technologies generally, and regarding the reliability of Clearview’s testing results specifically.\n\nWe shared our preliminary findings and recommendations with Clearview, with a view to bringing it into compliance with federal and provincial private sector privacy law. We recommended that Clearview: (i) cease offering its facial recognition tool to clients in Canada; (ii) cease the collection, use and disclosure of images and biometric facial arrays collected from individuals in Canada; and (iii) delete images and biometric facial arrays collected from individuals in Canada in its possession.\n\nClearview expressly disagreed with our findings.\n\nIn disagreeing with our findings, Clearview alleged an absence of harms to individuals flowing from its activities. In our view, Clearview’s position fails to acknowledge: (i) the myriad of instances where false, or misapplied matches could result in reputational damage, and (ii) more fundamentally, the affront to individuals’ privacy rights and broad-based harm inflicted on all members of society, who find themselves under continual mass surveillance by Clearview based on its indiscriminate scraping and processing of their facial images.\n\nIn terms of remedies, noting that it had withdrawn from the Canadian market during our investigation, Clearview stated that it was “prepared to consider” remaining outside of the Canadian market for a further two years, while our Offices developed relevant guidance. Clearview suggested that it would be appropriate for our Offices to suspend our investigation and not issue this final report, and that during such a suspension, it “would be willing to take steps, on a best efforts and without prejudice basis, to try to limit the collection and distribution of the images that it is able to identify as Canadian” [emphasis added]. Clearview has not committed to following our recommendations. The Offices view it as inappropriate to suspend the investigation and not issue this Report. We therefore find the matter to be well-founded and restate the recommendations in our preliminary findings.\n\nAdditionally, the CAI determined that contrary to the requirements of the LCCJTI , Clearview had not advised the CAI that it had created a database of biometric characteristics, nor obtained the express consent from individuals that verifying or confirming their identity would be conducted using a facial recognition process.\n\nBackground\n\nThis report of investigation examines Clearview AI, Inc.’s (Clearview) compliance with Canada’s Personal Information Protection and Electronic Documents Act ( PIPEDA ), Quebec’s Act Respecting the Protection of Personal Information in the Private Sector (Quebec’s Private Sector Act), and Act to Establish a Legal Framework for Information Technology ( LCCJTI ), British Columbia’s Personal Information Protection Act ( PIPA BC ), and Alberta’s Personal Information Protection Act ( PIPA AB ) – referred to collectively as the Acts. Clearview is a technology company headquartered in the United States that developed and delivered its facial recognition Footnote 4 software and combined database solution (App) to clients around the world. Clearview’s App allows clients to upload a digital image of an individual’s face and run a search against it. The App then applies its algorithm to the digital image and runs the result against Clearview’s database to identify and display likely matches and associated source information. In January and February 2020, public reports Footnote 5 indicated that Clearview was populating its facial recognition database by collecting digital images from a variety of public websites, including but not limited to, Facebook, YouTube, Instagram, Twitter and Venmo, in apparent violation of those organizations’ terms of service and without the consent of individuals. It was further indicated that these digital images were then indefinitely stored in Clearview’s database to be sourced and served as results for facial recognition searches. In February 2020, multiple reports Footnote 6 surfaced confirming that a number of Canadian law enforcement agencies and private organizations Footnote 7 had used Clearview’s services in order to identify individuals. Satisfied that reasonable grounds existed to investigate these matters, in February 2020, the Office of the Privacy Commissioner of Canada ( OPC ), the Commission d’accès à l’information du Québec ( CAI ), the Information and Privacy Commissioner for British Columbia ( OIPC BC ), and the Information and Privacy Commissioner of Alberta ( OIPC AB ), collectively referred to as the Offices, each initiated investigations pursuant to s. 11(2) of PIPEDA , s. 81 of Quebec’s Private Sector Act, s. 36(1)(a) of PIPA BC , and s. 36(1)(a) of PIPA AB respectively. The Offices decided to conduct the investigation jointly in order to maximize their expertise and their resources, while avoiding duplication of their efforts and those of Clearview.\n\nIssues\n\nThe issues in this investigation were: Whether Clearview was required under the Acts to get consent for its collection, use and disclosure of personal information and if so, whether it did; and Whether Clearview collected, used and/or disclosed personal information for a purpose that a reasonable person would consider appropriate in the circumstances, for a purpose that was reasonable and to fulfill a legitimate need? Footnote 8 The following Quebec-specific issue was also examined: Did Clearview previously disclose to the CAI the creation of a database of biometric characteristics or measurements? During the course of the investigation, specifically after the letter of intention referred to in paragraph 11 below, Clearview also asserted that our Offices do not have jurisdiction over the Clearview activities in question. We address this issue in our analysis, prior to considering the issues identified above.\n\nMethodology\n\nIn addition to conducting extensive open-source research, the investigative team (the team) analyzed representations provided by Clearview and records relating to its activities. The team also examined representations from a number of third parties identified as possible users of Clearview’s service. Between February and November 2020, Clearview provided multiple sets of written representations to our Offices. Furthermore, we gave Clearview multiple opportunities to meet with us to make inquiries and provide additional evidence. We conducted two such meetings in June 2020. Upon completion of the evidence-gathering phase of the joint investigation, our Offices issued a letter of intention to Clearview on October 29 2020, which set out and explained the rationale for our preliminary findings, identified several orders and recommendations under consideration and invited Clearview to respond. We then met with Clearview on November 17 to clarify our views, provide an opportunity to ask any questions, and discuss potential remedies to resolve the matter. On November 20, Clearview provided a written response articulating its disagreement with our preliminary findings and orders and recommendations under consideration. In this letter, Clearview set out a variety of new arguments, and provided new information which our Offices considered and assessed before producing this report of findings.\n\nClearview’s representations and our investigation\n\nThis section reflects initial representations provided by Clearview up to the point of the issuance of our letter of intention. Further representations provided by Clearview in its response to our letter of intention are included under our analysis of each issue.\n\nOverview of Clearview’s facial recognition implementation\n\nIn its submissions, Clearview explained that its facial recognition technology is based on five primary components: (i) image crawler, (ii) image store, (iii) metadata store, (iv) neural network and (v) vector database. The image crawler is an automated tool that searches public web pages and collects any images that it identifies as containing faces along with associated metadata such as the title, source link and description. This process is commonly referred to as “scraping.” The images and metadata collected through this scraping process are indefinitely stored on Clearview’s servers in the image and metadata stores respectively. The neural network underpins the algorithm that analyzes digital images of faces and turns them into numerical representations referred to as “vectors”. Clearview’s vectors consist of 512 data points that represent the various unique lines that make up a face. Clearview then stores all of these vectors in their vector database, where they are associated with the images stored on Clearview’s server. Every image in the database has a vector associated with it in order to allow identification and matching. When an App user wishes to identify an individual, they are required to upload an image of their target into the App and run a search. The neural network then analyzes the image and produces a vector. This vector is then compared against all vectors stored in Clearview’s database, with the App pulling any matching images from the vector database and providing them to the user, along with any associated metadata, as search results. Clearview stated that images uploaded by users are stored separately from images obtained from scraping, and do not show up in any search results. Clearview advised that its search results are displayed in a list containing thumbnail images that appear to be a match for the individual, the name of the image, description and source link. The user must then click the associated source link to be re-directed to the web page where the image was originally collected, in order to obtain additional information. Clearview stated that it “[does] not possess or maintain any information about names, addresses, nationality, date of birth [or] location” associated with the images in its database.\n\nClearview’s privacy practices regarding consent\n\nClearview originally stated that it does not seek consent from individuals whose information it collects. Rather, Clearview stated that in its view, the images it collected were publicly available and therefore it did not require the knowledge or consent of individuals to collect their information. In support of this position, Clearview stated that it only collected images from publicly-viewable web pages, and did not collect any images protected by privacy settings, such as those associated with certain social media accounts, or from pages that enabled “robots.txt”. Footnote 9 Clearview has confirmed that their image crawler is configured to respect whatever instructions are present in the robots.txt file.\n\nClearview’s purposes\n\nIn its initial representations, Clearview advised our Offices that its App was intended to be for the sole and exclusive use of law enforcement. This was reflected in Clearview’s terms of service, which state that “Users may use [the] Service for legitimate law enforcement and investigative purposes” and that “users may not use the Service for any reason other than law enforcement or investigative purposes.” In response to our letter of intention, Clearview advised that previously, its terms of service also extended access to “security professionals”. Clearview asserted that their technology provides “substantial, concrete benefits to public safety by dramatically increasing law enforcement’s ability to identify and investigate suspects, victims and witnesses.” Clearview pointed to numerous successes in cases ranging from “murder, armed robbery and child sexual exploitation to terrorism, major narcotics trafficking and multi-million dollar fraud.” When asked to speak to potential harms to Canadians that could arise from its technology, Clearview stated that any such harms were only hypothetical. Clearview stated that any “harm that a person would suffer from a Clearview search of their image is comparable to the harm that the person suffers when a Google search of his or her name is performed.” Clearview further indicated that no single user could browse their full database as results were only provided for matches, thus mitigating any risk. Clearview stated that even if its database were to be compromised and released, the images therein are all already accessible online, and thus not sensitive, and the vectors that it uses for biometric matching are hashed, Footnote 10 so they are useless outside of the Clearview App. While Clearview originally allowed a variety of public and private organizations to create accounts, we note that in response to our investigation, Clearview stated that it had suspended access to all users in Canada, outside the RCMP , in March 2020. Following further engagement with our Offices during the investigation, Clearview voluntarily exited the Canadian market in July 2020.\n\nComparison with other organizations\n\nClearview asserted that its App is essentially an image search engine and asked our Offices why we were “treating them differently from other search engines”. This investigation focuses on Clearview's practices and not on those of the search engines cited by Clearview. Our Offices initiate and conduct investigations into organizations on the basis of each case’s own particular set of facts. As such, we do not express an opinion on the obligations of any other organizations in this report.\n\nAnalysis\n\nClearview’s jurisdictional challenge\n\nAt the latter stages of our investigation, subsequent to receiving the letter of intention from our Offices seeking a response to the preliminary findings in this matter, Clearview argued that none of our Offices have jurisdiction over its activities, asserting that “[n]one of Clearview’s activities take place in Canada” and that it “is of the view in the circumstances that none of the statutes invoked apply and that no connecting factors create a real and substantial link to Canada.” Clearview submitted that PIPEDA does not apply “because there is no real and substantial connection to Canada.” Specifically, Clearview argued that the circumstances in the matter at hand were such that no real and substantial connection with Canada existed: the content referred to in Clearview’s platform was not “uniquely Canadian” and that it has content from “several other countries all over the world”; Clearview’s services were “not directly and solely directed at Canadians” and that “not many Canadians would have used [its] services”, asserting that “beyond the trial users, the only allegation is that one Canadian entity, the RCMP , would have used Clearview’s services”; and “there [appeared] to be no evidence that Clearview’s services are mainly felt by Canadians”. Clearview further argued that it is not subject to any provincial privacy laws as in its view: it did not collect, use or disclose personal information “within the provinces of Alberta, Quebec or British Columbia, but rather in the United States”; there was “no evidence or allegation” that Clearview did business within said provinces; and collection, use or disclosure had to take place entirely within each province to be applicable under the acts, and that there is “no evidence or allegation” that this took place.\n\nOPC ’s jurisdiction\n\nThe OPC notes that PIPEDA applies to organizations outside of Canada where a “real and substantial connection” to Canada exists. Footnote 11 In our view, the circumstances in this matter clearly demonstrate that a real and substantial connection to Canada exists. In coming to this conclusion, we considered the relevant connecting factors that flow from the jurisprudence, including the factors set out in A.T. v. Globe24h: (1) the location of the target audience of the website, (2) the source of the content on the website, (3) the location of the website operator, and (4) the location of the host server. Footnote 12 Regarding the location of Clearview’s target audience: While Clearview claims that its activity in Canada was limited, this is at odds with the fact that it actively marketed its services to Canadian organizations through promotional material, testimonials from Canadian law enforcement professionals, and agency-specific presentations and trials. Furthermore, Clearview publicly declared Canada to be part of its core market in statements to the media Footnote 13 and its own promotional materials. Footnote 14 The fact that only one agency became a paying customer is, in our view, immaterial. The colour and character of Clearview’s activities were commercial in nature, with trials existing for the express purpose of enticing the purchase of accounts. Clearview’s representations confirmed that 48 accounts (trial or otherwise) were created for law enforcement agencies and organizations across Canada, and thousands of searches were conducted through these accounts. In particular, we note that various provincial law enforcement agencies used trial accounts of the App for several months, with the number of searches conducted per trial account ranging from tens, to hundreds, or in one case, thousands. Furthermore, dismissing the RCMP as only “one Canadian entity” ignores the fact that the RCMP is Canada’s national law enforcement agency, operating all over Canada with national, federal, provincial, and municipal policing mandates. Regarding the source of Clearview’s content: It is not a requirement that Clearview’s content be exclusively derived from Canadian sources for there to be a real and substantial connection to Canada. As set out in Lawson v. Accusearch Inc., it is not necessary to identify specific Canadian sources of content to determine we have jurisdiction. Clearview’s assertion that it collects images without regard to geography or source does not preclude our jurisdiction when a substantial amount of its content is sourced from Canada. The exact number of images derived from individuals in Canada is unknown due to the fact that Clearview does not retain the national source. However, the indiscriminate nature of Clearview’s scraping renders it a relative certainty that it collected millions of images of individuals in Canada, Footnote 15 and used them to derive biometric image vectors for its database, including to market to Canadian law enforcement agencies. Finally, regarding the location of Clearview’s website operations and host server: We note that Clearview’s activities take place exclusively through a website or app. As referenced in paragraph 54 of A.T. v. Globe24h.com, a physical presence in Canada is not required to establish a real and substantial connection when considering websites under PIPEDA , as telecommunications occur “both here and there.” Clearview’s operations necessitate the transmission and receipt of personal information between Canada and the USA, both when collecting information and disclosing it through its software. As set out by the Supreme Court of Canada Footnote 16: “Receipt may be no less “significant” a connecting factor than the point of origin (not to mention the physical location of the host server, which may be in a third country).”\n\nProvincial jurisdiction\n\nWe further reject Clearview’s assertion that it is not subject to PIPA AB , PIPA BC or Quebec’s Private Sector Act (the Provincial Acts), respectively, and are of the view that Clearview’s activities fall under the jurisdiction of both the OPC and the provinces. Footnote 17 Provincial privacy legislation applies to any private sector organization that collects, uses and discloses information of individuals within that province. Clearview’s practice of indiscriminate scraping has undoubtedly resulted in the collection of the personal information of individuals within Quebec, Alberta and British Columbia, whose residents collectively account for nearly half of the Canadian population. In addition, provincial and municipal law enforcement agencies located within the provinces and subject to provincial oversight were targeted and used trial accounts of Clearview’s software, in the course of which they provided, and Clearview collected, personal information in the form of photographs of individuals. Footnote 18 Clearview is a commercial enterprise that collected, used, and disclosed personal information of individuals within Quebec, Alberta and British Columbia with the intention of selling a product to law enforcement agencies within the provinces. The fact that a company is located outside of Quebec, Alberta and British Columbia, does not mean it can evade obligations under Quebec’s Private Sector Act, PIPA AB and PIPA BC . Indeed, whenever a company collects the personal information of individuals located within a province, regardless of where the company is located, the Provincial Acts apply. Footnote 19 Considering the above, the Offices do not accept Clearview’s assertion that provincial legislation does not apply and are of the view that: the Provincial Acts apply, as previously stated; the Provincial Acts do not prevent the achievement of PIPEDA ’s objective, nor do they result in operational conflict or conflict of intent; each Provincial Act has been found to be substantially similar to PIPEDA . Footnote 20\n\nIssue 1: Did Clearview obtain requisite consent?\n\nIn our view, Clearview did not obtain consent required for its collection, use and disclosure of personal information through the App. In coming to this determination, we note that Clearview made no attempt whatsoever to obtain consent from individuals, given its erroneous interpretation of Canadian privacy law, which sets out when information is “publicly available” or “public under the law”. The Acts state that the consent of the individual is required for the collection, use or disclosure of personal information unless an exception applies. Footnote 21 The type of consent required will vary depending on the circumstances and the type of information involved. The Guidelines for obtaining meaningful consent Footnote 22 (the Guidelines) jointly issued by the OPC , OIPC AB and OIPC BC provide that “organizations must generally obtain express consent” when: (i) the information being collected, used or disclosed is sensitive; (ii) the collection, use or disclosure is outside of the reasonable expectations of the individual; and/or (iii) the collection, use or disclosure creates a meaningful residual risk of significant harm. Beyond Clearview’s collection of images, we also note that its creation of biometric information in the form of vectors constituted a distinct and additional collection and use of personal information, as previously found by the OPC , OIPC AB and OIPC BC in the matter of Cadillac Fairview. Footnote 23 With respect to biometric characteristics and measurements, Quebec’s LCCJTI specifically requires the express consent of the person concerned. Consent is described as express when it is explicit and unequivocal. To give express consent, a person must perform a positive action that clearly demonstrates his or her agreement. Footnote 24 To perform such an action, the person must be informed about what his or her consent entails. Footnote 25 The consent must be free, enlightened, given for specific purposes and limited in time. Footnote 26 In our view, biometric information is sensitive in almost all circumstances. It is intrinsically, and in most instances permanently, linked to the individual. It is distinctive, unlikely to vary over time, difficult to change and largely unique to the individual. That being said, within the category of biometric information, there are degrees of sensitivity. It is our view that facial biometric information is particularly sensitive. Possession of a facial recognition template can allow for identification of an individual through comparison against a vast array of images readily available on the Internet, as demonstrated in the matter at hand, or via surreptitious surveillance. For these reasons, it is our view that in the absence of an applicable exception, Clearview should have obtained express opt-in consent before it collected the images of any individual in Canada. In its submissions, Clearview acknowledged that it did not seek consent from the individuals whose information it collected, used or disclosed. Clearview argued that the information it collected was “publicly available” and that there was thus no reasonable expectation of privacy. Our Offices note that PIPEDA , PIPA BC and PIPA AB have exceptions to the requirement for consent where the personal information at issue is publicly available as set out in section 7(1)(d) of PIPEDA , sections 12(1)(e), 15(1)(e) and 18(1)(e) of PIPA BC , and sections 14(e), 17(e) and 20(j) of PIPA AB . The definition of “publicly available” is provided by each Act’s regulations Footnote 27 and is distinct from a common understanding of “publicly accessible” information. Information from sources such as social media or professional profiles, collected from public websites and then used for an unrelated purpose, does not fall under the “publicly available” exception of PIPEDA . Footnote 28 Similarly, the respective regulations of both PIPA AB and PIPA BC Footnote 29 prescribe sources of public information that include directories, registries, and publications. Social media websites and search engines are not listed as prescribed sources of publicly available information under either of these Acts. As such, collection from these sources would only be authorized with consent and only if the purposes are what a reasonable person would consider appropriate. Footnote 30 Quebec’s Private Sector Act and LCCJTI do not distinguish, and make no allowance for, “publicly available information.” However, Quebec’s Private Sector Act does not apply to information “which by law is public.” There are no Quebec statutes under which personal information is deemed to be public solely based on the fact that it has been posted on social media or the Web. Moreover, the CAI has previously ruled that, even where personal information has been posted on a public website, it does not mean that the information may be used for other purposes without the consent of the person concerned. Footnote 31 The fact that images are published on a website does not necessarily mean that their author has consented to their use by a third party. As such, our Offices do not recognize the personal information collected, used or disclosed by Clearview to be “publicly available” as envisioned by the Acts, or as information “which by law is public,” and thus the exception does not apply. As Clearview made no attempt to obtain consent, and no exception from the requirement to obtain consent is found to be applicable, we find that Clearview contravened sections 6.1 as well Principle 4.3 of Schedule 1 of PIPEDA , section 7 of PIPA AB , sections 6-8 of PIPA BC , sections 6 and 12-14 of Quebec’s Private Sector Act and section 44 of the LCCJTI .\n\nClearview’s response regarding consent\n\nIn its response, Clearview stated that: “With respect to the consent obligation under federal and provincial legislation, and assuming, without waiving the lack of jurisdiction invoked above that such laws apply, Clearview submits that the exception for publications which are publicly available applies. Information collected by Clearview is nothing more than information available to the public.” Clearview argued that its collection of information qualified under the exception set out in regulation for “personal information that appears in a publication, including a magazine, book or newspaper, in printed or electronic form, that is available to the public, where the individual has provided the information.” Footnote 32 In regard to Quebec’s legislation, which does not contain such exceptions, Clearview argued that the exception must necessarily be implied. It argued that otherwise, “the legislation is invalid because it breaches the Quebec and Canadian Charter guarantees of freedom of expression.” The respondent further argued that the regulatory definition of publicly available information “is not distinct from the common understanding of the words” and that while Parliament “did define some categories of items that may be included in what is said to be public, it did not restrict the definition with respect to publication,” stating that: “In Clearview’s submission, the definition [of a publication] could hardly be broader. As a result, personal information located on public blogs, public social media or any other public websites are included in the “publicly available” exception as they are included in the definition of a publication. Therefore, the collection of such information does not require consent.” In support of its position, Clearview cited the Federal Court of Appeal’s decision in Lukács v. Canada, Footnote 33 stating that “this decision makes it clear that these terms are not narrow and include any publication that is “available or accessible by the citizenry at large.” Clearview further submitted that the expectation of privacy for information in the public view “is or should be reduced” and that a broad interpretation of publicly available information should be preferred, stating: “Even if the regulation and its exceptions are ambiguous, and require an exercise in interpretation, they must be interpreted in accordance with the Canadian Charter. Restricting the free flow of publicly available information is contrary to the constitutional protection of freedom of expression. For this reason, exceptions to this principle must be narrowly construed and a broad interpretation of publicly available must be preferred so as not to unduly limit freedom of expression.” Finally, Clearview argued that: “In these circumstances, […] the positive effects of protecting personal information do not outweigh the negative effects on Clearview's freedom of expression. There is no pressing and substantial concern justifying an infringement on freedom of expression given the lack of a reasonable expectation of privacy in images that individuals themselves have already either placed or permitted to be placed in the public domain.” Based on these arguments, Clearview asserted that it did not contravene any of the Acts, as all of the information it collected and used was exempted as publicly available. As we note in paragraph 36, Clearview did not make any attempt to seek consent from individuals. Instead Clearview relies entirely on its argument that the personal information it collected, used and disclosed was publicly available and thus exempted from consent requirements. In considering Clearview’s submissions, our Offices have concluded that this view is incorrect, and that the exemption does not apply in the circumstances of this case. As set out in PIPEDA and confirmed in Turner v. Telus Communications Inc. Footnote 34, information will only be deemed “publicly available” if both publicly available and specified by the regulations. Clearview further argued that a “plain language” interpretation of the regulations was appropriate, and that it followed that a broad definition of the term “publication,” should be applied when considering whether the exemption applies. Clearview further argued that such a broad interpretation would be in accordance with the Canadian Charter of Rights and Freedoms (the Charter), namely freedom of expression. We do not accept this to be the case based on the facts, law or available jurisprudence as outlined below. It is our view that Lukács c. Canada is not applicable to the matter at hand, as it concerns the application of the Privacy Act, which is distinct from PIPEDA . In particular, we note that unlike in the Privacy Act, the meaning of “publicly available information” and what qualifies as a “publication” is specifically defined in PIPEDA , PIPA AB Footnote 35 and PIPA BC Footnote 36 by regulation (the Regulations). The Regulations thus take precedence. When interpreting the Regulations, we note that as privacy legislation is considered by the courts to be quasi-constitutional, Footnote 37 the rights accorded under them should be given a broad, purposive and liberal interpretation, and restrictions on those rights should be interpreted narrowly. Footnote 38 Since the Regulations create an exemption to a core privacy protection – the requirement for collection, use and disclosure of personal information to be with consent - they should be interpreted narrowly. With this in mind, we do not accept Clearview’s arguments in favour of a wider “plain language” interpretation. For example, social media, from which Clearview obtained a significant proportion of the images in its database, is not specified as a “publication” in the language of the PIPEDA regulations. It is the OPC ’s view that social media web pages differ substantially from the sources identified in the PIPEDA regulations. As the OPC previously found in the matter of Profile Technology, Footnote 39 there are a number of key differences between online information sources such as social media, and the examples of “publications” included in 1(e): social media web pages contain dynamic content, with new information being added, changed or deleted in real-time; and individuals exercise a level of direct control, a fundamental component of privacy protection, over their social media accounts, and over accessibility to associated content over time – for example, via privacy settings. In addition, the OIPC BC also takes the position that social media websites are not prescribed sources of “publicly available” information, and any collection from these sources would only be authorized with consent and only if the purposes are what a reasonable person would consider appropriate. Ultimately, Clearview’s assertions that publication necessarily includes “public blogs, public social media or any other public websites,” taken to their natural conclusion, imply that all publicly accessible content on the Internet is a publication in some form or other. This would create an extremely broad exemption that undermines the control users may otherwise maintain over their information at the source. In this regard, it has been noted that control is a fundamental component of privacy protection. Footnote 40 Even if such web pages were to be considered “publications” in the meaning of the Regulations, which we do not accept, s. 1 (e) of the PIPEDA Regulations and s. 7(e) of the PIPA AB Regulations specify that the exception only applies “where the individual has provided the information,” or where “it is reasonable to assume that the individual that the information is about provided that information,” respectively. As Clearview engages in mass collection of images through automated tools, it is inevitable that in many instances, the images would have instead been uploaded by a third party. Clearview argued that Quebec’s Private Sector Act implicitly includes an exclusion for “publicly available” personal information—because if it did not it would violate the freedom of expression. The CAI is of the view that argument cannot be accepted for the following reasons: The text of the Act clearly indicates that only information that is public “by law” is excluded, which does not include information that is otherwise available to the public in the absence of a law designating it as public. As a quasi-constitutional law that takes precedence over other legislation in Quebec, and has the purpose of clarifying the exercise of rights conferred by the Civil Code of Québec, specifically the right to privacy, any exceptions must be interpreted restrictively. Therefore, there exists no implied exclusion from Quebec’s Private Sector Act for publicly available information not designated as public by law. Because Clearview did not inform the AG as required by section 76 of the Code of Civil Procedure, the Commission cannot consider claims raised by Clearview suggesting that the Act respecting the private sector is inoperative. Indeed, such a review cannot take place if the Attorney General of Quebec has not been informed or been given an opportunity to make representations. Nor does it suffice to raise a freedom of expression violation. Clearview has neither explained nor demonstrated how its activities constitute the expression of a message relating to the pursuit of truth, participation in the community or individual self-fulfillment and human flourishing. Footnote 41\n\nIssue 2: Was Clearview collecting, using or disclosing personal information for an appropriate purpose?\n\nIn our view, for the reasons outlined below, Clearview’s purpose for collecting, using or disclosing personal information was neither appropriate nor legitimate. In accordance with the OPC ’s Guidance on inappropriate data practices: Interpretation and application of subsection 5(3), Footnote 42 the OPC considers the factors Footnote 43 set out by the courts in order to assist in determining whether a reasonable person would find that an organization’s collection, use and disclosure of information is for an appropriate purpose in the circumstances. These factors are to be applied in a contextual manner, which suggests flexibility and variability in accordance with the circumstances. Footnote 44 In applying s. 5(3), the courts have determined that the OPC is required to engage in a “balancing of interests” between the individual’s right to privacy and the commercial needs of the organization concerned. Footnote 45 This balancing of interests must be “viewed through the eyes of a reasonable person.” Footnote 46 Similar factors are also considered by OIPC BC in determining whether the purpose is reasonable. Footnote 47 Section 2 of PIPA AB says that in determining whether a thing or matter is reasonable or unreasonable, the standard to be applied is “what a reasonable person would consider appropriate in the circumstances”. Orders issued by the OIPC AB have also identified a number of questions for determining whether the collection of personal information in an instance was for a reasonable purpose, Footnote 48 including whether the collection of personal information was carried out in a reasonable manner. Finally, in analyzing whether Clearview had a serious and legitimate reason to establish a file on another person under section 4 of Quebec’s Private Sector Act, the CAI considers the lawfulness of the objective sought and its compliance with the law, justice and fairness. Footnote 49 We find that the collection of images and creation of biometric facial recognition arrays by Clearview, for its stated purpose of providing a service to law enforcement personnel, and use by others via trial accounts, represents the mass identification and surveillance of individuals by a private entity in the course of commercial activity. In our view, for the reasons outlined below, a reasonable person would not consider this purpose to be appropriate, reasonable, or legitimate in the circumstances, within the meaning of subsection 5(3) of the PIPEDA , sections 11, 14 and 17 of PIPA BC , Footnote 50 sections 11, 16 and 19 of PIPA AB and section 4 of Quebec’s Private Sector Act. As previously indicated, our Offices find the information at issue (facial biometrics generated from digital images) to be of a sensitive nature. Biometric information is distinctive, unlikely to vary over time, difficult to change and largely unique to the individual. Facial biometric data is particularly sensitive given that it is a key to an individual’s identity, supporting the ability to identify and surveil individuals. We further note that the additional contextual information provided via source links (that is, social media and websites) can include significant personal information of varying levels of sensitivity. Further, Clearview’s collection of information includes the mass indiscriminate collection of the personal information of minors, which would be considered particularly sensitive. It is our view that Clearview does not, in the circumstances, have an appropriate purpose, for: the mass and indiscriminate scraping of images from millions of individuals across Canada, including children, amongst over 3 billion images scraped world-wide; the development of biometric facial recognition arrays based on these images, and the retention of this information even after the source image or link has been removed from the Internet; or the subsequent use and disclosure of that information for its own commercial purposes; where such purposes: are unrelated to the purposes for which the images were originally posted (for example, social media or professional networking); are often to the detriment of the individual (for example, investigation, potential prosecution, embarrassment, etc.); and create the risk of significant harm to individuals whose images are captured by Clearview (including harms associated with misidentification or exposure to potential data breaches), where the vast majority of those individuals have never been and will never be implicated in a crime, or identified to assist in the resolution of a serious crime. Furthermore, Clearview’s collection of sensitive biometric personal information, as described above, was not, in our view, carried out in a legal manner. Clearview collects the information to populate its facial recognition database without obtaining express consent of the individuals in question, as required by the Acts, or any form of knowledge or consent for that matter. Clearview did not collect the information directly from the individuals in question. Nor did it have any relationship with the third parties whose websites it scraped, who could have, hypothetically, obtained consent for Clearview’s purposes. In fact, several of these third parties have made credible allegations that Clearview was not authorized to collect the information from their websites. As such, Clearview achieved its purposes via collection that inherently contravened Canadian privacy laws. Therefore, those purposes cannot in our view be considered appropriate. Consequently, we find that Clearview contravened: subsection 5(3) of the PIPEDA , section 4 of Quebec’s Private Sector Act, sections 11, 14 and 17 of PIPA BC and sections 11, 16 and 19 of PIPA AB .\n\nClearview’s Response Regarding Appropriate Purposes\n\nClearview disagreed with our preliminary characterization of its purposes and stated that its collection of information was to “enable law enforcement agencies to obtain information quickly and accurately in the course of an ongoing investigation” and that a reasonable person would consider this purpose to be “appropriate, reasonable and legitimate in the circumstances.” Clearview re-iterated its view that this information was publicly available and thus not sensitive. Clearview asserted that: “the difference between the purposes for which the images were originally posted and the ones for which Clearview used, collected, or disclosed them is irrelevant. If the purposes underlying Clearview's actions are appropriate and legitimate, it is reasonable to believe that Clearview has complied with this section of the law even if such images are not used, collected or disclosed for the same reason they were posted originally.” Clearview also asserted that any detriment to individuals resulting from the use of its services could not be imputed to Clearview, stating that: “Prosecution by law enforcement agencies using Clearview's services is in no way a direct and unique consequence of the services offered. Clearview cannot be held responsible for offering services to an entity that subsequently makes an error in its assessment of the person being investigated. Many factors will be taken into account by law enforcement agencies when doing their work. Clearview provides potential matches – just as witnesses provide potential identification in a line-up or eye-witness testimony. Law enforcement officials must ultimately determine the suitable use to be made of such information in the course of their investigations.” Clearview argued that a characterization of its purposes as detrimental to individuals was incorrect, stating: “Clearview's objectives are not to the detriment of individuals, but rather to the benefit of the community and the public interest by assisting law enforcement agencies responsible for public safety in their inquiries. Limiting such a service would arguably be at the expense of the public interest. Clearview facilitates research by providing a platform that contains all the information needed, information that is already available but dispersed on several third-party websites.” Clearview further argued that the only potential harm to most individuals would be that a link to a photo might be sent to a law enforcement agency, which in their view could not be described as significant. It opined that such potential harm was not disproportionate to the “benefits and objectives to which [Clearview] contributes.” Clearview concluded by referencing the purpose clause of PIPEDA , stating that: “when determining whether there are appropriate purposes involved, one must evaluate the balance between the privacy right of an individual and the need of organizations to collect, use or disclose personal information.” and that: “Given the significant potential benefit of Clearview's services to law enforcement and national security on the one hand, and the fact that significant harm is unlikely to occur on the other, especially considering that the information held is already publicly available and is distributed to law enforcement agencies for legitimate investigative purposes only, Clearview’s purposes are entirely appropriate.” We are not convinced by Clearview’s arguments, which cite the same jurisprudence that we have relied on. We remain of the view, based on our analysis outlined above in paragraphs 73 to 78, that Clearview is collecting sensitive biometric personal information, for purposes that a reasonable person would not consider appropriate in the circumstances. Whereas law enforcement agencies rely on the broad collection authority for their operations found in public-sector privacy legislation, these actions are circumscribed by the Charter and Clearview enjoys no such collection authority as a private organization. Although some of the information collected may have ultimately been used for law enforcement, Clearview’s real purpose for the collection is a commercial for-profit enterprise and not law enforcement. Footnote 51 Finally, we note that Clearview emphasizes the absence of harms to individuals flowing from its activities. In taking this position, Clearview fails to acknowledge: (i) the myriad of instances where false, or misapplied matches could result in reputational damage to individuals, and (ii) more fundamentally, the affront to individuals’ privacy rights and broad-based harm inflicted on all members of society, who find themselves under continual mass surveillance by Clearview based on its indiscriminate scraping and processing of their facial images.\n\nAdditional concerns in relation to appropriate purposes\n\nWe note a number of additional issues. We will not specifically opine on them, but we continue to have significant concerns about them in the context of Clearview’s facial recognition practices.\n\nAccuracy\n\nWhile our Offices did not complete a technical assessment of the accuracy of Clearview’s facial recognition technology, we recognize a number of concerns related to facial recognition technology, generally. Our Offices accept that facial recognition technologies may be used to render many services to society and individuals, and have a number of legitimate uses in business and government. For example we recognize that facial recognition can assist businesses with identity authentication, or law enforcement agencies in the investigation of serious and complex crimes. However, while facial recognition technology, and Clearview’s technology in particular, may be effective in certain circumstances, we note that there are significant concerns regarding the efficacy and accuracy of facial recognition technologies, in particular with respect to certain demographics. Despite advances in the sophistication of facial recognition technology through the increase of computational capacity, the improvement of underlying algorithms and the availability of huge volumes of data, such technologies are not perfect and can result in misidentification. This can be the result of a variety of factors, including the quality of photos/videos and the performance of algorithms used to compare facial characteristics. In particular, our Offices take note of claims of accuracy concerns stemming from a variety of studies and investigations of facial recognition algorithms found in a number of technology solutions. Accuracy issues in facial recognition technology can take two general forms: (i) failure to identify an individual whose face is recorded in the reference database, referred to as a “false-negative”; or (ii) matching faces that actually belong to two different individuals, referred to as a “false positive.” While the former is an issue primarily for the users of facial recognition technology, the latter presents compelling risks of harm to individuals, particularly when facial recognition is used in the context of law enforcement. Footnote 52 In particular, we refer to reports that facial recognition technology has been found to have significantly higher incidences of false positives or misidentifications when assessing the faces of people of colour, and especially women of colour, which could result in discriminatory treatment for those individuals. Footnote 53 For example, research conducted by NIST (National Institute of Standards and Technology) found that the rate of false positives for Asian and Black individuals was often greater than that for Caucasians, by a factor of 10 to 100 times. Footnote 54 Harms resulting from such misidentification can range from individuals being excluded from opportunities, to individuals being investigated and detained based on incorrect information. Such harms would generally be classified as significant. Footnote 55 We note that Clearview commissioned an independent panel to complete an accuracy test of their technology, which it claimed was based on the methodology of a previous test conducted by the American Civil Liberties Union ( ACLU ). A copy of the results from this test was provided in Clearview’s representations, and reported a 100% accuracy rate for Clearview’s technology. During our investigation we found that significant concerns, regarding the testing methodology and conclusions, had been raised by a variety of researchers, including the ACLU ’s own team, who characterized the study as “misleading,” and lodged a complaint with Clearview. Footnote 56 In its submissions, Clearview argued that the ACLU and other critics had failed to demonstrate how the results of the test were misleading. It reiterated that in testing, Clearview’s App correctly matched all the images it searched for, with no inaccuracies. While our Office will not opine on the merits of such complaints, we do note the persistent theme of concerns raised in relation to the opacity of Clearview’s technology, which is proprietary and inaccessible to the majority of researchers, make it difficult to make determinations on accuracy.\n\nCollection in contravention of contractual terms\n\nWe note that Clearview has received cease-and-desist letters from Google, Facebook, Twitter, YouTube and LinkedIn regarding their practice of collecting information in violation of terms of service. Footnote 57 Clearview represented that it has responded to these cease-and-desist requests by asserting a First Amendment right to scrape “public” information under the U.S. Constitution. Clearview also asserted that contractual terms have no bearing on our investigation or the appropriateness of its purposes. While we do not opine on whether or not one or more contractual violations occurred, to the extent that Clearview scraped personal information in contravention of platforms’ contractual terms, it would in our view, be relevant as a further factor in considering the inappropriateness of Clearview’s purposes, in the circumstances.\n\nRisk of harm arising from breach\n\nThe large amount of sensitive biometric information held by Clearview would in our view, make it a high value target for malicious actors. Clearview argued that “risk of harm from breach is not an appropriate consideration when assessing the purposes of Clearview’s actions, as this would go well beyond the scope of the law, which is to establish rules that recognize the right of privacy of individuals,” claiming that this risk is present in “almost all areas of society.” It further argued that even if such risks were taken into account, there was no risk of significant harm or likelihood of the information being stolen. While we will not opine on Clearview’s safeguards, which are outside the scope of this investigation, we do note that Clearview publicly announced that it was breached on two occasions within the past year. Once in February 2020 when its client list was leaked, Footnote 58 and again in April 2020 when its source code and pilot project video were obtained and partially leaked. Footnote 59 In our view, Clearview’s collection and subsequent use of billions of images and facial arrays which are linked to source data, represents a significant risk to tens of millions of individuals in Canada should it be compromised.\n\nIssue 3: Did Clearview satisfy its biometric obligations in Quebec?\n\nWhen a company builds a biometrics system in Quebec, it must comply with the rules set out in Quebec’s Private Sector Act and the LCCJTI . Indeed, it must in particular: obtain the express consent of the person concerned, in line with s. 44 of the LCCJTI ; and disclose the creation or existence of the biometrics system to the CAI in line with s. 45 of the LCCJTI . It is apparent from the investigation that Clearview failed to obtain the express consent of the persons concerned, as Clearview has acknowledged that no attempt to seek consent was made. Furthermore, the company failed to disclose the existence of its biometrics system to the CAI .\n\nClearview’s response regarding Quebec’s biometric law\n\nClearview argues that it did not build a biometric system in Quebec, since its activities take place in the United States. Noting that a provincial statute cannot apply extraterritorially in the absence of the express or implied will of the legislature, Clearview concludes that the LCCJTI cannot apply to it, because that would give the law extraterritorial scope that no provision could confer on it, whether explicitly or implicitly. The CAI does not share Clearview’s opinion with respect to the LCCJTI . Indeed, since Clearview does not deny having built a biometric system, the CAI is of the opinion that, even if the biometric system is located outside of Quebec, Clearview has nevertheless collected images in the course of operating a business in Quebec and must therefore obtain the express consent of these individuals before verifying or confirming their identity. The essence of the LCCJTI provisions at issue are respect for the privacy of the individuals concerned and the protection of their personal information. The intention that this mandatory obligation be applied to all persons is made very clear in the French version by the use of the word “ nul ”. The extraterritorial effects are incidental. Clearview, by offering its services within the territorial boundaries of the province and collecting and using the personal information of Quebecers, is operating a business in Quebec. Accordingly, Clearview is subject to the applicable legislation in the jurisdiction in which it is carrying out its activities, namely, the province of Quebec. Footnote 60 Clearview’s physical location and the site of its principal activities are therefore incidental and do not shelter it from the application of the LCCJTI . Therefore, Clearview must obtain the express consent of individuals before verifying or confirming their identity ( s. 44 of the LCCJTI ), as noted in paragraph 40. The sensitivity of the information collected, used or disclosed and the impact that the use of this information may have on the privacy of the individuals concerned requires that they be informed and express their consent. A biometric system cannot be used without the knowledge of the individuals involved. Footnote 61 Clearview was also required to disclose its database of biometric characteristics and measurements to the Commission, in accordance with section 45 of the LCCJTI . Consequently, the CAI finds that Clearview contravened sections 44 and 45 of the LCCJTI .\n\nRecommendations\n\nIn our letter of intention, we shared with Clearview that we could order or recommend to: cease offering the facial recognition services that have been the subject of this investigation to clients in Canada; cease the collection, use and disclosure of images and biometric facial arrays collected from individuals in Canada; and delete images and biometric facial arrays collected from individuals in Canada in its possession. With respect to the first recommendation, we asked Clearview to confirm that it would not resume its offer to provide the facial recognition services in Canada in the future. We also sought Clearview’s commitments explaining how and when it would implement the second and third recommendations.\n\nClearview’s response to our conclusions\n\nAs detailed in this report, Clearview expressly disagreed with our conclusions. Despite this, noting that following engagement with our Offices, it had voluntarily withdrawn from the Canadian market earlier in the investigation, Clearview indicated that it was “prepared to consider maintaining this status for a further two years, in order to allow the various Commissioners to provide detailed and meaningful guidelines as to how Canadian law proposes to deal with artificial intelligence.” Clearview suggested that as it was not “currently active” in Canada, our Offices should suspend our investigation and refrain from issuing a report or making a final determination on this matter. Clearview indicated that “during such a suspension, [it] would be willing to take steps, on a best efforts and without prejudice basis, to try to limit the collection and distribution of the images that it is able to identify as Canadian…” As of the time of writing this report, Clearview had not committed to following our recommendations or orders under consideration, and the Offices deemed it appropriate to issue this report.\n\nConclusions",
            "url": "https://www.priv.gc.ca/en/opc-actions-and-decisions/investigations/investigations-into-businesses/2021/pipeda-2021-001/#toc6-2",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "personal",
                "pipeda",
                "findings",
                "clearview",
                "office",
                "facial",
                "law",
                "québec",
                "investigation",
                "joint",
                "information",
                "privacy",
                "linformation",
                "individuals",
                "consent",
                "images",
                "à",
                "footnote",
                "clearviews"
            ],
            "summary": "BackgroundThis report of investigation examines Clearview AI, Inc.’s (Clearview) compliance with Canada’s Personal Information Protection and Electronic Documents Act ( PIPEDA ), Quebec’s Act Respecting the Protection of Personal Information in the Private Sector (Quebec’s Private Sector Act), and Act to Establish a Legal Framework for Information Technology ( LCCJTI ), British Columbia’s Personal Information Protection Act ( PIPA BC ), and Alberta’s Personal Information Protection Act ( PIPA AB ) – referred to collectively as the Acts.\nWe further note that the additional contextual information provided via source links (that is, social media and websites) can include significant personal information of varying levels of sensitivity.\nFurther, Clearview’s collection of information includes the mass indiscriminate collection of the personal information of minors, which would be considered particularly sensitive.\nWe will not specifically opine on them, but we continue to have significant concerns about them in the context of Clearview’s facial recognition practices.\nThe essence of the LCCJTI provisions at issue are respect for the privacy of the individuals concerned and the protection of their personal information.",
            "metadata": {
                "source_domain": "www.priv.gc.ca",
                "scrape_date": "2024-10-25T12:40:27.908082",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 63449
            }
        },
        {
            "title": "PIPEDA Findings #2021-001: Joint investigation of Clearview AI, Inc. by the Office of the Privacy Commissioner of Canada, the Commission d’accès à l’information du Québec, the Information and Privacy ",
            "text": "PIPEDA Findings #2021-001\n\nFebruary 2, 2021\n\nOverview\n\nThe Privacy Commissioner of Canada ( OPC ), the Commission d’accès à l’information du Québec ( CAI ), the Information and Privacy Commissioner for British Columbia ( OIPC BC ), and the Information and Privacy Commissioner of Alberta ( OIPC AB ), collectively referred to as “the Offices”, commenced a joint investigationFootnote 1 to examine whether Clearview AI, Inc.’s (“Clearview”) collection, use and disclosure of the personal information by means of its facial recognition tool complied with federal and provincial privacy laws applicable to the private sector.\n\nSpecifically, the Offices sought to determine whether Clearview:\n\nobtained requisite consent to collect, use and disclose personal information; and collected, used and disclosed personal information for an appropriate purpose Footnote 2.\n\nAdditionally, the CAI sought to determine whether Clearview had:\n\nReported the creation of a database of biometric characteristics or measurements.\n\nClearview’s facial recognition tool functions in four key sequential steps - Clearview:\n\n“scrapes” images of faces and associated data from publicly accessible online sources (including social media), and stores that information in its database; creates biometric identifiers in the form of numerical representations for each image; allows users to upload an image, which is then assessed against those biometric identifiers and matched to images in its database; and provides a list of results, containing all matching images and metadata. If a user clicks on any of these results, they are directed to the original source page of the image.\n\nThrough this process, Clearview amassed a database of over three billion images of faces and corresponding biometric identifiers, including those of a vast number of individuals in Canada, including children.\n\nClearview asserted that the tool is intended for use by law enforcement,Footnote 3 for legitimate law enforcement and investigative purposes. A variety of organizations, including private sector entities, used this service via a free-trial service.\n\nBiometric information is considered sensitive, in almost all circumstances, and facial recognition data is particularly sensitive. Furthermore, individuals who posted their images online, or whose images were posted by third party(ies), had no reasonable expectations that Clearview would collect, use and disclose their images for identification purposes. As such, express consent would generally be required. In Quebec, such use of biometric data requires express consent.\n\nClearview did not attempt to seek consent from the individuals whose information it collected. Clearview asserted that the information was “publicly available”, and thus exempt from consent requirements. Information collected from public websites, such as social media or professional profiles, and then used for an unrelated purpose, does not fall under the “publicly available” exception of PIPEDA , PIPA AB or PIPA BC . Nor is this information “public by law”, which would exempt it from Quebec’s Private Sector Law, and no exception of this nature exists for other biometric data under LCCJTI . Therefore, we found that Clearview was not exempt from the requirement to obtain consent.\n\nFurthermore, the Offices determined that Clearview collected, used and disclosed the personal information of individuals in Canada for inappropriate purposes, which cannot be rendered appropriate via consent. We found that the mass collection of images and creation of biometric facial recognition arrays by Clearview, for its stated purpose of providing a service to law enforcement personnel, and use by others via trial accounts, represents the mass identification and surveillance of individuals by a private entity in the course of commercial activity. We found Clearview’s purposes to be inappropriate where they: (i) are unrelated to the purposes for which those images were originally posted; (ii) will often be to the detriment of the individual whose images are captured; and (iii) create the risk of significant harm to those individuals, the vast majority of whom have never been and will never be implicated in a crime. Furthermore, it collected images in an unreasonable manner, via indiscriminate scraping of publicly accessible websites.\n\nWe identified certain other concerns on which we did not ultimately opine, but which we felt appropriate to raise in our report. This includes the fact that there were credible challenges to, and questions regarding, the efficacy and accuracy of facial recognition technologies generally, and regarding the reliability of Clearview’s testing results specifically.\n\nWe shared our preliminary findings and recommendations with Clearview, with a view to bringing it into compliance with federal and provincial private sector privacy law. We recommended that Clearview: (i) cease offering its facial recognition tool to clients in Canada; (ii) cease the collection, use and disclosure of images and biometric facial arrays collected from individuals in Canada; and (iii) delete images and biometric facial arrays collected from individuals in Canada in its possession.\n\nClearview expressly disagreed with our findings.\n\nIn disagreeing with our findings, Clearview alleged an absence of harms to individuals flowing from its activities. In our view, Clearview’s position fails to acknowledge: (i) the myriad of instances where false, or misapplied matches could result in reputational damage, and (ii) more fundamentally, the affront to individuals’ privacy rights and broad-based harm inflicted on all members of society, who find themselves under continual mass surveillance by Clearview based on its indiscriminate scraping and processing of their facial images.\n\nIn terms of remedies, noting that it had withdrawn from the Canadian market during our investigation, Clearview stated that it was “prepared to consider” remaining outside of the Canadian market for a further two years, while our Offices developed relevant guidance. Clearview suggested that it would be appropriate for our Offices to suspend our investigation and not issue this final report, and that during such a suspension, it “would be willing to take steps, on a best efforts and without prejudice basis, to try to limit the collection and distribution of the images that it is able to identify as Canadian” [emphasis added]. Clearview has not committed to following our recommendations. The Offices view it as inappropriate to suspend the investigation and not issue this Report. We therefore find the matter to be well-founded and restate the recommendations in our preliminary findings.\n\nAdditionally, the CAI determined that contrary to the requirements of the LCCJTI , Clearview had not advised the CAI that it had created a database of biometric characteristics, nor obtained the express consent from individuals that verifying or confirming their identity would be conducted using a facial recognition process.\n\nBackground\n\nThis report of investigation examines Clearview AI, Inc.’s (Clearview) compliance with Canada’s Personal Information Protection and Electronic Documents Act ( PIPEDA ), Quebec’s Act Respecting the Protection of Personal Information in the Private Sector (Quebec’s Private Sector Act), and Act to Establish a Legal Framework for Information Technology ( LCCJTI ), British Columbia’s Personal Information Protection Act ( PIPA BC ), and Alberta’s Personal Information Protection Act ( PIPA AB ) – referred to collectively as the Acts. Clearview is a technology company headquartered in the United States that developed and delivered its facial recognition Footnote 4 software and combined database solution (App) to clients around the world. Clearview’s App allows clients to upload a digital image of an individual’s face and run a search against it. The App then applies its algorithm to the digital image and runs the result against Clearview’s database to identify and display likely matches and associated source information. In January and February 2020, public reports Footnote 5 indicated that Clearview was populating its facial recognition database by collecting digital images from a variety of public websites, including but not limited to, Facebook, YouTube, Instagram, Twitter and Venmo, in apparent violation of those organizations’ terms of service and without the consent of individuals. It was further indicated that these digital images were then indefinitely stored in Clearview’s database to be sourced and served as results for facial recognition searches. In February 2020, multiple reports Footnote 6 surfaced confirming that a number of Canadian law enforcement agencies and private organizations Footnote 7 had used Clearview’s services in order to identify individuals. Satisfied that reasonable grounds existed to investigate these matters, in February 2020, the Office of the Privacy Commissioner of Canada ( OPC ), the Commission d’accès à l’information du Québec ( CAI ), the Information and Privacy Commissioner for British Columbia ( OIPC BC ), and the Information and Privacy Commissioner of Alberta ( OIPC AB ), collectively referred to as the Offices, each initiated investigations pursuant to s. 11(2) of PIPEDA , s. 81 of Quebec’s Private Sector Act, s. 36(1)(a) of PIPA BC , and s. 36(1)(a) of PIPA AB respectively. The Offices decided to conduct the investigation jointly in order to maximize their expertise and their resources, while avoiding duplication of their efforts and those of Clearview.\n\nIssues\n\nThe issues in this investigation were: Whether Clearview was required under the Acts to get consent for its collection, use and disclosure of personal information and if so, whether it did; and Whether Clearview collected, used and/or disclosed personal information for a purpose that a reasonable person would consider appropriate in the circumstances, for a purpose that was reasonable and to fulfill a legitimate need? Footnote 8 The following Quebec-specific issue was also examined: Did Clearview previously disclose to the CAI the creation of a database of biometric characteristics or measurements? During the course of the investigation, specifically after the letter of intention referred to in paragraph 11 below, Clearview also asserted that our Offices do not have jurisdiction over the Clearview activities in question. We address this issue in our analysis, prior to considering the issues identified above.\n\nMethodology\n\nIn addition to conducting extensive open-source research, the investigative team (the team) analyzed representations provided by Clearview and records relating to its activities. The team also examined representations from a number of third parties identified as possible users of Clearview’s service. Between February and November 2020, Clearview provided multiple sets of written representations to our Offices. Furthermore, we gave Clearview multiple opportunities to meet with us to make inquiries and provide additional evidence. We conducted two such meetings in June 2020. Upon completion of the evidence-gathering phase of the joint investigation, our Offices issued a letter of intention to Clearview on October 29 2020, which set out and explained the rationale for our preliminary findings, identified several orders and recommendations under consideration and invited Clearview to respond. We then met with Clearview on November 17 to clarify our views, provide an opportunity to ask any questions, and discuss potential remedies to resolve the matter. On November 20, Clearview provided a written response articulating its disagreement with our preliminary findings and orders and recommendations under consideration. In this letter, Clearview set out a variety of new arguments, and provided new information which our Offices considered and assessed before producing this report of findings.\n\nClearview’s representations and our investigation\n\nThis section reflects initial representations provided by Clearview up to the point of the issuance of our letter of intention. Further representations provided by Clearview in its response to our letter of intention are included under our analysis of each issue.\n\nOverview of Clearview’s facial recognition implementation\n\nIn its submissions, Clearview explained that its facial recognition technology is based on five primary components: (i) image crawler, (ii) image store, (iii) metadata store, (iv) neural network and (v) vector database. The image crawler is an automated tool that searches public web pages and collects any images that it identifies as containing faces along with associated metadata such as the title, source link and description. This process is commonly referred to as “scraping.” The images and metadata collected through this scraping process are indefinitely stored on Clearview’s servers in the image and metadata stores respectively. The neural network underpins the algorithm that analyzes digital images of faces and turns them into numerical representations referred to as “vectors”. Clearview’s vectors consist of 512 data points that represent the various unique lines that make up a face. Clearview then stores all of these vectors in their vector database, where they are associated with the images stored on Clearview’s server. Every image in the database has a vector associated with it in order to allow identification and matching. When an App user wishes to identify an individual, they are required to upload an image of their target into the App and run a search. The neural network then analyzes the image and produces a vector. This vector is then compared against all vectors stored in Clearview’s database, with the App pulling any matching images from the vector database and providing them to the user, along with any associated metadata, as search results. Clearview stated that images uploaded by users are stored separately from images obtained from scraping, and do not show up in any search results. Clearview advised that its search results are displayed in a list containing thumbnail images that appear to be a match for the individual, the name of the image, description and source link. The user must then click the associated source link to be re-directed to the web page where the image was originally collected, in order to obtain additional information. Clearview stated that it “[does] not possess or maintain any information about names, addresses, nationality, date of birth [or] location” associated with the images in its database.\n\nClearview’s privacy practices regarding consent\n\nClearview originally stated that it does not seek consent from individuals whose information it collects. Rather, Clearview stated that in its view, the images it collected were publicly available and therefore it did not require the knowledge or consent of individuals to collect their information. In support of this position, Clearview stated that it only collected images from publicly-viewable web pages, and did not collect any images protected by privacy settings, such as those associated with certain social media accounts, or from pages that enabled “robots.txt”. Footnote 9 Clearview has confirmed that their image crawler is configured to respect whatever instructions are present in the robots.txt file.\n\nClearview’s purposes\n\nIn its initial representations, Clearview advised our Offices that its App was intended to be for the sole and exclusive use of law enforcement. This was reflected in Clearview’s terms of service, which state that “Users may use [the] Service for legitimate law enforcement and investigative purposes” and that “users may not use the Service for any reason other than law enforcement or investigative purposes.” In response to our letter of intention, Clearview advised that previously, its terms of service also extended access to “security professionals”. Clearview asserted that their technology provides “substantial, concrete benefits to public safety by dramatically increasing law enforcement’s ability to identify and investigate suspects, victims and witnesses.” Clearview pointed to numerous successes in cases ranging from “murder, armed robbery and child sexual exploitation to terrorism, major narcotics trafficking and multi-million dollar fraud.” When asked to speak to potential harms to Canadians that could arise from its technology, Clearview stated that any such harms were only hypothetical. Clearview stated that any “harm that a person would suffer from a Clearview search of their image is comparable to the harm that the person suffers when a Google search of his or her name is performed.” Clearview further indicated that no single user could browse their full database as results were only provided for matches, thus mitigating any risk. Clearview stated that even if its database were to be compromised and released, the images therein are all already accessible online, and thus not sensitive, and the vectors that it uses for biometric matching are hashed, Footnote 10 so they are useless outside of the Clearview App. While Clearview originally allowed a variety of public and private organizations to create accounts, we note that in response to our investigation, Clearview stated that it had suspended access to all users in Canada, outside the RCMP , in March 2020. Following further engagement with our Offices during the investigation, Clearview voluntarily exited the Canadian market in July 2020.\n\nComparison with other organizations\n\nClearview asserted that its App is essentially an image search engine and asked our Offices why we were “treating them differently from other search engines”. This investigation focuses on Clearview's practices and not on those of the search engines cited by Clearview. Our Offices initiate and conduct investigations into organizations on the basis of each case’s own particular set of facts. As such, we do not express an opinion on the obligations of any other organizations in this report.\n\nAnalysis\n\nClearview’s jurisdictional challenge\n\nAt the latter stages of our investigation, subsequent to receiving the letter of intention from our Offices seeking a response to the preliminary findings in this matter, Clearview argued that none of our Offices have jurisdiction over its activities, asserting that “[n]one of Clearview’s activities take place in Canada” and that it “is of the view in the circumstances that none of the statutes invoked apply and that no connecting factors create a real and substantial link to Canada.” Clearview submitted that PIPEDA does not apply “because there is no real and substantial connection to Canada.” Specifically, Clearview argued that the circumstances in the matter at hand were such that no real and substantial connection with Canada existed: the content referred to in Clearview’s platform was not “uniquely Canadian” and that it has content from “several other countries all over the world”; Clearview’s services were “not directly and solely directed at Canadians” and that “not many Canadians would have used [its] services”, asserting that “beyond the trial users, the only allegation is that one Canadian entity, the RCMP , would have used Clearview’s services”; and “there [appeared] to be no evidence that Clearview’s services are mainly felt by Canadians”. Clearview further argued that it is not subject to any provincial privacy laws as in its view: it did not collect, use or disclose personal information “within the provinces of Alberta, Quebec or British Columbia, but rather in the United States”; there was “no evidence or allegation” that Clearview did business within said provinces; and collection, use or disclosure had to take place entirely within each province to be applicable under the acts, and that there is “no evidence or allegation” that this took place.\n\nOPC ’s jurisdiction\n\nThe OPC notes that PIPEDA applies to organizations outside of Canada where a “real and substantial connection” to Canada exists. Footnote 11 In our view, the circumstances in this matter clearly demonstrate that a real and substantial connection to Canada exists. In coming to this conclusion, we considered the relevant connecting factors that flow from the jurisprudence, including the factors set out in A.T. v. Globe24h: (1) the location of the target audience of the website, (2) the source of the content on the website, (3) the location of the website operator, and (4) the location of the host server. Footnote 12 Regarding the location of Clearview’s target audience: While Clearview claims that its activity in Canada was limited, this is at odds with the fact that it actively marketed its services to Canadian organizations through promotional material, testimonials from Canadian law enforcement professionals, and agency-specific presentations and trials. Furthermore, Clearview publicly declared Canada to be part of its core market in statements to the media Footnote 13 and its own promotional materials. Footnote 14 The fact that only one agency became a paying customer is, in our view, immaterial. The colour and character of Clearview’s activities were commercial in nature, with trials existing for the express purpose of enticing the purchase of accounts. Clearview’s representations confirmed that 48 accounts (trial or otherwise) were created for law enforcement agencies and organizations across Canada, and thousands of searches were conducted through these accounts. In particular, we note that various provincial law enforcement agencies used trial accounts of the App for several months, with the number of searches conducted per trial account ranging from tens, to hundreds, or in one case, thousands. Furthermore, dismissing the RCMP as only “one Canadian entity” ignores the fact that the RCMP is Canada’s national law enforcement agency, operating all over Canada with national, federal, provincial, and municipal policing mandates. Regarding the source of Clearview’s content: It is not a requirement that Clearview’s content be exclusively derived from Canadian sources for there to be a real and substantial connection to Canada. As set out in Lawson v. Accusearch Inc., it is not necessary to identify specific Canadian sources of content to determine we have jurisdiction. Clearview’s assertion that it collects images without regard to geography or source does not preclude our jurisdiction when a substantial amount of its content is sourced from Canada. The exact number of images derived from individuals in Canada is unknown due to the fact that Clearview does not retain the national source. However, the indiscriminate nature of Clearview’s scraping renders it a relative certainty that it collected millions of images of individuals in Canada, Footnote 15 and used them to derive biometric image vectors for its database, including to market to Canadian law enforcement agencies. Finally, regarding the location of Clearview’s website operations and host server: We note that Clearview’s activities take place exclusively through a website or app. As referenced in paragraph 54 of A.T. v. Globe24h.com, a physical presence in Canada is not required to establish a real and substantial connection when considering websites under PIPEDA , as telecommunications occur “both here and there.” Clearview’s operations necessitate the transmission and receipt of personal information between Canada and the USA, both when collecting information and disclosing it through its software. As set out by the Supreme Court of Canada Footnote 16: “Receipt may be no less “significant” a connecting factor than the point of origin (not to mention the physical location of the host server, which may be in a third country).”\n\nProvincial jurisdiction\n\nWe further reject Clearview’s assertion that it is not subject to PIPA AB , PIPA BC or Quebec’s Private Sector Act (the Provincial Acts), respectively, and are of the view that Clearview’s activities fall under the jurisdiction of both the OPC and the provinces. Footnote 17 Provincial privacy legislation applies to any private sector organization that collects, uses and discloses information of individuals within that province. Clearview’s practice of indiscriminate scraping has undoubtedly resulted in the collection of the personal information of individuals within Quebec, Alberta and British Columbia, whose residents collectively account for nearly half of the Canadian population. In addition, provincial and municipal law enforcement agencies located within the provinces and subject to provincial oversight were targeted and used trial accounts of Clearview’s software, in the course of which they provided, and Clearview collected, personal information in the form of photographs of individuals. Footnote 18 Clearview is a commercial enterprise that collected, used, and disclosed personal information of individuals within Quebec, Alberta and British Columbia with the intention of selling a product to law enforcement agencies within the provinces. The fact that a company is located outside of Quebec, Alberta and British Columbia, does not mean it can evade obligations under Quebec’s Private Sector Act, PIPA AB and PIPA BC . Indeed, whenever a company collects the personal information of individuals located within a province, regardless of where the company is located, the Provincial Acts apply. Footnote 19 Considering the above, the Offices do not accept Clearview’s assertion that provincial legislation does not apply and are of the view that: the Provincial Acts apply, as previously stated; the Provincial Acts do not prevent the achievement of PIPEDA ’s objective, nor do they result in operational conflict or conflict of intent; each Provincial Act has been found to be substantially similar to PIPEDA . Footnote 20\n\nIssue 1: Did Clearview obtain requisite consent?\n\nIn our view, Clearview did not obtain consent required for its collection, use and disclosure of personal information through the App. In coming to this determination, we note that Clearview made no attempt whatsoever to obtain consent from individuals, given its erroneous interpretation of Canadian privacy law, which sets out when information is “publicly available” or “public under the law”. The Acts state that the consent of the individual is required for the collection, use or disclosure of personal information unless an exception applies. Footnote 21 The type of consent required will vary depending on the circumstances and the type of information involved. The Guidelines for obtaining meaningful consent Footnote 22 (the Guidelines) jointly issued by the OPC , OIPC AB and OIPC BC provide that “organizations must generally obtain express consent” when: (i) the information being collected, used or disclosed is sensitive; (ii) the collection, use or disclosure is outside of the reasonable expectations of the individual; and/or (iii) the collection, use or disclosure creates a meaningful residual risk of significant harm. Beyond Clearview’s collection of images, we also note that its creation of biometric information in the form of vectors constituted a distinct and additional collection and use of personal information, as previously found by the OPC , OIPC AB and OIPC BC in the matter of Cadillac Fairview. Footnote 23 With respect to biometric characteristics and measurements, Quebec’s LCCJTI specifically requires the express consent of the person concerned. Consent is described as express when it is explicit and unequivocal. To give express consent, a person must perform a positive action that clearly demonstrates his or her agreement. Footnote 24 To perform such an action, the person must be informed about what his or her consent entails. Footnote 25 The consent must be free, enlightened, given for specific purposes and limited in time. Footnote 26 In our view, biometric information is sensitive in almost all circumstances. It is intrinsically, and in most instances permanently, linked to the individual. It is distinctive, unlikely to vary over time, difficult to change and largely unique to the individual. That being said, within the category of biometric information, there are degrees of sensitivity. It is our view that facial biometric information is particularly sensitive. Possession of a facial recognition template can allow for identification of an individual through comparison against a vast array of images readily available on the Internet, as demonstrated in the matter at hand, or via surreptitious surveillance. For these reasons, it is our view that in the absence of an applicable exception, Clearview should have obtained express opt-in consent before it collected the images of any individual in Canada. In its submissions, Clearview acknowledged that it did not seek consent from the individuals whose information it collected, used or disclosed. Clearview argued that the information it collected was “publicly available” and that there was thus no reasonable expectation of privacy. Our Offices note that PIPEDA , PIPA BC and PIPA AB have exceptions to the requirement for consent where the personal information at issue is publicly available as set out in section 7(1)(d) of PIPEDA , sections 12(1)(e), 15(1)(e) and 18(1)(e) of PIPA BC , and sections 14(e), 17(e) and 20(j) of PIPA AB . The definition of “publicly available” is provided by each Act’s regulations Footnote 27 and is distinct from a common understanding of “publicly accessible” information. Information from sources such as social media or professional profiles, collected from public websites and then used for an unrelated purpose, does not fall under the “publicly available” exception of PIPEDA . Footnote 28 Similarly, the respective regulations of both PIPA AB and PIPA BC Footnote 29 prescribe sources of public information that include directories, registries, and publications. Social media websites and search engines are not listed as prescribed sources of publicly available information under either of these Acts. As such, collection from these sources would only be authorized with consent and only if the purposes are what a reasonable person would consider appropriate. Footnote 30 Quebec’s Private Sector Act and LCCJTI do not distinguish, and make no allowance for, “publicly available information.” However, Quebec’s Private Sector Act does not apply to information “which by law is public.” There are no Quebec statutes under which personal information is deemed to be public solely based on the fact that it has been posted on social media or the Web. Moreover, the CAI has previously ruled that, even where personal information has been posted on a public website, it does not mean that the information may be used for other purposes without the consent of the person concerned. Footnote 31 The fact that images are published on a website does not necessarily mean that their author has consented to their use by a third party. As such, our Offices do not recognize the personal information collected, used or disclosed by Clearview to be “publicly available” as envisioned by the Acts, or as information “which by law is public,” and thus the exception does not apply. As Clearview made no attempt to obtain consent, and no exception from the requirement to obtain consent is found to be applicable, we find that Clearview contravened sections 6.1 as well Principle 4.3 of Schedule 1 of PIPEDA , section 7 of PIPA AB , sections 6-8 of PIPA BC , sections 6 and 12-14 of Quebec’s Private Sector Act and section 44 of the LCCJTI .\n\nClearview’s response regarding consent\n\nIn its response, Clearview stated that: “With respect to the consent obligation under federal and provincial legislation, and assuming, without waiving the lack of jurisdiction invoked above that such laws apply, Clearview submits that the exception for publications which are publicly available applies. Information collected by Clearview is nothing more than information available to the public.” Clearview argued that its collection of information qualified under the exception set out in regulation for “personal information that appears in a publication, including a magazine, book or newspaper, in printed or electronic form, that is available to the public, where the individual has provided the information.” Footnote 32 In regard to Quebec’s legislation, which does not contain such exceptions, Clearview argued that the exception must necessarily be implied. It argued that otherwise, “the legislation is invalid because it breaches the Quebec and Canadian Charter guarantees of freedom of expression.” The respondent further argued that the regulatory definition of publicly available information “is not distinct from the common understanding of the words” and that while Parliament “did define some categories of items that may be included in what is said to be public, it did not restrict the definition with respect to publication,” stating that: “In Clearview’s submission, the definition [of a publication] could hardly be broader. As a result, personal information located on public blogs, public social media or any other public websites are included in the “publicly available” exception as they are included in the definition of a publication. Therefore, the collection of such information does not require consent.” In support of its position, Clearview cited the Federal Court of Appeal’s decision in Lukács v. Canada, Footnote 33 stating that “this decision makes it clear that these terms are not narrow and include any publication that is “available or accessible by the citizenry at large.” Clearview further submitted that the expectation of privacy for information in the public view “is or should be reduced” and that a broad interpretation of publicly available information should be preferred, stating: “Even if the regulation and its exceptions are ambiguous, and require an exercise in interpretation, they must be interpreted in accordance with the Canadian Charter. Restricting the free flow of publicly available information is contrary to the constitutional protection of freedom of expression. For this reason, exceptions to this principle must be narrowly construed and a broad interpretation of publicly available must be preferred so as not to unduly limit freedom of expression.” Finally, Clearview argued that: “In these circumstances, […] the positive effects of protecting personal information do not outweigh the negative effects on Clearview's freedom of expression. There is no pressing and substantial concern justifying an infringement on freedom of expression given the lack of a reasonable expectation of privacy in images that individuals themselves have already either placed or permitted to be placed in the public domain.” Based on these arguments, Clearview asserted that it did not contravene any of the Acts, as all of the information it collected and used was exempted as publicly available. As we note in paragraph 36, Clearview did not make any attempt to seek consent from individuals. Instead Clearview relies entirely on its argument that the personal information it collected, used and disclosed was publicly available and thus exempted from consent requirements. In considering Clearview’s submissions, our Offices have concluded that this view is incorrect, and that the exemption does not apply in the circumstances of this case. As set out in PIPEDA and confirmed in Turner v. Telus Communications Inc. Footnote 34, information will only be deemed “publicly available” if both publicly available and specified by the regulations. Clearview further argued that a “plain language” interpretation of the regulations was appropriate, and that it followed that a broad definition of the term “publication,” should be applied when considering whether the exemption applies. Clearview further argued that such a broad interpretation would be in accordance with the Canadian Charter of Rights and Freedoms (the Charter), namely freedom of expression. We do not accept this to be the case based on the facts, law or available jurisprudence as outlined below. It is our view that Lukács c. Canada is not applicable to the matter at hand, as it concerns the application of the Privacy Act, which is distinct from PIPEDA . In particular, we note that unlike in the Privacy Act, the meaning of “publicly available information” and what qualifies as a “publication” is specifically defined in PIPEDA , PIPA AB Footnote 35 and PIPA BC Footnote 36 by regulation (the Regulations). The Regulations thus take precedence. When interpreting the Regulations, we note that as privacy legislation is considered by the courts to be quasi-constitutional, Footnote 37 the rights accorded under them should be given a broad, purposive and liberal interpretation, and restrictions on those rights should be interpreted narrowly. Footnote 38 Since the Regulations create an exemption to a core privacy protection – the requirement for collection, use and disclosure of personal information to be with consent - they should be interpreted narrowly. With this in mind, we do not accept Clearview’s arguments in favour of a wider “plain language” interpretation. For example, social media, from which Clearview obtained a significant proportion of the images in its database, is not specified as a “publication” in the language of the PIPEDA regulations. It is the OPC ’s view that social media web pages differ substantially from the sources identified in the PIPEDA regulations. As the OPC previously found in the matter of Profile Technology, Footnote 39 there are a number of key differences between online information sources such as social media, and the examples of “publications” included in 1(e): social media web pages contain dynamic content, with new information being added, changed or deleted in real-time; and individuals exercise a level of direct control, a fundamental component of privacy protection, over their social media accounts, and over accessibility to associated content over time – for example, via privacy settings. In addition, the OIPC BC also takes the position that social media websites are not prescribed sources of “publicly available” information, and any collection from these sources would only be authorized with consent and only if the purposes are what a reasonable person would consider appropriate. Ultimately, Clearview’s assertions that publication necessarily includes “public blogs, public social media or any other public websites,” taken to their natural conclusion, imply that all publicly accessible content on the Internet is a publication in some form or other. This would create an extremely broad exemption that undermines the control users may otherwise maintain over their information at the source. In this regard, it has been noted that control is a fundamental component of privacy protection. Footnote 40 Even if such web pages were to be considered “publications” in the meaning of the Regulations, which we do not accept, s. 1 (e) of the PIPEDA Regulations and s. 7(e) of the PIPA AB Regulations specify that the exception only applies “where the individual has provided the information,” or where “it is reasonable to assume that the individual that the information is about provided that information,” respectively. As Clearview engages in mass collection of images through automated tools, it is inevitable that in many instances, the images would have instead been uploaded by a third party. Clearview argued that Quebec’s Private Sector Act implicitly includes an exclusion for “publicly available” personal information—because if it did not it would violate the freedom of expression. The CAI is of the view that argument cannot be accepted for the following reasons: The text of the Act clearly indicates that only information that is public “by law” is excluded, which does not include information that is otherwise available to the public in the absence of a law designating it as public. As a quasi-constitutional law that takes precedence over other legislation in Quebec, and has the purpose of clarifying the exercise of rights conferred by the Civil Code of Québec, specifically the right to privacy, any exceptions must be interpreted restrictively. Therefore, there exists no implied exclusion from Quebec’s Private Sector Act for publicly available information not designated as public by law. Because Clearview did not inform the AG as required by section 76 of the Code of Civil Procedure, the Commission cannot consider claims raised by Clearview suggesting that the Act respecting the private sector is inoperative. Indeed, such a review cannot take place if the Attorney General of Quebec has not been informed or been given an opportunity to make representations. Nor does it suffice to raise a freedom of expression violation. Clearview has neither explained nor demonstrated how its activities constitute the expression of a message relating to the pursuit of truth, participation in the community or individual self-fulfillment and human flourishing. Footnote 41\n\nIssue 2: Was Clearview collecting, using or disclosing personal information for an appropriate purpose?\n\nIn our view, for the reasons outlined below, Clearview’s purpose for collecting, using or disclosing personal information was neither appropriate nor legitimate. In accordance with the OPC ’s Guidance on inappropriate data practices: Interpretation and application of subsection 5(3), Footnote 42 the OPC considers the factors Footnote 43 set out by the courts in order to assist in determining whether a reasonable person would find that an organization’s collection, use and disclosure of information is for an appropriate purpose in the circumstances. These factors are to be applied in a contextual manner, which suggests flexibility and variability in accordance with the circumstances. Footnote 44 In applying s. 5(3), the courts have determined that the OPC is required to engage in a “balancing of interests” between the individual’s right to privacy and the commercial needs of the organization concerned. Footnote 45 This balancing of interests must be “viewed through the eyes of a reasonable person.” Footnote 46 Similar factors are also considered by OIPC BC in determining whether the purpose is reasonable. Footnote 47 Section 2 of PIPA AB says that in determining whether a thing or matter is reasonable or unreasonable, the standard to be applied is “what a reasonable person would consider appropriate in the circumstances”. Orders issued by the OIPC AB have also identified a number of questions for determining whether the collection of personal information in an instance was for a reasonable purpose, Footnote 48 including whether the collection of personal information was carried out in a reasonable manner. Finally, in analyzing whether Clearview had a serious and legitimate reason to establish a file on another person under section 4 of Quebec’s Private Sector Act, the CAI considers the lawfulness of the objective sought and its compliance with the law, justice and fairness. Footnote 49 We find that the collection of images and creation of biometric facial recognition arrays by Clearview, for its stated purpose of providing a service to law enforcement personnel, and use by others via trial accounts, represents the mass identification and surveillance of individuals by a private entity in the course of commercial activity. In our view, for the reasons outlined below, a reasonable person would not consider this purpose to be appropriate, reasonable, or legitimate in the circumstances, within the meaning of subsection 5(3) of the PIPEDA , sections 11, 14 and 17 of PIPA BC , Footnote 50 sections 11, 16 and 19 of PIPA AB and section 4 of Quebec’s Private Sector Act. As previously indicated, our Offices find the information at issue (facial biometrics generated from digital images) to be of a sensitive nature. Biometric information is distinctive, unlikely to vary over time, difficult to change and largely unique to the individual. Facial biometric data is particularly sensitive given that it is a key to an individual’s identity, supporting the ability to identify and surveil individuals. We further note that the additional contextual information provided via source links (that is, social media and websites) can include significant personal information of varying levels of sensitivity. Further, Clearview’s collection of information includes the mass indiscriminate collection of the personal information of minors, which would be considered particularly sensitive. It is our view that Clearview does not, in the circumstances, have an appropriate purpose, for: the mass and indiscriminate scraping of images from millions of individuals across Canada, including children, amongst over 3 billion images scraped world-wide; the development of biometric facial recognition arrays based on these images, and the retention of this information even after the source image or link has been removed from the Internet; or the subsequent use and disclosure of that information for its own commercial purposes; where such purposes: are unrelated to the purposes for which the images were originally posted (for example, social media or professional networking); are often to the detriment of the individual (for example, investigation, potential prosecution, embarrassment, etc.); and create the risk of significant harm to individuals whose images are captured by Clearview (including harms associated with misidentification or exposure to potential data breaches), where the vast majority of those individuals have never been and will never be implicated in a crime, or identified to assist in the resolution of a serious crime. Furthermore, Clearview’s collection of sensitive biometric personal information, as described above, was not, in our view, carried out in a legal manner. Clearview collects the information to populate its facial recognition database without obtaining express consent of the individuals in question, as required by the Acts, or any form of knowledge or consent for that matter. Clearview did not collect the information directly from the individuals in question. Nor did it have any relationship with the third parties whose websites it scraped, who could have, hypothetically, obtained consent for Clearview’s purposes. In fact, several of these third parties have made credible allegations that Clearview was not authorized to collect the information from their websites. As such, Clearview achieved its purposes via collection that inherently contravened Canadian privacy laws. Therefore, those purposes cannot in our view be considered appropriate. Consequently, we find that Clearview contravened: subsection 5(3) of the PIPEDA , section 4 of Quebec’s Private Sector Act, sections 11, 14 and 17 of PIPA BC and sections 11, 16 and 19 of PIPA AB .\n\nClearview’s Response Regarding Appropriate Purposes\n\nClearview disagreed with our preliminary characterization of its purposes and stated that its collection of information was to “enable law enforcement agencies to obtain information quickly and accurately in the course of an ongoing investigation” and that a reasonable person would consider this purpose to be “appropriate, reasonable and legitimate in the circumstances.” Clearview re-iterated its view that this information was publicly available and thus not sensitive. Clearview asserted that: “the difference between the purposes for which the images were originally posted and the ones for which Clearview used, collected, or disclosed them is irrelevant. If the purposes underlying Clearview's actions are appropriate and legitimate, it is reasonable to believe that Clearview has complied with this section of the law even if such images are not used, collected or disclosed for the same reason they were posted originally.” Clearview also asserted that any detriment to individuals resulting from the use of its services could not be imputed to Clearview, stating that: “Prosecution by law enforcement agencies using Clearview's services is in no way a direct and unique consequence of the services offered. Clearview cannot be held responsible for offering services to an entity that subsequently makes an error in its assessment of the person being investigated. Many factors will be taken into account by law enforcement agencies when doing their work. Clearview provides potential matches – just as witnesses provide potential identification in a line-up or eye-witness testimony. Law enforcement officials must ultimately determine the suitable use to be made of such information in the course of their investigations.” Clearview argued that a characterization of its purposes as detrimental to individuals was incorrect, stating: “Clearview's objectives are not to the detriment of individuals, but rather to the benefit of the community and the public interest by assisting law enforcement agencies responsible for public safety in their inquiries. Limiting such a service would arguably be at the expense of the public interest. Clearview facilitates research by providing a platform that contains all the information needed, information that is already available but dispersed on several third-party websites.” Clearview further argued that the only potential harm to most individuals would be that a link to a photo might be sent to a law enforcement agency, which in their view could not be described as significant. It opined that such potential harm was not disproportionate to the “benefits and objectives to which [Clearview] contributes.” Clearview concluded by referencing the purpose clause of PIPEDA , stating that: “when determining whether there are appropriate purposes involved, one must evaluate the balance between the privacy right of an individual and the need of organizations to collect, use or disclose personal information.” and that: “Given the significant potential benefit of Clearview's services to law enforcement and national security on the one hand, and the fact that significant harm is unlikely to occur on the other, especially considering that the information held is already publicly available and is distributed to law enforcement agencies for legitimate investigative purposes only, Clearview’s purposes are entirely appropriate.” We are not convinced by Clearview’s arguments, which cite the same jurisprudence that we have relied on. We remain of the view, based on our analysis outlined above in paragraphs 73 to 78, that Clearview is collecting sensitive biometric personal information, for purposes that a reasonable person would not consider appropriate in the circumstances. Whereas law enforcement agencies rely on the broad collection authority for their operations found in public-sector privacy legislation, these actions are circumscribed by the Charter and Clearview enjoys no such collection authority as a private organization. Although some of the information collected may have ultimately been used for law enforcement, Clearview’s real purpose for the collection is a commercial for-profit enterprise and not law enforcement. Footnote 51 Finally, we note that Clearview emphasizes the absence of harms to individuals flowing from its activities. In taking this position, Clearview fails to acknowledge: (i) the myriad of instances where false, or misapplied matches could result in reputational damage to individuals, and (ii) more fundamentally, the affront to individuals’ privacy rights and broad-based harm inflicted on all members of society, who find themselves under continual mass surveillance by Clearview based on its indiscriminate scraping and processing of their facial images.\n\nAdditional concerns in relation to appropriate purposes\n\nWe note a number of additional issues. We will not specifically opine on them, but we continue to have significant concerns about them in the context of Clearview’s facial recognition practices.\n\nAccuracy\n\nWhile our Offices did not complete a technical assessment of the accuracy of Clearview’s facial recognition technology, we recognize a number of concerns related to facial recognition technology, generally. Our Offices accept that facial recognition technologies may be used to render many services to society and individuals, and have a number of legitimate uses in business and government. For example we recognize that facial recognition can assist businesses with identity authentication, or law enforcement agencies in the investigation of serious and complex crimes. However, while facial recognition technology, and Clearview’s technology in particular, may be effective in certain circumstances, we note that there are significant concerns regarding the efficacy and accuracy of facial recognition technologies, in particular with respect to certain demographics. Despite advances in the sophistication of facial recognition technology through the increase of computational capacity, the improvement of underlying algorithms and the availability of huge volumes of data, such technologies are not perfect and can result in misidentification. This can be the result of a variety of factors, including the quality of photos/videos and the performance of algorithms used to compare facial characteristics. In particular, our Offices take note of claims of accuracy concerns stemming from a variety of studies and investigations of facial recognition algorithms found in a number of technology solutions. Accuracy issues in facial recognition technology can take two general forms: (i) failure to identify an individual whose face is recorded in the reference database, referred to as a “false-negative”; or (ii) matching faces that actually belong to two different individuals, referred to as a “false positive.” While the former is an issue primarily for the users of facial recognition technology, the latter presents compelling risks of harm to individuals, particularly when facial recognition is used in the context of law enforcement. Footnote 52 In particular, we refer to reports that facial recognition technology has been found to have significantly higher incidences of false positives or misidentifications when assessing the faces of people of colour, and especially women of colour, which could result in discriminatory treatment for those individuals. Footnote 53 For example, research conducted by NIST (National Institute of Standards and Technology) found that the rate of false positives for Asian and Black individuals was often greater than that for Caucasians, by a factor of 10 to 100 times. Footnote 54 Harms resulting from such misidentification can range from individuals being excluded from opportunities, to individuals being investigated and detained based on incorrect information. Such harms would generally be classified as significant. Footnote 55 We note that Clearview commissioned an independent panel to complete an accuracy test of their technology, which it claimed was based on the methodology of a previous test conducted by the American Civil Liberties Union ( ACLU ). A copy of the results from this test was provided in Clearview’s representations, and reported a 100% accuracy rate for Clearview’s technology. During our investigation we found that significant concerns, regarding the testing methodology and conclusions, had been raised by a variety of researchers, including the ACLU ’s own team, who characterized the study as “misleading,” and lodged a complaint with Clearview. Footnote 56 In its submissions, Clearview argued that the ACLU and other critics had failed to demonstrate how the results of the test were misleading. It reiterated that in testing, Clearview’s App correctly matched all the images it searched for, with no inaccuracies. While our Office will not opine on the merits of such complaints, we do note the persistent theme of concerns raised in relation to the opacity of Clearview’s technology, which is proprietary and inaccessible to the majority of researchers, make it difficult to make determinations on accuracy.\n\nCollection in contravention of contractual terms\n\nWe note that Clearview has received cease-and-desist letters from Google, Facebook, Twitter, YouTube and LinkedIn regarding their practice of collecting information in violation of terms of service. Footnote 57 Clearview represented that it has responded to these cease-and-desist requests by asserting a First Amendment right to scrape “public” information under the U.S. Constitution. Clearview also asserted that contractual terms have no bearing on our investigation or the appropriateness of its purposes. While we do not opine on whether or not one or more contractual violations occurred, to the extent that Clearview scraped personal information in contravention of platforms’ contractual terms, it would in our view, be relevant as a further factor in considering the inappropriateness of Clearview’s purposes, in the circumstances.\n\nRisk of harm arising from breach\n\nThe large amount of sensitive biometric information held by Clearview would in our view, make it a high value target for malicious actors. Clearview argued that “risk of harm from breach is not an appropriate consideration when assessing the purposes of Clearview’s actions, as this would go well beyond the scope of the law, which is to establish rules that recognize the right of privacy of individuals,” claiming that this risk is present in “almost all areas of society.” It further argued that even if such risks were taken into account, there was no risk of significant harm or likelihood of the information being stolen. While we will not opine on Clearview’s safeguards, which are outside the scope of this investigation, we do note that Clearview publicly announced that it was breached on two occasions within the past year. Once in February 2020 when its client list was leaked, Footnote 58 and again in April 2020 when its source code and pilot project video were obtained and partially leaked. Footnote 59 In our view, Clearview’s collection and subsequent use of billions of images and facial arrays which are linked to source data, represents a significant risk to tens of millions of individuals in Canada should it be compromised.\n\nIssue 3: Did Clearview satisfy its biometric obligations in Quebec?\n\nWhen a company builds a biometrics system in Quebec, it must comply with the rules set out in Quebec’s Private Sector Act and the LCCJTI . Indeed, it must in particular: obtain the express consent of the person concerned, in line with s. 44 of the LCCJTI ; and disclose the creation or existence of the biometrics system to the CAI in line with s. 45 of the LCCJTI . It is apparent from the investigation that Clearview failed to obtain the express consent of the persons concerned, as Clearview has acknowledged that no attempt to seek consent was made. Furthermore, the company failed to disclose the existence of its biometrics system to the CAI .\n\nClearview’s response regarding Quebec’s biometric law\n\nClearview argues that it did not build a biometric system in Quebec, since its activities take place in the United States. Noting that a provincial statute cannot apply extraterritorially in the absence of the express or implied will of the legislature, Clearview concludes that the LCCJTI cannot apply to it, because that would give the law extraterritorial scope that no provision could confer on it, whether explicitly or implicitly. The CAI does not share Clearview’s opinion with respect to the LCCJTI . Indeed, since Clearview does not deny having built a biometric system, the CAI is of the opinion that, even if the biometric system is located outside of Quebec, Clearview has nevertheless collected images in the course of operating a business in Quebec and must therefore obtain the express consent of these individuals before verifying or confirming their identity. The essence of the LCCJTI provisions at issue are respect for the privacy of the individuals concerned and the protection of their personal information. The intention that this mandatory obligation be applied to all persons is made very clear in the French version by the use of the word “ nul ”. The extraterritorial effects are incidental. Clearview, by offering its services within the territorial boundaries of the province and collecting and using the personal information of Quebecers, is operating a business in Quebec. Accordingly, Clearview is subject to the applicable legislation in the jurisdiction in which it is carrying out its activities, namely, the province of Quebec. Footnote 60 Clearview’s physical location and the site of its principal activities are therefore incidental and do not shelter it from the application of the LCCJTI . Therefore, Clearview must obtain the express consent of individuals before verifying or confirming their identity ( s. 44 of the LCCJTI ), as noted in paragraph 40. The sensitivity of the information collected, used or disclosed and the impact that the use of this information may have on the privacy of the individuals concerned requires that they be informed and express their consent. A biometric system cannot be used without the knowledge of the individuals involved. Footnote 61 Clearview was also required to disclose its database of biometric characteristics and measurements to the Commission, in accordance with section 45 of the LCCJTI . Consequently, the CAI finds that Clearview contravened sections 44 and 45 of the LCCJTI .\n\nRecommendations\n\nIn our letter of intention, we shared with Clearview that we could order or recommend to: cease offering the facial recognition services that have been the subject of this investigation to clients in Canada; cease the collection, use and disclosure of images and biometric facial arrays collected from individuals in Canada; and delete images and biometric facial arrays collected from individuals in Canada in its possession. With respect to the first recommendation, we asked Clearview to confirm that it would not resume its offer to provide the facial recognition services in Canada in the future. We also sought Clearview’s commitments explaining how and when it would implement the second and third recommendations.\n\nClearview’s response to our conclusions\n\nAs detailed in this report, Clearview expressly disagreed with our conclusions. Despite this, noting that following engagement with our Offices, it had voluntarily withdrawn from the Canadian market earlier in the investigation, Clearview indicated that it was “prepared to consider maintaining this status for a further two years, in order to allow the various Commissioners to provide detailed and meaningful guidelines as to how Canadian law proposes to deal with artificial intelligence.” Clearview suggested that as it was not “currently active” in Canada, our Offices should suspend our investigation and refrain from issuing a report or making a final determination on this matter. Clearview indicated that “during such a suspension, [it] would be willing to take steps, on a best efforts and without prejudice basis, to try to limit the collection and distribution of the images that it is able to identify as Canadian…” As of the time of writing this report, Clearview had not committed to following our recommendations or orders under consideration, and the Offices deemed it appropriate to issue this report.\n\nConclusions",
            "url": "https://www.priv.gc.ca/en/opc-actions-and-decisions/investigations/investigations-into-businesses/2021/pipeda-2021-001/#toc6-3",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "personal",
                "pipeda",
                "findings",
                "clearview",
                "office",
                "facial",
                "law",
                "québec",
                "investigation",
                "joint",
                "information",
                "privacy",
                "linformation",
                "individuals",
                "consent",
                "images",
                "à",
                "footnote",
                "clearviews"
            ],
            "summary": "BackgroundThis report of investigation examines Clearview AI, Inc.’s (Clearview) compliance with Canada’s Personal Information Protection and Electronic Documents Act ( PIPEDA ), Quebec’s Act Respecting the Protection of Personal Information in the Private Sector (Quebec’s Private Sector Act), and Act to Establish a Legal Framework for Information Technology ( LCCJTI ), British Columbia’s Personal Information Protection Act ( PIPA BC ), and Alberta’s Personal Information Protection Act ( PIPA AB ) – referred to collectively as the Acts.\nWe further note that the additional contextual information provided via source links (that is, social media and websites) can include significant personal information of varying levels of sensitivity.\nFurther, Clearview’s collection of information includes the mass indiscriminate collection of the personal information of minors, which would be considered particularly sensitive.\nWe will not specifically opine on them, but we continue to have significant concerns about them in the context of Clearview’s facial recognition practices.\nThe essence of the LCCJTI provisions at issue are respect for the privacy of the individuals concerned and the protection of their personal information.",
            "metadata": {
                "source_domain": "www.priv.gc.ca",
                "scrape_date": "2024-10-25T12:40:28.133679",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 63449
            }
        },
        {
            "title": "Facial Recognition Lawsuit – Clearview AI",
            "text": "Facial Recognition Lawsuit – Clearview AI\n\nDate: July 20, 2020\n\nClassification: Unclassified\n\nBranch/Agency: RCMP\n\nIssue:\n\nA class-action lawsuit has been proposed relating to the RCMP’s use of Clearview AI’s facial recognition technology.\n\nProposed Response:\n\nWe are aware that a proposed class-action lawsuit was filed with the Federal Court of Canada relating to the RCMP’s use of Clearview AI’s facial recognition technology.\n\nThe claim is currently being reviewed and I cannot comment on it at this time.\n\nWe are committed to keeping Canadians safe and protecting their privacy rights.\n\nThe Privacy Commissioner is reviewing the use of facial recognition technology, and is also investigating the RCMP’s use of Clearview AI. The RCMP is fully cooperating with the investigation and we look forward to reviewing the Privacy Commissioner's reports.\n\nBackground:\n\nOn July 8, 2020, a proposed class action was filed with the Federal Court of Canada alleging that Clearview AI collects, copies, stores, discloses and sells facial photos of Canadian residents without their knowledge or consent by using an algorithm to detect the unique face print of an individual. The plaintiff alleges that this is a violation of privacy rights, constitutional rights and their copyright and moral rights as the authors and holders of these rights have not consented to their reproduction and use by Clearview. Furthermore, the plaintiff has alleged that by becoming a customer and client, the RCMP obtained access to and used an illicit database, thus violating the rights of residents and citizens of Canada\n\nAs part of this proposed class action, the plaintiff is seeking:\n\nAn order certifying the class action;\n\nA declaration that the RCMP engaged liability and violated rights of class members by becoming a client of Clearview and accessing the database;\n\nA declaration that the RCMP engaged liability and violated the Targeted Individual Class Members by running related searches in the Clearview database;\n\nA declaration that the RCMP cannot engage with Clearview and use its services or similar services of other providers;\n\nAn order enjoining the RCMP to remit to the Targeted Individual Class Members all documents and information obtained from Clearview with respect to them, and destroy all copies of such documents and information; and\n\nGeneral pecuniary and non-pecuniary, special, punitive and or statutory damages for negligence, willfully obtaining access to an illicit database, privacy breaches, copyright infringement and moral rights violations.\n\nLastly, the proposed class members are:\n\nAll natural persons, who are either residents or citizens of Canada, whose faces appear in the photographs collected by Clearview (the “Collected Photographs”) (the “Privacy Breach Class” or the “Privacy Breach Class Members”);\n\nAll natural persons whose photographs had been used by the RCMP for the purpose of using Clearview’s services (the “Targeted Individuals Class” or the “Targeted Individuals Class Members); and\n\nAll natural or legal persons holding copyright and moral rights with respect to the Collected Photographs (the “Copyright Infringement Class” or the “Copyright Infringement Class Members” and, collectively with the Privacy Breach Class and the Targeted Individuals Class, the “Class” or “Class Members”).\n\nClearview AI provides access to a repository of images and any associated metadata that has been collected from publically available websites to facilitate image comparison. Privacy concerns have centered around the legality of law enforcement’s use of biometric technologies, including facial recognition, particularly around how the information is collected, used, disclosed, and retained. As a result, on February 21, 2020, the Office of the Privacy Commissioner (OPC), announced an investigation, with its counterparts in Quebec, British Columbia and Alberta, into whether Clearview AI and its use of facial recognition technology complies with Canadian privacy legislation.\n\nOn February 27, 2020, the RCMP acknowledged in a public statement that it had recently started to use and explore Clearview AI’s facial recognition technology in a limited capacity, in particular by the National Child Exploitation Crime Centre (NCECC). The RCMP’s NCECC had two paid licenses for the Clearview AI application and been using the technology since October 24, 2019. NCECC use has been limited to victim identification for investigations of online child sexual exploitation. To date, this technology has been used in 15 online child sexual exploitation cases, resulting in the successful identification and rescue of two children.\n\nOn February 28, 2020, the OPC announced that it would investigate the RCMP’s use of Clearview AI’s facial recognition technology. Since that time, the RCMP has been engaged by the OPC and is actively supporting its ongoing investigation into the RCMP’s use of Clearview AI. As part of this investigation, the RCMP has committed to working with the OPC to develop guidelines and policies on the future use of automated facial recognition technologies. On July 6, 2020, Clearview AI announced that they would cease to offer access to its facial recognition technology tool in Canada and has since suspended RCMP access to this technology.\n\nContacts:\n\nPrepared by: Kees Bradley, Manager, Cybercrime and Information Sharing Policy, 343-540-5959\n\nApproved by: Stephen White, Deputy Commissioner, Specialized Policing Services 613-843-4631",
            "url": "https://www.publicsafety.gc.ca/cnt/trnsprnc/brfng-mtrls/prlmntry-bndrs/20201119/023/index-en.aspx",
            "authors": [],
            "publish_date": "2020-11-19T02:00:00",
            "keywords": [
                "rcmps",
                "privacy",
                "recognition",
                "technology",
                "lawsuit",
                "rights",
                "ai",
                "rcmp",
                "clearview",
                "class",
                "facial"
            ],
            "summary": "Facial Recognition Lawsuit – Clearview AIDate: July 20, 2020Classification: UnclassifiedBranch/Agency: RCMPIssue:A class-action lawsuit has been proposed relating to the RCMP’s use of Clearview AI’s facial recognition technology.\nProposed Response:We are aware that a proposed class-action lawsuit was filed with the Federal Court of Canada relating to the RCMP’s use of Clearview AI’s facial recognition technology.\nThe Privacy Commissioner is reviewing the use of facial recognition technology, and is also investigating the RCMP’s use of Clearview AI.\nOn February 28, 2020, the OPC announced that it would investigate the RCMP’s use of Clearview AI’s facial recognition technology.\nOn July 6, 2020, Clearview AI announced that they would cease to offer access to its facial recognition technology tool in Canada and has since suspended RCMP access to this technology.",
            "metadata": {
                "source_domain": "www.publicsafety.gc.ca",
                "scrape_date": "2024-10-25T12:40:28.344053",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 5482
            }
        },
        {
            "title": "Netherlands: Face-Recognition Company Clearview AI Fined for Violating EU’s General Data Protection Regulation",
            "text": "On May 16, 2024, the Dutch Data Protection Authority (DPA) (Autoriteit Persoonsgegevens, AP) fined Clearview AI Inc. 30.5 million euros (approximately US$33.5 million) for violating the European Union’s (EU’s) General Data Protection Regulation (GDPR), in particular by processing personal, biometric data without a proper legal basis. The DPA also issued four enforcement orders that effectively require the company to cease its current operations within the EU.\n\nClearview, a New York-based firm, provides artificial intelligence (AI)-powered facial recognition technology built on a vast database of images collected from individuals around the world.\n\nBackground and Applicable Law\n\nThe GDPR, which came into effect on May 25, 2018, applies directly in all EU member states and regulates the processing of personal data. It requires data controllers to adhere to key principles, including establishing a legitimate legal basis for processing personal data. (GDPR, Arts. 5, 6.) “Data processing” encompasses any action taken on personal data, such as collection, recording, structuring, and storage. (Art. 4, para. 2.) The GDPR applies even if the data controller is based outside the EU as long as personal data of individuals within the EU is being processed, especially when the processing includes monitoring their behavior within the EU. (Art. 3, para. 2.)\n\nUnder the GDPR, personal data must be processed lawfully. One possible legal basis is demonstrating a legitimate interest in processing the data. However, such interests may be overridden by the interests or fundamental rights and freedoms of the data subject. (Art. 6, para. 1(f).) The Dutch DPA, as the competent national supervisory body, is empowered to impose administrative fines and orders against data controllers when GDPR violations are identified. (Art. 58, paras. 1, 2.)\n\nClearview’s Business Model\n\nClearview offers services that use facial recognition technology, meaning an algorithm capable of precisely analyzing facial features in an image, enabling it to recognize the same individual across other images. (DPA Decision, Para. 6.) The company employs an advanced algorithm based on machine learning, which converts a face into a unique code, known as an “embedding” or “vector.” By comparing these vectors, the algorithm can identify and match other images featuring the same individual. (Para. 7.) Clearview has compiled a database of more than 30 billion photos from publicly accessible sources such as social media, websites, news, mugshots, and U.S. public databases on convicted individuals. (Para. 8.) Each photo in the database is associated with corresponding metadata which supports the identification of the person depicted. (Para. 11.) One of the key services offered by Clearview is the “Clearview for law-enforcement and public defenders” service. Once the User provides a “probe image” of the subject, the system matches the image to its database and helps the user to identify the subject. (Paras. 13-19.)\n\nDecision\n\nThe DPA concluded that Clearview, through its “Clearview for law-enforcement and public defenders” service, processes personal data of individuals within the Netherlands without a legal basis. The processed data includes biometric data — a category specially protected under the GDPR. (Art. 9, para. 1.) The Dutch DPA emphasized that the processing of personal data is not incidental to Clearview’s service but central to its operation. Clearview systematically processes large-scale personal data for facial recognition, but its business interests do not qualify as legitimate interest for data processing under the GDPR. (Art. 6, para. 1 (f).). (Para. 91.)\n\nThe DPA identified three additional violations: failure to meet transparency obligations (art. 12, paras. 1, 14), failure to respond to two access requests (art. 12, paras. 3, 15), and failure to facilitate the exercise of access rights (art. 12, paras. 2, 15). Assessing the severity of these violations, the DPA highlighted the impact on a significant number of data subjects in the Netherlands, including minors, who are entitled to heightened protection. (Para. 201.) It considered it particularly serious that Clearview obstructed individuals from exercising their access rights and failed to provide all required information under article 14 of the GDPR.\n\nFurthermore, the DPA expressed concern that Clearview knowingly continued its conduct despite sanctions imposed by other EU supervisory authorities, indicating deliberate intent behind the violations. (Para. 205.) At the time of the decision, Clearview had not ceased the unlawful processing activities, prompting the DPA to issue four compliance orders, each subject to penalties, aimed at halting the identified violations. (Paras. 223-236.)\n\nRelated Developments\n\nIn Germany, the governing parties in parliament have proposed a new law that stands in contrast to the decision of the Dutch DPA. Following the successful conclusion of a decades long search for a domestic terrorist, which was initiated by a group of journalists using an AI tool similar to Clearview’s, the proposed law would allow the German federal police to access public databases similar to the one created by Clearview. (Art. 1 of the Draft Law to Improve the Fight Against Terrorism.) This proposal has faced criticism from legal scholars, who argue that the combination of mass data collection, data evaluation, database merging, and the use of AI constitutes a breach of both the German Constitution and EU law.\n\nPrepared by Maximilian Spitzley, Law Library Intern, under the supervision of Jenny Gesley, Foreign Law Specialist\n\nLaw Library of Congress, October 17, 2024\n\nRead more Global Legal Monitor articles.",
            "url": "https://www.loc.gov/item/global-legal-monitor/2024-10-16/netherlands-face-recognition-company-clearview-ai-fined-for-violating-eus-general-data-protection-regulation/",
            "authors": [],
            "publish_date": "2024-10-16T00:00:00",
            "keywords": [
                "para",
                "company",
                "personal",
                "fined",
                "art",
                "clearview",
                "facerecognition",
                "general",
                "eus",
                "gdpr",
                "protection",
                "dpa",
                "legal",
                "netherlands",
                "data",
                "violating",
                "regulation",
                "paras",
                "processing"
            ],
            "summary": "On May 16, 2024, the Dutch Data Protection Authority (DPA) (Autoriteit Persoonsgegevens, AP) fined Clearview AI Inc. 30.5 million euros (approximately US$33.5 million) for violating the European Union’s (EU’s) General Data Protection Regulation (GDPR), in particular by processing personal, biometric data without a proper legal basis.\nIt requires data controllers to adhere to key principles, including establishing a legitimate legal basis for processing personal data.\n“Data processing” encompasses any action taken on personal data, such as collection, recording, structuring, and storage.\nUnder the GDPR, personal data must be processed lawfully.\nClearview systematically processes large-scale personal data for facial recognition, but its business interests do not qualify as legitimate interest for data processing under the GDPR.",
            "metadata": {
                "source_domain": "www.loc.gov",
                "scrape_date": "2024-10-25T12:40:36.766152",
                "content_type": "official_statements",
                "extraction_method": "newspaper3k",
                "content_length": 5728
            }
        }
    ]
}