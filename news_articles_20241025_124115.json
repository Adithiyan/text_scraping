{
    "total_articles": 43,
    "articles": [
        {
            "title": "Privacy regulator drops pursuit of Clearview AI as Greens call for more scrutiny on use of Australians’ images",
            "text": "The Australian privacy regulator has ended its pursuit of Clearview AI over use of the images of Australians’ faces in its facial recognition service, despite no sign from the company it has complied with a ruling ordering the images to be deleted, and calls from the Greens for “further investigation”.\n\nClearview AI is a facial recognition service that has been used by law enforcement across the globe, including in limited trials in Australia. It claims to have a database of over 50bn faces scraped from the internet, including social media.\n\nIn 2021, the office of the Australian information commissioner found Clearview AI had breached Australians’ privacy through the collection of these images without consent, and ordered the company to cease collecting the images and delete the ones on record within 90 days. Clearview initially appealed against the decision to the administrative appeals tribunal, but ceased its appeal in August last year before the AAT could make a ruling, meaning the original decision stands.\n\nThere is no indication as to whether Clearview has since complied with the order and the company did not respond to a request for comment.\n\nOn Wednesday, a year after Clearview ceased its appeal, the privacy commissioner, Carly Kind, announced that the OAIC would not continue to pursue Clearview to enforce the order.\n\n“I have given extensive consideration to the question of whether the OAIC should invest further resources in scrutinising the actions of Clearview AI, a company that has already been investigated by the OAIC and which has found itself the subject of regulatory investigations in at least three jurisdictions around the world as well as a class action in the United States,” she said.\n\n“Considering all the relevant factors, I am not satisfied that further action is warranted in the particular case of Clearview AI at this time.”\n\nIn June, Clearview AI agreed to resolve a class action suit brought against the company over the alleged privacy violation of Americans included in the system for an undisclosed amount with no admission of wrongdoing. The settlement has yet to be approved by the court.\n\nA 2022 settlement with the American Civil Liberties Union (ACLU) also restricted Clearview AI from selling its database to most businesses in the United States and all entities including law enforcement in Illinois for five years.\n\nKind said on Wednesday Clearview’s practices were increasingly common and troublesome in the years since as part of the drive towards generative artificial intelligence models.\n\nGreens senator and digital rights spokesperson David Shoebridge said there were still clear questions about the impact of Clearview AI on privacy.\n\n“The suspicion that Clearview AI has continued to scrape individuals’ photos absolutely warrants further investigation and it is heartening that the OAIC is confirming that they have heard these community concerns,” he said.\n\n“If AI is being used by Clearview to potentially supercharge the harm being done here then the public deserves to know as soon as possible.”\n\nThe OAIC and 11 other regulators issued a statement in August last year calling on publicly available sites to take reasonable steps to protect personal information on their sites being scraped unlawfully.\n\nKind said all regulated entities in Australia that use AI to collect, use or disclose personal information were required to comply with the Privacy Act.\n\n“The OAIC will soon be issuing guidance for entities seeking to develop and train generative AI models, including how the APPs (Australian privacy principles) apply to the collection and use of personal information. We will also issue guidance for entities using commercially available AI products, including chatbots.”\n\nCorrespondence between Clearview AI and the OAIC as part of the failed AAT appeal from a freedom of information request last year reveals Clearview had been of the view it was not subject to the Australian jurisdiction given it had decided not to do business in Australia, and had blocked its web crawler from obtaining images from servers based in Australia.\n\nAustralian and UK users had been able to opt-out of the system, but when the company began re-scraping the internet in January last year it took no steps to reassure users that the faces scraped did not include Australians who had their images on servers located outside Australia, such as those used by social media sites like Facebook.",
            "url": "https://www.theguardian.com/technology/article/2024/aug/21/privacy-regulator-drops-pursuit-of-clearview-ai-over-use-of-australians-images-in-facial-recognition-tech-ntwnfb",
            "authors": [
                "Josh Taylor"
            ],
            "publish_date": "2024-08-21T00:00:00",
            "keywords": [
                "entities",
                "oaic",
                "company",
                "including",
                "australian",
                "scrutiny",
                "drops",
                "greens",
                "australians",
                "pursuit",
                "information",
                "privacy",
                "clearview",
                "images",
                "regulator",
                "ai"
            ],
            "summary": "The Australian privacy regulator has ended its pursuit of Clearview AI over use of the images of Australians’ faces in its facial recognition service, despite no sign from the company it has complied with a ruling ordering the images to be deleted, and calls from the Greens for “further investigation”.\nClearview AI is a facial recognition service that has been used by law enforcement across the globe, including in limited trials in Australia.\nIn 2021, the office of the Australian information commissioner found Clearview AI had breached Australians’ privacy through the collection of these images without consent, and ordered the company to cease collecting the images and delete the ones on record within 90 days.\nA 2022 settlement with the American Civil Liberties Union (ACLU) also restricted Clearview AI from selling its database to most businesses in the United States and all entities including law enforcement in Illinois for five years.\nGreens senator and digital rights spokesperson David Shoebridge said there were still clear questions about the impact of Clearview AI on privacy.",
            "metadata": {
                "source_domain": "www.theguardian.com",
                "scrape_date": "2024-10-25T12:40:00.451641",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 4456
            }
        },
        {
            "title": "Clearview AI faces $45.6M fine in the Netherlands for 'illegal database' of faces",
            "text": "The Dutch data protection watchdog on Tuesday issued facial recognition startup Clearview AI with a fine of 30.5 million euros ($45.6 million Cdn) over its creation of what the agency called an \"illegal database\" of billions of photos of faces.\n\nThe Netherlands' Data Protection Agency, or DPA, also warned Dutch companies that using Clearview's services is also banned.\n\nThe data agency said that New York-based Clearview \"has not objected to this decision and is therefore unable to appeal against the fine.\"\n\nBut in a statement emailed to The Associated Press, Clearview's chief legal officer, Jack Mulcaire, said that the decision is \"unlawful, devoid of due process and is unenforceable.\"\n\nAs part of the decision, Dutch companies are also banned from using Clearview AI, according to the Netherlands' Data Protection Agency. (Ascannio/Shutterstock)\n\nThe Dutch agency said that building the database and insufficiently informing people whose images appear in the database amounted to serious breaches of the European Union's General Data Protection Regulation, or GDPR.\n\n\"Facial recognition is a highly intrusive technology, that you cannot simply unleash on anyone in the world,\" DPA chairman Aleid Wolfsen said in a statement.\n\n\"If there is a photo of you on the Internet — and doesn't that apply to all of us? — then you can end up in the database of Clearview and be tracked. This is not a doom scenario from a scary film. Nor is it something that could only be done in China,\" he said.\n\nDPA said that if Clearview doesn't halt the breaches of the regulation, it faces noncompliance penalties of up to 5.1 million euros ($5.6 million Cdn) on top of the fine.\n\nClearview AI says company not subject to EU regulations\n\nMulcaire said in his statement that Clearview doesn't fall under EU data protection regulations.\n\n\"Clearview AI does not have a place of business in the Netherlands or the EU, it does not have any customers in the Netherlands or the EU, and does not undertake any activities that would otherwise mean it is subject to the GDPR,\" he said.\n\nAnyone could end up on Clearview AI's database and be tracked if a photo of them exists anywhere on the internet, the watchdog warns. (Chris Wattie/Reuters)\n\nIn June, Clearview reached a settlement in an Illinois lawsuit alleging its massive photographic collection of faces violated the subjects' privacy rights, a deal that attorneys estimate could be worth more than $50 million US. Clearview didn't admit any liability as part of the settlement agreement.\n\nThe case in Illinois consolidated lawsuits from around the U.S. filed against Clearview, which pulled photos from social media and elsewhere on the internet to create a database that it sold to businesses, individuals and government entities.",
            "url": "https://www.cbc.ca/news/business/clearview-ai-netherlands-1.7311631",
            "authors": [
                "The Associated Press"
            ],
            "publish_date": null,
            "keywords": [
                "protection",
                "fine",
                "faces",
                "agency",
                "illegal",
                "456m",
                "eu",
                "netherlands",
                "data",
                "dutch",
                "ai",
                "million",
                "clearview",
                "database"
            ],
            "summary": "The Dutch data protection watchdog on Tuesday issued facial recognition startup Clearview AI with a fine of 30.5 million euros ($45.6 million Cdn) over its creation of what the agency called an \"illegal database\" of billions of photos of faces.\nThe Netherlands' Data Protection Agency, or DPA, also warned Dutch companies that using Clearview's services is also banned.\nThe data agency said that New York-based Clearview \"has not objected to this decision and is therefore unable to appeal against the fine.\"\nAs part of the decision, Dutch companies are also banned from using Clearview AI, according to the Netherlands' Data Protection Agency.\nClearview AI says company not subject to EU regulationsMulcaire said in his statement that Clearview doesn't fall under EU data protection regulations.",
            "metadata": {
                "source_domain": "www.cbc.ca",
                "scrape_date": "2024-10-25T12:40:00.460147",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 2768
            }
        },
        {
            "title": "Information and Privacy Commissioner of Ontario Statement on Toronto Police Service Use of Clearview AI Technology",
            "text": "The indiscriminate scraping of the internet to collect images of people’s faces for law enforcement purposes has significant privacy implications for all Ontarians. We have made it clear in the past that my office should be consulted before this type of technology is used.\n\nWe were not aware that the Toronto Police Service was using Clearview AI technology until contacted by them on February 5. We are relieved that its use has been halted.\n\nThere are vital privacy issues at stake with the use of any facial recognition technology. My office will be consulting with the Toronto Police Service shortly and re-examining their use of facial recognition technology and the appropriateness of using Clearview AI. We question whether there are any circumstances where it would be acceptable to use Clearview AI.\n\nWe continue to strongly encourage organizations to contact us if they are considering using new technologies that could pose a potential privacy risk to citizens. The use of this technology is of great concern.\n\nWe’ve learned through recent media reports that other police services may also be using Clearview AI. They should stop this practice immediately and contact my office. I’ve also asked my staff to contact those we’ve become aware of through the media to discuss the legality and privacy implications of their use of this technology.\n\n— Brian Beamish, Information and Privacy Commissioner of Ontario",
            "url": "https://www.ipc.on.ca/en/media-centre/blog/information-and-privacy-commissioner-ontario-statement-toronto-police-service-use-clearview-ai",
            "authors": [],
            "publish_date": "2020-02-14T16:57:12-05:00",
            "keywords": [
                "using",
                "recognition",
                "toronto",
                "statement",
                "commissioner",
                "information",
                "ai",
                "ontario",
                "privacy",
                "contact",
                "service",
                "clearview",
                "office",
                "technology"
            ],
            "summary": "We were not aware that the Toronto Police Service was using Clearview AI technology until contacted by them on February 5.\nThere are vital privacy issues at stake with the use of any facial recognition technology.\nMy office will be consulting with the Toronto Police Service shortly and re-examining their use of facial recognition technology and the appropriateness of using Clearview AI.\nWe question whether there are any circumstances where it would be acceptable to use Clearview AI.\nWe’ve learned through recent media reports that other police services may also be using Clearview AI.",
            "metadata": {
                "source_domain": "www.ipc.on.ca",
                "scrape_date": "2024-10-25T12:40:00.475779",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 1420
            }
        },
        {
            "title": "Clearview AI fined by Dutch authorities for ‘illegal’ facial recognition database",
            "text": "It’s not the first time the US facial recognition company has been fined in Europe.\n\nADVERTISEMENT\n\nDutch authorities fined US facial recognition company Clearview AI €30.5 million for building an illegal database, the watchdog said on Tuesday.\n\nThe Dutch Data Protection Authority (Dutch DPA) also issued the company a penalty of up to €5 million for non-compliance.\n\nEuronews Next has reached out to Clearview AI but did not receive a reply at the time of publication.\n\nThe DPA said in a statement that “Clearview should never have built the database with photos, the unique biometric codes and other information linked to them”.\n\nFacial recognition technology is used to query the search engine and find an individual based on their photograph.\n\n“Facial recognition is a highly intrusive technology, that you cannot simply unleash on anyone in the world,” said Dutch DPA chairman Aleid Wolfsen, warning the public against using Clearview.\n\n“Clearview breaks the law, and this makes using the services of Clearview illegal. Dutch organisations that use Clearview may therefore expect hefty fines from the Dutch DPA,” he added.\n\nClearview does not have an office in Europe. It has been fined by other European regulators such as France’s CNIL, the body responsible for issuing sanctions.\n\nIn October 2022, France imposed a €20 million fine on Clearview and ordered the company not to collect and process data on individuals located in France without any legal basis and to delete the data of these individuals.\n\nThe European Data Protection Board (EDPB) said in 2023 that Clearview had not sent any proof of compliance within the two-month request.",
            "url": "https://www.euronews.com/next/2024/09/03/clearview-ai-fined-by-dutch-authorities-for-illegal-facial-recognition-database",
            "authors": [
                "Pascale Davies"
            ],
            "publish_date": "2024-09-03T00:00:00",
            "keywords": [
                "database",
                "recognition",
                "using",
                "illegal",
                "authorities",
                "dpa",
                "company",
                "technology",
                "fined",
                "dutch",
                "data",
                "ai",
                "million",
                "clearview",
                "facial"
            ],
            "summary": "It’s not the first time the US facial recognition company has been fined in Europe.\nADVERTISEMENTDutch authorities fined US facial recognition company Clearview AI €30.5 million for building an illegal database, the watchdog said on Tuesday.\nThe Dutch Data Protection Authority (Dutch DPA) also issued the company a penalty of up to €5 million for non-compliance.\nFacial recognition technology is used to query the search engine and find an individual based on their photograph.\nDutch organisations that use Clearview may therefore expect hefty fines from the Dutch DPA,” he added.",
            "metadata": {
                "source_domain": "www.euronews.com",
                "scrape_date": "2024-10-25T12:40:00.491404",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 1649
            }
        },
        {
            "title": "Clearview AI Opt Out Guide",
            "text": "To opt out of Clearview AI, follow our Clearview AI opt-out guide.\n\nClearview AI is a facial recognition platform. Basically, it’s a search engine of publicly available images (of which it now has more than 40 billion, according to its site).\n\nWhen Clearview AI users (currently only government agencies) upload an image, they get links to publicly available photos that match (or are similar to) the person in the image they uploaded.\n\nUse our step-by-step guide below to opt out of Clearview AI.\n\nDeleteMe’s Clearview AI Opt Out Review\n\nTo opt out of Clearview AI, you must complete an online form, upload a photo of your face, and click on a confirmation link in your email. Your request should be processed after a waiting period.\n\nSpeed: 2 Difficulty: 4\n\nClearview AI Listing Removal Walkthrough\n\nOpt out of Clearview in four steps.\n\nGo to https://www.clearview.ai/ and scroll to the bottom of the page.\n\nClick “Privacy & Requests” in the footer (under ‘Legal’).\n\n2. Under the state you live in, click “Delete”\n\nClearview AI allows you to opt out of their database if you are a California, Colorado, Connecticut, Illinois, Utah, or Virginia resident.\n\nUnder the state you are a resident of, click the privacy right you want to exercise (Access, Delete, Do Not Sell/Share, Correct, or Limit Use/Disc. Of Sens. Info).\n\n3. Fill out the form and click “Submit”\n\nYou will be redirected to an online privacy form. Fill it out.\n\nFirst, affirm that you’re a resident of the state you chose or are authorized to request opt-out on behalf of someone else in the state.\n\nNext, select the right you want to exercise (Access My Information, Delete My Information, Do Not Sell/Share My Information, Correct My Information, or Limit Use and Disclosure of Sensitive Personal Information). You can select multiple rights.\n\nThen, enter your email address. Clearview AI will send you a confirmation email when your request is completed.\n\nFinally, upload a photo of your face.\n\nClick “I acknowledge.”\n\nClick the “I’m not a robot” checkbox.\n\nClick “Submit.”\n\n4. Click the email confirmation link\n\nTo verify your request, Clearview AI will send you a confirmation link to your email address.\n\nGo to your inbox, find the email from Clearview AI, and click the “Confirm email” button.\n\nNote: If you don’t see the email from Clearview AI, check your spam folder.\n\nYour Clearview AI opt-out request is in progress.\n\nYou can contact Clearview AI by email at privacy@clearview.ai or by leaving a voicemail at (866) 637-0257.\n\nClearview AI asks that you do not email them with privacy requests but rather complete the appropriate online form available here: https://www.clearview.ai/privacy-and-requests/\n\nWho Is Selling Your Info?\n\nData brokers! These companies collect your personal information from various sources (public records, social media, etc.), compile this information into detailed profiles, and sell these profiles to anyone who wants them.\n\nLearn more about data brokers and people search sites in our detailed data broker guide.\n\nThen, take a look at our data broker opt-out guide to see which data brokers and people search sites you should opt-out from, including:\n\nAlternatively, consider subscribing to a data broker removal service like DeleteMe. Our privacy experts will delete you from data brokers continuously on your behalf, saving you hundreds of hours in the process.\n\nClearview AI Opt Out FAQs\n\nHere are some common questions that people have about Clearview AI.\n\nWhat is Clearview AI?\n\nClearview AI is a facial recognition company.\n\nIt provides law enforcement and government agencies with a platform that acts as a face search engine. Users can upload a photo, and the system will try to find a match in its database. It then links to where those matches appear online.\n\nTo create its database of billions of photos, Clearview AI scraped millions of websites, including social media platforms.\n\nCan anyone use Clearview AI?\n\nNo. Currently, only government agencies and their agents can use Clearview AI.\n\nDoes Clearview AI have my photo?\n\nProbably. If your photos appear online, then it is very likely that Clearview AI has you in their database.\n\nThe good news is that you can opt out of Clearview AI. To do so, you need to complete an opt-out form on Clearview AI’s website and upload an image of your face. You can read our full guide to learn how to opt out of Clearview AI.",
            "url": "https://joindeleteme.com/blog/clearview-ai-opt-out-guide/#:~:text=The%20good%20news%20is%20that,an%20image%20of%20your%20face.",
            "authors": [],
            "publish_date": "2024-08-16T11:39:08-04:00",
            "keywords": [
                "email",
                "request",
                "opt",
                "guide",
                "information",
                "data",
                "click",
                "ai",
                "optout",
                "clearview",
                "upload"
            ],
            "summary": "To opt out of Clearview AI, follow our Clearview AI opt-out guide.\nUse our step-by-step guide below to opt out of Clearview AI.\nDeleteMe’s Clearview AI Opt Out ReviewTo opt out of Clearview AI, you must complete an online form, upload a photo of your face, and click on a confirmation link in your email.\nClearview AI Opt Out FAQsHere are some common questions that people have about Clearview AI.\nYou can read our full guide to learn how to opt out of Clearview AI.",
            "metadata": {
                "source_domain": "joindeleteme.com",
                "scrape_date": "2024-10-25T12:40:00.509585",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 4385
            }
        },
        {
            "title": "Clearview AI fined US$33.7M over 'illegal database' of faces",
            "text": "THE HAGUE, Netherlands -\n\nThe Dutch data protection watchdog on Tuesday issued facial recognition startup Clearview AI with a fine of 30.5 million euros (US$33.7 million) over its creation of what the agency called an \"illegal database\" of billion of photos of faces.\n\nThe Netherlands' Data Protection Agency, or DPA, also warned Dutch companies that using Clearview's services is also banned.\n\nThe data agency said that New York-based Clearview \"has not objected to this decision and is therefore unable to appeal against the fine.\"\n\nBut in a statement emailed to The Associated Press, Clearview's chief legal officer, Jack Mulcaire, said that the decision is \"unlawful, devoid of due process and is unenforceable.\"\n\nThe Dutch agency said that building the database and insufficiently informing people whose images appear in the database amounted to serious breaches of the European Union's General Data Protection Regulation, or GDPR.\n\n\"Facial recognition is a highly intrusive technology, that you cannot simply unleash on anyone in the world,\" DPA chairman Aleid Wolfsen said in a statement.\n\n\"If there is a photo of you on the Internet -- and doesn't that apply to all of us? -- then you can end up in the database of Clearview and be tracked. This is not a doom scenario from a scary film. Nor is it something that could only be done in China,\" he said.\n\nDPA said that if Clearview doesn't halt the breaches of the regulation, it faces noncompliance penalties of up to 5.1 million euros (US$5.6 million) on top of the fine.\n\nMulcaire said in his statement that Clearview doesn't fall under EU data protection regulations.\n\n\"Clearview AI does not have a place of business in the Netherlands or the EU, it does not have any customers in the Netherlands or the EU, and does not undertake any activities that would otherwise mean it is subject to the GDPR,\" he said.\n\nIn June, Clearview reached a settlement in an Illinois lawsuit alleging its massive photographic collection of faces violated the subjects' privacy rights, a deal that attorneys estimate could be worth more than US$50 million. Clearview didn't admit any liability as part of the settlement agreement.\n\nThe case in Illinois consolidated lawsuits from around the U.S. filed against Clearview, which pulled photos from social media and elsewhere on the internet to create a database that it sold to businesses, individuals and government entities.",
            "url": "https://www.ctvnews.ca/sci-tech/clearview-ai-fined-us-33-7-million-by-dutch-data-protection-watchdog-over-illegal-database-of-faces-1.7023151",
            "authors": [],
            "publish_date": "2024-09-03T07:51:00-04:00",
            "keywords": [
                "protection",
                "faces",
                "us337m",
                "agency",
                "illegal",
                "eu",
                "fined",
                "netherlands",
                "data",
                "dutch",
                "ai",
                "million",
                "clearview",
                "doesnt",
                "database"
            ],
            "summary": "THE HAGUE, Netherlands -The Dutch data protection watchdog on Tuesday issued facial recognition startup Clearview AI with a fine of 30.5 million euros (US$33.7 million) over its creation of what the agency called an \"illegal database\" of billion of photos of faces.\nThe Netherlands' Data Protection Agency, or DPA, also warned Dutch companies that using Clearview's services is also banned.\nThe data agency said that New York-based Clearview \"has not objected to this decision and is therefore unable to appeal against the fine.\"\nDPA said that if Clearview doesn't halt the breaches of the regulation, it faces noncompliance penalties of up to 5.1 million euros (US$5.6 million) on top of the fine.\nMulcaire said in his statement that Clearview doesn't fall under EU data protection regulations.",
            "metadata": {
                "source_domain": "www.ctvnews.ca",
                "scrape_date": "2024-10-25T12:40:00.684170",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 2414
            }
        },
        {
            "title": "CEO speaks out about Clearview AI's controversial facial recognition technology",
            "text": "Clearview AI facial recognition software aims to match people's faces with billions of images scraped off social media and shares them with clients like police agencies. CBS News correspondent Errol Barnett joined CBSN AM with more on the CEO's first network TV interview.\n\nSubscribe to the CBS News Channel HERE: http://youtube.com/cbsnews\n\nWatch CBSN live HERE: http://cbsn.ws/1PlLpZ7\n\nFollow CBS News on Instagram HERE: https://www.instagram.com/cbsnews/\n\nLike CBS News on Facebook HERE: http://facebook.com/cbsnews\n\nFollow CBS News on Twitter HERE: http://twitter.com/cbsnews\n\nGet the latest news and best in original reporting from CBS News delivered to your inbox. Subscribe to newsletters HERE: http://cbsn.ws/1RqHw7T\n\nGet your news on the go! Download CBS News mobile apps HERE: http://cbsn.ws/1Xb1WC8\n\nGet new episodes of shows you love across devices the next day, stream CBSN and local news live, and watch full seasons of CBS fan favorites like Star Trek Discovery anytime, anywhere with CBS All Access. Try it free! http://bit.ly/1OQA29B\n\n---\n\nCBSN is the first digital streaming news network that will allow Internet-connected consumers to watch live, anchored news coverage on their connected TV and other devices. At launch, the network is available 24/7 and makes all of the resources of CBS News available directly on digital platforms with live, anchored coverage 15 hours each weekday. CBSN. Always On.",
            "url": "https://www.clearview.ai/as-seen-on-tv/cbs-news-controversial-ai-facial-recognition-hoan-ton-that-",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "cbsn",
                "coverage",
                "technology",
                "facial",
                "ais",
                "cbs",
                "network",
                "speaks",
                "controversial",
                "live",
                "watch",
                "ceo",
                "tv",
                "digital",
                "devices",
                "available",
                "clearview",
                "recognition"
            ],
            "summary": "Clearview AI facial recognition software aims to match people's faces with billions of images scraped off social media and shares them with clients like police agencies.\nCBS News correspondent Errol Barnett joined CBSN AM with more on the CEO's first network TV interview.\nSubscribe to the CBS News Channel HERE: http://youtube.com/cbsnewsWatch CBSN live HERE: http://cbsn.ws/1PlLpZ7Follow CBS News on Instagram HERE: https://www.instagram.com/cbsnews/Like CBS News on Facebook HERE: http://facebook.com/cbsnewsFollow CBS News on Twitter HERE: http://twitter.com/cbsnewsGet the latest news and best in original reporting from CBS News delivered to your inbox.\nhttp://bit.ly/1OQA29B---CBSN is the first digital streaming news network that will allow Internet-connected consumers to watch live, anchored news coverage on their connected TV and other devices.\nAt launch, the network is available 24/7 and makes all of the resources of CBS News available directly on digital platforms with live, anchored coverage 15 hours each weekday.",
            "metadata": {
                "source_domain": "www.clearview.ai",
                "scrape_date": "2024-10-25T12:40:01.053128",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 1430
            }
        },
        {
            "title": "Clearview AI Opt Out Guide",
            "text": "To opt out of Clearview AI, follow our Clearview AI opt-out guide.\n\nClearview AI is a facial recognition platform. Basically, it’s a search engine of publicly available images (of which it now has more than 40 billion, according to its site).\n\nWhen Clearview AI users (currently only government agencies) upload an image, they get links to publicly available photos that match (or are similar to) the person in the image they uploaded.\n\nUse our step-by-step guide below to opt out of Clearview AI.\n\nDeleteMe’s Clearview AI Opt Out Review\n\nTo opt out of Clearview AI, you must complete an online form, upload a photo of your face, and click on a confirmation link in your email. Your request should be processed after a waiting period.\n\nSpeed: 2 Difficulty: 4\n\nClearview AI Listing Removal Walkthrough\n\nOpt out of Clearview in four steps.\n\nGo to https://www.clearview.ai/ and scroll to the bottom of the page.\n\nClick “Privacy & Requests” in the footer (under ‘Legal’).\n\n2. Under the state you live in, click “Delete”\n\nClearview AI allows you to opt out of their database if you are a California, Colorado, Connecticut, Illinois, Utah, or Virginia resident.\n\nUnder the state you are a resident of, click the privacy right you want to exercise (Access, Delete, Do Not Sell/Share, Correct, or Limit Use/Disc. Of Sens. Info).\n\n3. Fill out the form and click “Submit”\n\nYou will be redirected to an online privacy form. Fill it out.\n\nFirst, affirm that you’re a resident of the state you chose or are authorized to request opt-out on behalf of someone else in the state.\n\nNext, select the right you want to exercise (Access My Information, Delete My Information, Do Not Sell/Share My Information, Correct My Information, or Limit Use and Disclosure of Sensitive Personal Information). You can select multiple rights.\n\nThen, enter your email address. Clearview AI will send you a confirmation email when your request is completed.\n\nFinally, upload a photo of your face.\n\nClick “I acknowledge.”\n\nClick the “I’m not a robot” checkbox.\n\nClick “Submit.”\n\n4. Click the email confirmation link\n\nTo verify your request, Clearview AI will send you a confirmation link to your email address.\n\nGo to your inbox, find the email from Clearview AI, and click the “Confirm email” button.\n\nNote: If you don’t see the email from Clearview AI, check your spam folder.\n\nYour Clearview AI opt-out request is in progress.\n\nYou can contact Clearview AI by email at privacy@clearview.ai or by leaving a voicemail at (866) 637-0257.\n\nClearview AI asks that you do not email them with privacy requests but rather complete the appropriate online form available here: https://www.clearview.ai/privacy-and-requests/\n\nWho Is Selling Your Info?\n\nData brokers! These companies collect your personal information from various sources (public records, social media, etc.), compile this information into detailed profiles, and sell these profiles to anyone who wants them.\n\nLearn more about data brokers and people search sites in our detailed data broker guide.\n\nThen, take a look at our data broker opt-out guide to see which data brokers and people search sites you should opt-out from, including:\n\nAlternatively, consider subscribing to a data broker removal service like DeleteMe. Our privacy experts will delete you from data brokers continuously on your behalf, saving you hundreds of hours in the process.\n\nClearview AI Opt Out FAQs\n\nHere are some common questions that people have about Clearview AI.\n\nWhat is Clearview AI?\n\nClearview AI is a facial recognition company.\n\nIt provides law enforcement and government agencies with a platform that acts as a face search engine. Users can upload a photo, and the system will try to find a match in its database. It then links to where those matches appear online.\n\nTo create its database of billions of photos, Clearview AI scraped millions of websites, including social media platforms.\n\nCan anyone use Clearview AI?\n\nNo. Currently, only government agencies and their agents can use Clearview AI.\n\nDoes Clearview AI have my photo?\n\nProbably. If your photos appear online, then it is very likely that Clearview AI has you in their database.\n\nThe good news is that you can opt out of Clearview AI. To do so, you need to complete an opt-out form on Clearview AI’s website and upload an image of your face. You can read our full guide to learn how to opt out of Clearview AI.",
            "url": "https://joindeleteme.com/blog/clearview-ai-opt-out-guide/#:~:text=To%20opt%20out%20of%20Clearview%20AI%2C%20you%20must%20complete%20an,processed%20after%20a%20waiting%20period.",
            "authors": [],
            "publish_date": "2024-08-16T11:39:08-04:00",
            "keywords": [
                "email",
                "request",
                "opt",
                "guide",
                "information",
                "data",
                "click",
                "ai",
                "optout",
                "clearview",
                "upload"
            ],
            "summary": "To opt out of Clearview AI, follow our Clearview AI opt-out guide.\nUse our step-by-step guide below to opt out of Clearview AI.\nDeleteMe’s Clearview AI Opt Out ReviewTo opt out of Clearview AI, you must complete an online form, upload a photo of your face, and click on a confirmation link in your email.\nClearview AI Opt Out FAQsHere are some common questions that people have about Clearview AI.\nYou can read our full guide to learn how to opt out of Clearview AI.",
            "metadata": {
                "source_domain": "joindeleteme.com",
                "scrape_date": "2024-10-25T12:40:02.834675",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 4385
            }
        },
        {
            "title": "Toronto police used Clearview AI facial recognition software in 84 investigations",
            "text": "Toronto police used Clearview AI facial recognition software to try to identify suspects, victims and witnesses in 84 criminal investigations in the three and a half months officers utilized the controversial technology before their police chief found out and ordered them to stop.\n\nThe revelations are contained in an internal police document recently obtained by CBC News through an appeal of an access to information request.\n\nBetween October 2019 and early February 2020, officers uploaded more than 2,800 photos to the U.S. company's software to look for a match among the three billion images Clearview AI extracted from public websites, such as Facebook and Instagram, to build its database.\n\nToronto police first admitted that some of its officers used Clearview AI in mid-February 2020, one month after the service denied using it. But until now, no details around how — and to what extent — officers used the facial recognition software have been released.\n\nThe internal report shows how detectives from multiple units started to use a free trial of Clearview AI to advance criminal investigations without consulting anyone other than the company itself and internal supervisors about the legality and accuracy of the technology.\n\n\"When you're enforcing the law, your first obligation is to comply with it,\" said Brenda McPhail, director of the privacy, technology and surveillance program at the Canadian Civil Liberties Association (CCLA). \"It really doesn't seem like that was top of mind as the concept of this tool, as the examples of this tool, as the conversations about this tool circulated through the force.\"\n\nBrenda McPhail of the Canadian Civil Liberties Association says the police use of facial recognition technology as an investigative tool is a 'slippery slope' when it comes to privacy. (Submitted by Brenda McPhail)\n\nAccording to the report, detectives using the technology only met with Crown attorneys about Clearview AI after a New York Times investigation in January 2020 revealed details of how the company compiled its database and its use by more than 600 law enforcement agencies in Canada, the United States and elsewhere. Soon after, then-Toronto police chief Mark Saunders was informed that his officers were using the software and ordered them to stop on Feb. 5.\n\nSince then, four Canadian privacy commissioners have determined that Clearview AI conducted mass surveillance and broke Canadian privacy laws by collecting photos of Canadians without their knowledge or consent.\n\nCriminal cases could be in jeopardy\n\nGiven those findings, the co-chair of the Criminal Lawyers' Association's criminal law and technology committee says the police service's lack of due diligence before using Clearview AI could put cases where it was used at risk.\n\n\"If police violated the law as part of their investigations, this could make those investigations vulnerable to charter challenges,\" said Eric Neubauer, a Toronto lawyer.\n\n\"We have the right in Canada to be free from unreasonable search and seizure — one could conceivably see an argument being brought in court that this was a fairly profound violation of that right.\"\n\nWhen he was Toronto police chief, Mark Saunders found out his officers were using Clearview AI and ordered them to stop utilizing it on Feb. 5, 2020. (Michael Wilson/CBC)\n\nSo far, Neubauer and McPhail say they haven't seen a Canadian example of the software's use face legal scrutiny in court. That said, there were already two Toronto cases before the courts based at least in part on evidence that officers generated through the use of Clearview AI in March 2020, according to the report.\n\nOf the 84 criminal investigations where searches were completed, the report says that 25 were advanced through Clearview AI, with investigators identifying or confirming the whereabouts of four suspects, 12 victims and two witnesses.\n\nNo plans to use Clearview AI: Toronto police\n\nIn a statement, Toronto police spokesperson Connie Osborne told CBC News that the service has no plans to use Clearview AI again.\n\n\"The Toronto Police Services Board is currently developing a policy for the use of artificial intelligence technology and machine learning following public consultation,\" Osborne said.\n\n\"The service is also developing a robust procedure for the adoption of new technology to ensure governance of procurement and any potential use is compliant with the relevant laws, including privacy requirements.\"\n\nThe proposed AI technology policy would establish five risk-based categories for technology ranging from minimal to extreme risk. \"A facial recognition software with illegally sourced data that could result in mass surveillance\" is listed as an example of extreme risk technology on the board's public consultation web page — which would not be allowed for use under the proposed police policy.\n\nToronto police attended a conference in October 2019 in the Netherlands, where one detective was introduced to Clearview AI through a showcase put on by the FBI and the U.S. Department of Homeland Security, according to the service's internal report. (Thomas Peter/Reuters)\n\nDetective introduced to Clearview AI at conference\n\nAccording to the report obtained by CBC News, Toronto police were first introduced to Clearview AI at a victim identification conference in the Netherlands in October 2019.\n\nWhile there, a detective attended an FBI and U.S. Department of Homeland Security showcase of the technology as an investigative tool in identifying exploited children online — and also used Clearview AI in connection with real child exploitation investigations.\n\nWithin days of returning to Toronto, the service obtained a free trial of Clearview AI. By the end of October, investigators from both the child exploitation and intelligence services were using the technology. By mid-December 2019, an internal showcase of Clearview AI was held for roughly 100 investigators from sex crimes, homicide and financial crimes units.\n\nIn the report, the details are redacted for all but one investigation where officers used Clearview AI: the third homicide of 2020 was advanced through the use of the technology and an arrest was made. Although the report doesn't specify, it was the suspect who was identified through the software.\n\nFirefighters found Maryna Kudzianiuk with serious injuries while responding to a fire at this highrise building in Toronto in January 2020. Police ruled her death a homicide after she died in hospital. (Jeremy Cohn/CBC)\n\nToronto police confirmed with CBC News that the victim in that case was Maryna Kudzianiuk. The 49-year-old died in hospital after firefighters found her while responding to a Scarborough highrise fire in January 2020.\n\nAfter an autopsy, police ruled her death a homicide, and about a week later a man was arrested and charged with first-degree murder.\n\n'A slippery slope'\n\nWhile examples like that might show the benefits of the technology to help solve — or stop — the most serious crimes, the CCLA's McPhail says that \"it's such a slippery slope.\"\n\nShe told CBC News that child exploitation is often used to legitimize invasive technology, such as that sold by Clearview AI, by claiming \"one is too many,\" without focusing on all of the images of children scooped up non-consensually.\n\n\"The faces of our kids — if we've put up their photo on Facebook for Grandma — end up in a police lineup that can be searched by police in Canada, by police in the U.S., by police in Europe,\" McPhail said. \"What is the risk to all of the children proportionate to the benefit to the few children?\"\n\nMcPhail and Neubauer also raised concerns about the accuracy of Clearview AI's software.\n\n\"This technology has been found to have higher incidences of false positives or misidentifications for faces of people of colour,\" Neubauer said. \"This means more investigations, potentially detentions and arrests of individuals in marginalized groups who already face disproportionate levels of arrest, investigation and detention.\"\n\nGiven those issues, the Toronto lawyer stresses the importance of studying emerging technologies before using them in real cases going forward.\n\n\"These tools used by law enforcement must be subject to public and legal scrutiny and oversight,\" he said. \"That means full transparency as to when it's being used and also how it works.\"\n\nProvincial watchdogs issue order to delete photos\n\nClearview AI left the Canadian market in the summer of 2020. But concerns around the images the company has collected remain.\n\nEarlier this month, the provincial privacy watchdogs for British Columbia, Alberta and Quebec ordered Clearview AI to delete images and biometric data collected without permission.\n\nClearview AI previously told the B.C. privacy commissioner that it was \"simply not possible\" for the company to identify whether individuals in photos were in Canada at the time the image was taken or whether they were Canadian citizens or residents.\n\nThe Information and Privacy Commissioner of Ontario says it doesn't have jurisdiction over private companies such as Clearview AI — the way privacy watchdogs do in B.C., Alberta and Quebec — because Ontario doesn't have a private-sector privacy law.\n\nBut Ontario's privacy commissioner is working with its federal and provincial counterparts to develop guidance on the use of facial recognition technologies by police, which the office says will be released next year.",
            "url": "https://www.cbc.ca/news/canada/toronto/toronto-police-report-clearview-ai-1.6295295",
            "authors": [
                "Reporter",
                "Cbc Toronto",
                "Nicole Brockbank Is A Reporter For Cbc Toronto'S Enterprise Unit. Fuelled Coffee",
                "She Digs Up",
                "Researches",
                "Writes Original Investigative",
                "Feature Stories. Nicole.Brockbank Cbc.Ca"
            ],
            "publish_date": null,
            "keywords": [
                "privacy",
                "software",
                "using",
                "toronto",
                "technology",
                "used",
                "facial",
                "84",
                "2020",
                "investigations",
                "officers",
                "report",
                "ai",
                "clearview",
                "recognition"
            ],
            "summary": "Toronto police first admitted that some of its officers used Clearview AI in mid-February 2020, one month after the service denied using it.\nBut until now, no details around how — and to what extent — officers used the facial recognition software have been released.\nNo plans to use Clearview AI: Toronto policeIn a statement, Toronto police spokesperson Connie Osborne told CBC News that the service has no plans to use Clearview AI again.\nThe proposed AI technology policy would establish five risk-based categories for technology ranging from minimal to extreme risk.\nBy mid-December 2019, an internal showcase of Clearview AI was held for roughly 100 investigators from sex crimes, homicide and financial crimes units.",
            "metadata": {
                "source_domain": "www.cbc.ca",
                "scrape_date": "2024-10-25T12:40:03.979560",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 9433
            }
        },
        {
            "title": "",
            "text": "",
            "url": "https://www.oipc.bc.ca/news-releases/3611",
            "authors": [],
            "publish_date": null,
            "keywords": [],
            "summary": "",
            "metadata": {
                "source_domain": "www.oipc.bc.ca",
                "scrape_date": "2024-10-25T12:40:03.242195",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 0
            }
        },
        {
            "title": "Greece: Opened data protection investigation into Clearview AI",
            "text": "Opened data protection investigation into Clearview AI\n\nOn 16 July 2021, the Greek Data Protection Authority opened an investigation into ClearviewAI's personal data collection practices, after receiving a complaint from Homo Digitalis, a Greek civil society association. In the complaint, it was noted that CrearviewAI failed to grant access to the data it stores after receiving a request from the plaintiff. Furthermore, it was alleged that ClearviewAI's personal data collection practices, including web-scraping techniques and image processing, violate the EU General Data Protection Regulation (GDPR).\n\nOriginal source",
            "url": "https://digitalpolicyalert.org/event/5658-opened-data-protection-investigation-into-clearview-ai",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "protection",
                "receiving",
                "greece",
                "investigation",
                "personal",
                "greek",
                "collection",
                "data",
                "ai",
                "opened",
                "complaint",
                "clearview",
                "practices"
            ],
            "summary": "Opened data protection investigation into Clearview AIOn 16 July 2021, the Greek Data Protection Authority opened an investigation into ClearviewAI's personal data collection practices, after receiving a complaint from Homo Digitalis, a Greek civil society association.\nIn the complaint, it was noted that CrearviewAI failed to grant access to the data it stores after receiving a request from the plaintiff.\nFurthermore, it was alleged that ClearviewAI's personal data collection practices, including web-scraping techniques and image processing, violate the EU General Data Protection Regulation (GDPR).\nOriginal source",
            "metadata": {
                "source_domain": "digitalpolicyalert.org",
                "scrape_date": "2024-10-25T12:40:06.709589",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 624
            }
        },
        {
            "title": "",
            "text": "",
            "url": "https://qmro.qmul.ac.uk/xmlui/bitstream/handle/123456789/80559/1%20-%20Facial%20Recognition%20Technology%20%28Article%29.pdf?sequence=1&isAllowed=y",
            "authors": [],
            "publish_date": null,
            "keywords": [],
            "summary": "",
            "metadata": {
                "source_domain": "qmro.qmul.ac.uk",
                "scrape_date": "2024-10-25T12:40:04.513025",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 0
            }
        },
        {
            "title": "IAPP",
            "text": "{\"text\": \"You need to enable JavaScript to run this app.\"}",
            "url": "https://iapp.org/news/a/greek-dpa-imposes-20m-euro-fine-on-clearview-ai-for-unlawful-processing-of-personal-data",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "iapp"
            ],
            "summary": "",
            "metadata": {
                "source_domain": "iapp.org",
                "scrape_date": "2024-10-25T12:40:07.579377",
                "content_type": "news_articles",
                "extraction_method": "trafilatura",
                "content_length": 0
            }
        },
        {
            "title": "IAPP",
            "text": "{\"text\": \"You need to enable JavaScript to run this app.\"}",
            "url": "https://iapp.org/news/b/greek-dpa-fines-clearview-ai-20m-euros-bans-data-collection-processing",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "iapp"
            ],
            "summary": "",
            "metadata": {
                "source_domain": "iapp.org",
                "scrape_date": "2024-10-25T12:40:07.723700",
                "content_type": "news_articles",
                "extraction_method": "trafilatura",
                "content_length": 0
            }
        },
        {
            "title": "Greece: Ruling in data protection investigation into Clearview AI",
            "text": "Ruling in data protection investigation into Clearview AI\n\nOn 13 July 2022, the Hellenic Data Protection Authority (DPA) fined the company Clearview AI after pursuing an investigation into its personal data collection practices. Clearview AI was fined EUR 20 million for violating the EU General Data Protection Regulation (GDPR) by processing individuals' biometric and geolocation data without explicit consent and for failing to provide access to the data its stores after requests. Furthermore, the company was found in violation of the principles of legality and transparency regarding data collection. In addition, in its ruling, the DPA prohibited the company from collecting and processing personal data of individuals in Greece using facial recognition and ordered it to erase the collected data relating to individuals located in Greece.\n\nOriginal source",
            "url": "https://digitalpolicyalert.org/event/5627-ruling-in-data-protection-investigation-into-clearview-ai",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "protection",
                "individuals",
                "greece",
                "company",
                "investigation",
                "personal",
                "fined",
                "data",
                "ruling",
                "ai",
                "processing",
                "clearview"
            ],
            "summary": "Ruling in data protection investigation into Clearview AIOn 13 July 2022, the Hellenic Data Protection Authority (DPA) fined the company Clearview AI after pursuing an investigation into its personal data collection practices.\nClearview AI was fined EUR 20 million for violating the EU General Data Protection Regulation (GDPR) by processing individuals' biometric and geolocation data without explicit consent and for failing to provide access to the data its stores after requests.\nFurthermore, the company was found in violation of the principles of legality and transparency regarding data collection.\nIn addition, in its ruling, the DPA prohibited the company from collecting and processing personal data of individuals in Greece using facial recognition and ordered it to erase the collected data relating to individuals located in Greece.\nOriginal source",
            "metadata": {
                "source_domain": "digitalpolicyalert.org",
                "scrape_date": "2024-10-25T12:40:08.573327",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 864
            }
        },
        {
            "title": "Clearview AI: Hellenic DPA demands 20 million euro fine • EFDPO",
            "text": "With the decision Nr. 35/2022 the Hellenic DPA imposed a fine of 20 million euros on Clearview AI Inc following the examination of a complaint lodged by the civil non-profit organization “Homo Digitalis” on behalf of a complainant, who claimed that the above mentioned company violated her right of access to personal data. Except for the 20 million euros fine that was imposed on Clearview AI Inc for violating the principles of lawfulness and transparency (art. 5 paragraphs 1(a) and (2), 6, 9 GDPR) and its obligations under Articles 12, 14, 15 and 27 of the GDPR, the DPA ordered the company to comply, so that the complainant’s request for access to personal data could be satisfied and prohibited the further collection and processing of personal data of subjects that are located in Greece, using methods that include facial recognition. Finally, the company was ordered to delete all the personal data of subjects located in Greece that are collected and processed with the use of such methods.\n\nSource\n\nFind more information about the Hellenic Association of Data Protection & Privacy: www.dataprotection.gr",
            "url": "https://www.efdpo.eu/clearview-ai-hellenic-dpa-demands-20-million-euro-fine/",
            "authors": [
                "Karsten Füllhaase"
            ],
            "publish_date": "2022-08-22T08:48:59+00:00",
            "keywords": [
                "fine",
                "20",
                "dpa",
                "greece",
                "company",
                "demands",
                "personal",
                "subjects",
                "imposed",
                "data",
                "hellenic",
                "efdpo",
                "euro",
                "located",
                "ai",
                "million",
                "ordered",
                "clearview"
            ],
            "summary": "With the decision Nr.\n35/2022 the Hellenic DPA imposed a fine of 20 million euros on Clearview AI Inc following the examination of a complaint lodged by the civil non-profit organization “Homo Digitalis” on behalf of a complainant, who claimed that the above mentioned company violated her right of access to personal data.\nExcept for the 20 million euros fine that was imposed on Clearview AI Inc for violating the principles of lawfulness and transparency (art.\nFinally, the company was ordered to delete all the personal data of subjects located in Greece that are collected and processed with the use of such methods.\nSourceFind more information about the Hellenic Association of Data Protection & Privacy: www.dataprotection.gr",
            "metadata": {
                "source_domain": "www.efdpo.eu",
                "scrape_date": "2024-10-25T12:40:08.866657",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 1116
            }
        },
        {
            "title": "Clearview AI’s GDPR fines rise to $110M total after latest penalty by Dutch DPA",
            "text": "Clearview AI was fined 30.5 million euro (U.S. $33.8 million) by the Dutch Data Protection Authority (DPA) and ordered to stop collecting images of Dutch citizens in the latest enforcement action against the U.S. company.\n\nClearview has created a massive database by collecting photographs of people from websites and social media, along with their names and other identifying information. The company has developed extremely powerful facial recognition software that can match a new photo or video with an identity already in its database of 50 billion images.\n\nClearview has rocketed to success by selling access to its database, and the facial recognition tool, to government law enforcement and security agencies. It sells a version of its facial recognition tool to businesses but does not provide the private sector access to the database, the company said.",
            "url": "https://www.complianceweek.com/regulatory-enforcement/clearview-ais-gdpr-fines-rise-to-110m-total-after-latest-penalty-by-dutch-dpa/35338.article#:~:text=Clearview%20is%20mandated%20under%20the,requests%2C%20the%20Dutch%20DPA%20alleged.",
            "authors": [
                "Adrianne Appel",
                "Aaron Nicodemus",
                "Jeff Dale"
            ],
            "publish_date": null,
            "keywords": [
                "company",
                "dutch",
                "access",
                "clearview",
                "latest",
                "facial",
                "fines",
                "enforcement",
                "ais",
                "gdpr",
                "million",
                "database",
                "dpa",
                "penalty",
                "recognition",
                "collecting",
                "total",
                "tool",
                "rise"
            ],
            "summary": "Clearview AI was fined 30.5 million euro (U.S. $33.8 million) by the Dutch Data Protection Authority (DPA) and ordered to stop collecting images of Dutch citizens in the latest enforcement action against the U.S. company.\nClearview has created a massive database by collecting photographs of people from websites and social media, along with their names and other identifying information.\nThe company has developed extremely powerful facial recognition software that can match a new photo or video with an identity already in its database of 50 billion images.\nClearview has rocketed to success by selling access to its database, and the facial recognition tool, to government law enforcement and security agencies.\nIt sells a version of its facial recognition tool to businesses but does not provide the private sector access to the database, the company said.",
            "metadata": {
                "source_domain": "www.complianceweek.com",
                "scrape_date": "2024-10-25T12:40:09.282762",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 863
            }
        },
        {
            "title": "Clearview AI’s massive fine for GDPR violations — and what it means",
            "text": "“Move fast and break things.”\n\n“It’s easier to ask for forgiveness than to get permission.”\n\n“F*** around and find out.”\n\nWhat inspired this somewhat circular set of clichés to start bouncing around in my head is the news from early September that Clearview AI, which provides facial-recognition software and services, has been fined €30.5 million (roughly $34 million) by the Dutch Data Protection Authority (DPA) for violating the EU’s General Data Protection Regulation (GDPR).\n\nIn case you’re not fully up to speed on GDPR, it is one of the most stringent data-protection regulations in the world, first enacted in 2018. Its basic premise is that if you collect and store any personal data about any EU resident, you must have their permission and you must treat it very carefully to ensure it is secure.\n\nGDPR includes a requirement that the data must only be stored and processed in the EU — that’s one reason Barracuda now has considerably more data storage infrastructure overseas than we did before GDPR was enacted.\n\nBillions of faces\n\nClearview AI’s breathtaking fine was imposed because, according to the DPA, the company built an “illegal database with billions of photos of faces.” As the company’s own website states, “Our platform, powered by facial recognition technology, includes the largest known database of 50+ billion facial images sourced from public-only web sources, including news media, mugshot websites, public social media, and other open sources.”\n\nThis is Clearview AI’s business model: Build a huge database of faces with associated names, analyze the images to assign a unique biometric code to each face, and then deliver a service to police, military, and intelligence organizations that lets them scan new images — say, surveillance footage, or photos from a political protest — to identify the people in them.\n\nClearly this can have positive uses, such as helping to solve crimes. Just as clearly, it can be put to more sinister uses, such as helping a dictatorial regime identify and punish political opponents.\n\nFlouting the law\n\nThe GDPR is very clear on this: You cannot collect people’s data, including facial biometric data, without their consent or knowledge, and without informing them fully about what the data will be used for. You also have to provide a way for individuals to access their data upon request.\n\nFor its part, Clearview AI claims that it is not subject to GDPR regulations because it does not have a place of business in the EU — which in my non-expert opinion is a completely disingenuous argument that doesn’t absolve them of anything.\n\nAccording to Dutch DPA chairman Aleid Wolfsen, “We are now going to investigate if we can hold the management of the company personally liable and fine them for directing those violations. That liability already exists if directors know that the GDPR is being violated, have the authority to stop that, but omit to do so, and in this way consciously accept those violations.”\n\nIf you doubt that Clearview AI’s management knew they were violating GDPR and embraced it as a deliberate strategy, please contact me, I have a bridge to sell you.\n\nNo. Clearly this is an example of the first two aphorisms with which I opened this post. And if the company and its directors end up having to pay hefty fines, it also exemplifies the third one.\n\nLike Uber moving aggressively into cities in obvious violation of their livery and limousine dispatch rules, Clearview AI likely hopes that by establishing itself as the only provider of its brand of service, and by building up a customer base of governments and their agencies, it can insulate itself from enforcement of privacy laws.\n\nWolfsen issued a warning: “‘Clearview breaks the law, and this makes using the services of Clearview illegal. Dutch organizations that use Clearview may therefore expect hefty fines from the Dutch DPA.” But once people got used to the convenience of ride-sharing, regulators had no choice but to accommodate them. Similarly, it’s hard to see police and intelligence agencies willingly giving up the power to put a name to any face in any photo.\n\nLet’s get compliant\n\nIf nothing else, the €30.5 million fine imposed on Clearview AI demonstrates that European regulators are deadly serious about enforcing GDPR. So, for the sake of argument, let’s say that your organization would prefer to comply with GDPR and other data-privacy rules — and avoid the risk of being subjected to massive fines.\n\nOne important step is to make sure you know exactly where protected customer and other sensitive data is stored, and to remediate any potential exposures. Barracuda Data Inspector automatically scans your SharePoint and OneDrive data to both identify sensitive data that’s improperly stored, and to find and eliminate malware or other malicious files. It’s a great way to increase your peace of mind and confidence that you’re staying compliant and not at risk of paying massive fines.",
            "url": "https://blog.barracuda.com/2024/10/23/clearview-ai-fine-gdpr-violations",
            "authors": [
                "Tony Burgess"
            ],
            "publish_date": "2024-10-23T00:00:00",
            "keywords": [
                "means",
                "fine",
                "dpa",
                "ais",
                "violations",
                "data",
                "dutch",
                "way",
                "stored",
                "million",
                "ai",
                "gdpr",
                "clearview",
                "images",
                "massive"
            ],
            "summary": "According to Dutch DPA chairman Aleid Wolfsen, “We are now going to investigate if we can hold the management of the company personally liable and fine them for directing those violations.\nWolfsen issued a warning: “‘Clearview breaks the law, and this makes using the services of Clearview illegal.\nDutch organizations that use Clearview may therefore expect hefty fines from the Dutch DPA.” But once people got used to the convenience of ride-sharing, regulators had no choice but to accommodate them.\nLet’s get compliantIf nothing else, the €30.5 million fine imposed on Clearview AI demonstrates that European regulators are deadly serious about enforcing GDPR.\nIt’s a great way to increase your peace of mind and confidence that you’re staying compliant and not at risk of paying massive fines.",
            "metadata": {
                "source_domain": "blog.barracuda.com",
                "scrape_date": "2024-10-25T12:40:09.675578",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 4956
            }
        },
        {
            "title": "Clearview AI hit with its largest GDPR fine yet as Dutch regulator considers holding execs personally liable",
            "text": "Clearview AI, the controversial U.S.-based facial recognition startup that built a searchable database of 30 billion images populated by scraping the internet for people’s selfies without their consent, has been hit with its largest privacy fine yet in Europe.\n\nThe Netherlands’ data protection authority, Autoriteit Persoonsgegevens (AP), said on Tuesday that it has imposed a penalty of €30.5 million — around $33.7 million at current exchange rates — on Clearview AI for a raft of breaches of the European Union’s General Data Protection Regulation (GDPR) after confirming the database contains images of Dutch citizens.\n\nThis fine is larger than separate GDPR sanctions imposed by data protection authorities in France, Italy, Greece and the U.K. back in 2022.\n\nIn a press release, the AP warned it has ordered an additional penalty of up to €5.1 million that will be levied for continued non-compliance, saying Clearview failed to stop the GDPR violations after the investigation concluded, which is why it has made the additional order. The total fine could hit €35.6 million if Clearview AI keeps ignoring the Netherlands regulator.\n\nThe Dutch data protection authority began investigating Clearview AI in March 2023 after it received complaints from three individuals related to the company’s failure to comply with data access requests. The GDPR gives EU residents a set of rights related to their personal data, which includes the right to request a copy of their data or have it deleted. Clearview AI has not been complying with such requests.\n\nOther GDPR violations the AP is sanctioning Clearview AI for include the salient one of building a database by collecting people’s biometric data without a valid legal basis. It is also being sanctioned for GDPR transparency failings.\n\n“Clearview should never have built the database with photos, the unique biometric codes and other information linked to them,” the AP wrote. “This especially applies for the [face-derived unique biometric] codes. Like fingerprints, these are biometric data. Collecting and using them is prohibited. There are some statutory exceptions to this prohibition, but Clearview cannot rely on them.”\n\nThe company also failed to inform the individuals whose personal data it scraped and added to its database, per the decision.\n\nReached for comment, Clearview representative Lisa Linden of the Washington, D.C.-based PR firm Resilere Partners did not respond to questions but emailed TechCrunch a statement that’s attributed to Clearview’s chief legal officer, Jack Mulcaire.\n\n“Clearview AI does not have a place of business in the Netherlands or the EU, it does not have any customers in the Netherlands or the EU, and does not undertake any activities that would otherwise mean it is subject to the GDPR,” Mulcaire wrote, adding: “This decision is unlawful, devoid of due process and is unenforceable.”\n\nAccording to the Dutch regulator, the company cannot appeal the penalty as it failed to object to the decision.\n\nIt’s also worth noting that the GDPR is extraterritorial in scope, meaning it applies to the processing of personal data of EU people wherever that processing takes place.\n\nU.S.-based Clearview uses people’s scraped data to sell an identity-matching service to customers that can include government agencies, law enforcement and other security services. However, its clients are increasingly unlikely to hail from the EU, where use of the privacy law-breaking tech risks regulatory sanction — something which happened to a Swedish police authority back in 2021.\n\nThe AP warned that it will rigorously sanction any Dutch entities that seek to use Clearview AI. “Clearview breaks the law, and this makes using the services of Clearview illegal. Dutch organisations that use Clearview may therefore expect hefty fines from the Dutch DPA,” wrote Dutch DPA chairman, Aleid Wolfsen.\n\nAn English language version of the AP’s decision can be accessed via this link.\n\nPersonal liability?\n\nClearview AI has faced a raft of GDPR penalties over the past several years (on paper, it has amassed a total of about €100 million in EU privacy fines), but regional data protection authorities apparently haven’t been very successful at collecting any of these fines. The U.S.-based company remains uncooperative and has not appointed a legal representative in the EU.\n\nMore importantly, Clearview AI has not changed its GDPR-violating behavior — it has continued to flout European privacy laws with apparent operational impunity on account of being based elsewhere.\n\nThe Dutch AP is concerned about this, saying it is exploring ways to ensure Clearview stops breaking the law. The regulator is looking into whether the company’s directors can be held personally responsible for the violations.\n\n“Such a company cannot continue to violate the rights of Europeans and get away with it. Certainly not in this serious manner and on this massive scale. We are now going to investigate if we can hold the management of the company personally liable and fine them for directing those violations,” wrote Wolfsen. “That liability already exists if directors know that the GDPR is being violated, have the authority to stop that, but omit to do so, and in this way consciously accept those violations.”\n\nSince we’ve just seen the founder of messaging app Telegram, Pavel Durov, arrested on French soil over allegations of illegal content being spread on his platform, it’s interesting to consider whether sanctioning the people managing Clearview might have a greater chance of driving compliance — they may wish to travel freely to and around the EU, after all.",
            "url": "https://techcrunch.com/2024/09/03/clearview-ai-hit-with-its-largest-gdpr-fine-yet-as-dutch-regulator-considers-holding-execs-personally-liable/",
            "authors": [
                "Natasha Lomas",
                "Rebecca Bellan",
                "Zack Whittaker",
                "Sean O'Kane",
                "Frederic Lardinois",
                "Kyle Wiggers",
                "Manish Singh",
                "Senior Reporter",
                "--C-Author-Card-Image-Size Align-Items Center Display Flex Gap Var",
                "Media"
            ],
            "publish_date": "2024-09-03T00:00:00",
            "keywords": [
                "largest",
                "execs",
                "hit",
                "fine",
                "protection",
                "holding",
                "liable",
                "eu",
                "ap",
                "dutch",
                "data",
                "million",
                "ai",
                "gdpr",
                "personally",
                "clearview",
                "regulator",
                "database"
            ],
            "summary": "This fine is larger than separate GDPR sanctions imposed by data protection authorities in France, Italy, Greece and the U.K. back in 2022.\nThe total fine could hit €35.6 million if Clearview AI keeps ignoring the Netherlands regulator.\nThe Dutch data protection authority began investigating Clearview AI in March 2023 after it received complaints from three individuals related to the company’s failure to comply with data access requests.\nClearview AI has not been complying with such requests.\nThe Dutch AP is concerned about this, saying it is exploring ways to ensure Clearview stops breaking the law.",
            "metadata": {
                "source_domain": "techcrunch.com",
                "scrape_date": "2024-10-25T12:40:10.541866",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 5636
            }
        },
        {
            "title": "Extraterritorial enforcement of the GDPR in light of Clearview AI’s recent fine",
            "text": "The European General Data Protection Regulation (GDPR) applies to controllers not established in the European Union (EU) if their processing activities involve the monitoring of the behaviour of individuals within the EU. However, previous enforcement actions taken against Clearview AI clearly highlight that enforcing the GDPR against such controllers may be challenging in practice. On 16 May 2024, the Dutch Data Protection Authority (Autoriteit Persoonsgegevens; hereinafter: AP) fined Clearview AI €30.5 million for violating the GDPR. In light of the recent fine imposed on Clearview AI by the AP, this blog post discusses the extraterritorial scope of the GDPR and the difficulty of enforcing the GDPR extraterritorially.\n\nClearview AI\n\nClearview AI (hereinafter: Clearview), a facial recognition company based in New York, has developed a tool that recognises individuals by uploading a facial image and matching it with the 50 billion images stored within their database. It entered the spotlight in 2020, when the New York Times published an article that uncovered that Clearview had collected billions of images of individuals by indiscriminately scraping images from the Internet without their knowledge or consent. “Data scraping” is the automatic extraction of large amounts of data by the use of web scraping software. Clearview has collected data from millions of domain names by using an open-web crawling algorithm which collects data in an untargeted and systemic way. Clearview's data scrapers target not only individuals residing in the United States but anyone around the world whose pictures are available online. Clearview’s goal is to identify every single person on the planet using its facial recognition tool1.\n\n(Extra)territorial Scope of the GDPR\n\nCompared to its predecessor, the DPD, the territorial scope of the GDPR was significantly expanded. The GDPR’s territorial scope potentially extends to a wide range of online processing activities that take place outside the EU. A controller without an establishment within the EU could still be subject to the GDPR’s territorial scope if they monitor the behaviour of individuals residing within the EU.\n\nIn Clearview’s case, the AP determined that Clearview processes personal data of Dutch individuals, as images of Dutch citizens were found in Clearview’s database. The AP also referenced earlier decisions by other EU DPAs, which confirmed that Clearview’s database contained images of German, Italian and French citizens. Additionally, Clearview’s processing activities are deemed to involve the monitoring of the behaviour of Dutch citizens. The images that are collected also include the underlying metadata, such as webpage title, source link, geographical location, age, education, gender, date of birth, nationality, language and other data2. The collection and storage of facial images can be a great source of information about a person’s private life, especially when this occurs for an extended period of time. When images and their underlying metadata are collected continuously, the constant influx of information with regard to geographical location could reveal a person’s home address, work address, where they are located throughout the day, and other personal information concerning the individual. Considering the amount of pictures that Clearview collected and the continuous updates to the database with new (meta)data, it enables the monitoring of individuals’ behaviour over time.\n\nAs a result, Clearview’s processing activities are subject to the territorial scope of the GDPR. Nonetheless, based on prior enforcement actions taken by EU DPAs, it seems that enforcing the GDPR extraterritorially may be challenging in practice.\n\nExtraterritorial Enforcement Issues\n\nThe EU is obligated to guarantee the protection of personal data rights, as it is a fundamental right within the EU, and this protection may even extend beyond the EU’s borders. The difficulty of enforcing the GDPR, when it comes to cross-border processing, lies in the very nature of the Internet. The Internet is a global interconnected network that is not restricted by geographical borders. Data scrapers are not hindered by technological or geographical barriers when accessing personal data of EU residents on the Internet. On the other hand, the extraterritorial reach of the GDPR is delimited by state sovereignty. In practice, this complicates the extraterritorial enforcement of the GDPR when controllers do not have an establishment within the EU, as EU DPAs lack jurisdiction to enforce the GDPR outside EU borders.\n\nPrior to the AP’s fine, several DPAs in the EU, including in Austria, France, Germany, Italy and Greece have established that the activities of Clearview are violating the GDPR. Clearview insists that the GDPR does not apply to them because it does not provide its services in the EU. The company has been uncooperative with enforcement actions from EU DPAs.\n\nNext Steps\n\nGiven Clearview’s non-compliance with previous fines imposed by other EU DPAs, the AP is exploring alternative methods to ensure that Clearview ceases its violations. This includes investigating whether the company's directors can be held personally responsible for the breaches. With the recent arrest of Telegram's founder in France, it is worth considering whether sanctioning the management of Clearview could be a more effective approach to enforcing GDPR compliance. However, it remains to be seen whether this approach will prove succesful.‍\n\nIf your business employs similar (facial recognition) technologies or services and requires guidance on GDPR compliance, do not hesitate to get in touch with Privacy Company.\n\n‍\n\n[1] Drew Harwell, ‘Facial recognition firm Clearview tells investors it’s seeking massive expansion beyond law enforcement’ (WashingtonPost 16 February 2022) <www.washingtonpost.com/technology/2022/02/16/clearview-expansion-facial-recognition/> accessed 15 August 2023.\n\n[2] Garante per la protezione dei dati personali, Decision 9751362, Ordinanza ingiunzione nei confronti di Clearview AI, 10 febbraio 2022.",
            "url": "https://www.privacycompany.eu/blog/extraterritorial-enforcement-of-the-gdpr-in-light-of-clearview-ais-recent-fine-",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "light",
                "fine",
                "individuals",
                "eu",
                "scope",
                "enforcement",
                "clearviews",
                "recent",
                "ais",
                "extraterritorial",
                "data",
                "gdpr",
                "clearview",
                "images",
                "facial"
            ],
            "summary": "However, previous enforcement actions taken against Clearview AI clearly highlight that enforcing the GDPR against such controllers may be challenging in practice.\nIn light of the recent fine imposed on Clearview AI by the AP, this blog post discusses the extraterritorial scope of the GDPR and the difficulty of enforcing the GDPR extraterritorially.\nClearview's data scrapers target not only individuals residing in the United States but anyone around the world whose pictures are available online.\n(Extra)territorial Scope of the GDPRCompared to its predecessor, the DPD, the territorial scope of the GDPR was significantly expanded.\nIn practice, this complicates the extraterritorial enforcement of the GDPR when controllers do not have an establishment within the EU, as EU DPAs lack jurisdiction to enforce the GDPR outside EU borders.",
            "metadata": {
                "source_domain": "www.privacycompany.eu",
                "scrape_date": "2024-10-25T12:40:10.683073",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 6112
            }
        },
        {
            "title": "Clearview AI Engaged In “Mass Surveillance”",
            "text": "{\"text\": \"Clearview AI broke Canadian law when it scraped the internet for 3 billion photos of people, including possibly millions of Canadians, created biometric identifiers from those photos, and sold their facial recognition tool to police forces across Canada. It was mass surveillance. It was illegal. These are the findings of the joint investigation by the federal, BC, Alberta and Quebec Privacy Commissioners, released February 3rd, 2021. And police forces across the country used Clearview facial recognition tools, without due diligence or public transparency.\\nToday’s investigation report is damning and explicit: Clearview AI is at fault for flogging a tool that flagrantly violates Canadian law. In part this hinges on the concept of meaningful and informed consent, a principle at the heart of our law. Scraping images, contrary to the terms of service of many of the platforms, and using them for a purpose that individuals posting a pic for Grandma could never imagine, subverts consent. It is not the case that all information that is posted online is free and fair game for secondary uses. When people post information, they do so with a reasonable expectation that platform rules will be followed and their information will be used for those purposes they’ve agreed to, not scooped up by random third parties for completely different purposes. The report clearly states, “information collected from public websites, such as social media or professional profiles, and then used for an unrelated purpose, does not fall under the “publicly available” exception of PIPEDA, PIPA AB or PIPA BC. Nor is this information “public by law” , which would exempt it from Quebec’s Private Sector Law…”. In other words, every private sector privacy law in Canada would require consent, and Clearview didn’t have it.\\nThe other key finding is that Clearview used personal information of people in Canada (including children) for inappropriate purposes, which means that even if they had gotten consent (and they didn’t) the use would still be illegal. The Commissioners said that “the mass collection of images…represents the mass identification and surveillance of individuals by a private entity in the course of commercial activity” for purposes which “will often be to the detriment of the individual whose images are captured” and “create significant risk of harm to those individuals, the vast majority of whom have never been and will never be implicated in a crime.”\\nThe Commissioners recommended Clearview cease offering their facial recognition tool in Canada; stop collecting, using or disclosing images and biometric facial arrays from individuals in Canada; and delete images and facial arrays of such individuals. Clearview expressly disagreed with the findings and has not committed to following recommendations although they announced they were withdrawing from the Canadian market before this report was issued.\\nThe Commissioner’s investigation focused on Clearview and its culpability. But it must be noted that police forces across Canada are also at fault, for embracing the tool without doing assessments of its legality, and for misleading the public about it. When the New York Times broke the story about Clearview AI’s business practices in January 2020, many police forces asked by Canadian media if they were using it said no. When CCLA filed a series of access to information requests to check on those claims, we were beginning to get responses that there were “no responsive records” at about the same time as there was a security breach at Clearview. Their client list leaked, proving that the company had a number of Canadian clients in Nova Scotia, Alberta and Ontario. The Toronto Police Service, the OPP and the RCMP are among those who used it. Some forces claimed it was individual officers or units who experimented with trial versions of the software distributed at conferences, unknown to Chiefs of Police who had originally issued statements that the technology had not been procured or used.\\nThis is not, therefore, just a story about a bad technology actor, but also about a crisis of accountability with regards to police use of a controversial, inherently invasive surveillance technology. While the online world is under-regulated and our laws are out of date when faced with the potential of emerging technology, we do have privacy laws that govern the terms and nature of consent for uses of our personal information. Clearview’s application is not operating in an entirely lawless world, just one in which the law seems to be being ignored, by the company and by the law enforcement agencies who used the product.\\nAs I wrote when the story broke, this brings all of the social debate about facial recognition—should it be banned, are there ever cases where benefits outweigh the risks of its use, how can it be regulated (or simply, can it be effectively regulated)—into clear and urgent focus. Not only does facial recognition facilitate a form of mass surveillance that is profoundly dangerous to human rights in our democracy, but it is a fundamentally flawed technology. Larger, more responsible companies have been afraid to set this tech loose into the world for that reason; indeed, Amazon, IBM and Microsoft have stopped selling their facial recognition tools to police, recognizing they are too prone to facilitating discrimination given their inaccuracy on faces that are Black, Brown, Indigenous, female, young, that is, not male and white. Before the pandemic hit, the parliamentary Standing Committee on Access to Information, Privacy and Ethics planned a study of facial recognition technology, and that would be a good start to wider, deeper consideration of the many issues it raises.\\nBecause the investigation report, published today, makes one thing clear. It must be a priority to begin the hard but necessary public conversations that ask first if there are contexts in which this technology is appropriate for use in a democracy that values freedom from routine private sector or state scrutiny as we move about our public streets and transact business in private spaces.\\nA similarly urgent set of conversations is needed about the kinds of accountability and transparency the public deserves and demands in return from police who wish to use increasingly powerful and invasive surveillance technologies. The social license to exercise the powers we grant our law enforcement bodies can only exist in a trust relationship, and before we even get to the question of whether or not there is social benefit in allowing police to use facial recognition technology and if so, whether any benefit outweighs the social risks, we need assurance that our law enforcement bodies are committed to using tools that are lawfully conceived and lawfully implemented.\\nThe Clearview AI debacle and the report that lays it bare provides us with an important reminder of all that we have to lose if we fail to engage with the risks of new technology as well as being open to its benefits. CCLA reiterates our call for a moratorium on facial recognition software until Canada has had a chance, as a nation, to discuss, debate, and dispute first if, then, only if we get past that question, when and how, this technology should be used in a rights-respecting democracy.\"}",
            "url": "https://ccla.org/privacy/surveillance-technology/clearview-ai-engaged-in-mass-surveillance/",
            "authors": [
                "Brenda Mcphail"
            ],
            "publish_date": "2021-02-03T19:07:07+00:00",
            "keywords": [
                "surveillance",
                "vital",
                "notice",
                "policymakers",
                "mass",
                "consent",
                "onlinethe",
                "supplements",
                "ai",
                "online",
                "support",
                "engaged",
                "process",
                "clearview",
                "video"
            ],
            "summary": "Guest Blog: AI Policymakers Should Encourage Video Notice Supplements to Support Meaningful Consent OnlineThe design of an online consent process is vital to ensuring individuals can decide about…",
            "metadata": {
                "source_domain": "ccla.org",
                "scrape_date": "2024-10-25T12:40:06.417902",
                "content_type": "news_articles",
                "extraction_method": "trafilatura",
                "content_length": 198
            }
        },
        {
            "title": "Clearview AI, Used by Police to Find Criminals, Is Now in Public Defenders’ Hands",
            "text": "It was the scariest night of Andrew Grantt Conlyn’s life. He sat in the passenger seat of a two-door 1997 Ford Mustang, clutching his seatbelt, as his friend drove approximately 100 miles per hour down a palm-tree-lined avenue in Fort Myers, Fla. His friend, inebriated and distraught, occasionally swerved onto the wrong side of the road to pass cars that were complying with the 35-m.p.h. speed limit.\n\n“Someone is going to die tonight,” Mr. Conlyn thought.\n\nAnd then his friend hit a curb and lost control of the car. The Mustang began spinning wildly, hitting a light pole and three palm trees before coming to a stop, the passenger’s side against a tree.\n\nAt some point, Mr. Conlyn blacked out. When he came to, his friend was gone, the car was on fire and his seatbelt buckle was jammed. Luckily, a good Samaritan intervened, prying open the driver’s door and pulling Mr. Conlyn out of the burning vehicle.",
            "url": "https://www.nytimes.com/2022/09/18/technology/facial-recognition-clearview-ai.html",
            "authors": [
                "Kashmir Hill"
            ],
            "publish_date": "2022-09-18T00:00:00",
            "keywords": [
                "twodoor",
                "criminals",
                "public",
                "clearview",
                "seatbelt",
                "vehicle",
                "used",
                "mr",
                "wildly",
                "hands",
                "conlyn",
                "car",
                "mustang",
                "ai",
                "friend",
                "defenders",
                "wrong"
            ],
            "summary": "“Someone is going to die tonight,” Mr. Conlyn thought.\nThe Mustang began spinning wildly, hitting a light pole and three palm trees before coming to a stop, the passenger’s side against a tree.\nAt some point, Mr. Conlyn blacked out.\nWhen he came to, his friend was gone, the car was on fire and his seatbelt buckle was jammed.\nLuckily, a good Samaritan intervened, prying open the driver’s door and pulling Mr. Conlyn out of the burning vehicle.",
            "metadata": {
                "source_domain": "www.nytimes.com",
                "scrape_date": "2024-10-25T12:40:11.177764",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 912
            }
        },
        {
            "title": "Clearview AI commercialization of facial recognition raises concerns, risks",
            "text": "The year is 2054 and a man walks into a Gap store. The virtual salesperson greets him by name, “Hello Mr. Yakomoto. Welcome back to the Gap,” from the life-size video monitor. This famous scene is cribbed from the film Minority Report. The prescience displayed in the 2002 film has actually short-changed the advances of science and technology between then and now. Indeed, some may argue that today we are well beyond the fictional capabilities of the Minority Report. The moral dilemma posed in the film, however, remains.\n\nToday many sensors and cameras are in constant search-and-connect mode. Recently, Clearview AI has announced that it is taking its advanced facial recognition technologies beyond the already controversial government/law enforcement usage into the commercial sector. The company, according to the Washington Post, has accumulated over 100 billion facial photos and is adding to the total at a rate of 1.5 billion images per month, which it wishes to monetize.\n\nWhile Clearview AI is not sailing in the ocean of facial recognition technology alone, it is meeting with a strong headwind of controversy, complete with global efforts to regulate how the technology may be used, especially in law enforcement. Some other facial recognition vendors have stepped away while others simply have taken a pause.",
            "url": "https://www.csoonline.com/article/572133/clearview-ai-commercialization-of-facial-recognition-raises-concerns-risks.html",
            "authors": [
                "Contributing Writer",
                "More This Author",
                ".Wp-Block-Co-Authors-Plus-Coauthors.Is-Layout-Flow",
                "Class",
                "Wp-Block-Co-Authors-Plus",
                "Display Inline",
                ".Wp-Block-Co-Authors-Plus-Avatar",
                "Where Img",
                "Height Auto Max-Width",
                "Vertical-Align Bottom .Wp-Block-Co-Authors-Plus-Coauthors.Is-Layout-Flow .Wp-Block-Co-Authors-Plus-Avatar"
            ],
            "publish_date": null,
            "keywords": [
                "clearview",
                "recognition",
                "billion",
                "minority",
                "technology",
                "enforcement",
                "gap",
                "commercialization",
                "report",
                "ai",
                "risks",
                "concerns",
                "film",
                "raises",
                "facial"
            ],
            "summary": "This famous scene is cribbed from the film Minority Report.\nIndeed, some may argue that today we are well beyond the fictional capabilities of the Minority Report.\nRecently, Clearview AI has announced that it is taking its advanced facial recognition technologies beyond the already controversial government/law enforcement usage into the commercial sector.\nWhile Clearview AI is not sailing in the ocean of facial recognition technology alone, it is meeting with a strong headwind of controversy, complete with global efforts to regulate how the technology may be used, especially in law enforcement.\nSome other facial recognition vendors have stepped away while others simply have taken a pause.",
            "metadata": {
                "source_domain": "www.csoonline.com",
                "scrape_date": "2024-10-25T12:40:11.483924",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 1325
            }
        },
        {
            "title": "Face search company Clearview AI overturns UK privacy fine",
            "text": "Face search company Clearview AI overturns UK privacy fine\n\nGetty Images\n\nA company which enables its clients to search a database of billions of images scraped from the internet for matches to a particular face has won an appeal against the UK's privacy watchdog.\n\nLast year, Clearview AI was fined more than £7.5m by the Information Commissioner's Office (ICO) for unlawfully storing facial images.\n\nJack Mulcaire, Clearview AI's lawyer, said the firm was \"pleased\".\n\nThe ICO said it would \"take stock\" of the judgement.\n\nClearview AI offers its clients a system that works like a search engine for faces - users upload a photo and it finds matches in a database of billions of images it has collected.\n\nIt then provides links to where matching images appear online.\n\nIn March, Clearview's founder Hoan Ton-That told the BBC it had run nearly a million searches for US police, helping them to solve a range of crimes, including murders.\n\nHe also revealed its database contained 30 billion images scraped from the internet.\n\nCritics argue that law enforcement's use of Clearview's technology puts everyone into a \"perpetual police line-up\".\n\nAnd prior to the ICO's action, now ruled unlawful, France, Italy and Australia had also taken action against the firm.\n\nThe BBC's James Clayton sees Clearview in action\n\nIn the past Clearview AI had commercial customers, but since a 2020 settlement in a case brought by US civil liberties campaigners, the firm now only accepts clients who carry out criminal law enforcement or national security functions.\n\nClearview does not have UK or EU clients, but its customers are based in the US and in other countries including Panama, Brazil, Mexico, and the Dominican Republic, Tuesday's judgement revealed.\n\nIn simple terms, Clearview succeeded in appealing against the ICO's fine and enforcement action because it was used solely by law enforcement bodies outside the UK.\n\nThe three-member tribunal at the First-tier Tribunal, which heard the appeal, concluded that although Clearview did carry out data processing related to monitoring the behaviour of people in the UK, the ICO \"did not have jurisdiction\" to take enforcement action or issue a fine.\n\nNo 'blanket permission' for scraping\n\nExplaining the decision James Castro-Edwards, data privacy lawyer from Arnold & Porter told the BBC that, \"Clearview only provided services to non-UK/EU law enforcement or national security bodies and their contractors.\"\n\n\"UK data protection law (UK GDPR) provides that acts of foreign governments fall outside its scope; it is not for one government to seek to bind or control the activities of another sovereign state\".\n\nIn response to the judgement, the ICO said that it would carefully consider next steps but added: \"It is important to note that this judgement does not remove the ICO's ability to act against companies based internationally who process data of people in the UK, particularly businesses scraping data of people in the UK, and instead covers a specific exemption around foreign law enforcement.\"\n\nWill Richmond-Coggan, a data protection partner at law firm Freeths, agreed, arguing that even though the appeal was allowed, the decision underlined that scraping large volumes of publicly available data was an activity to which UK data protection rules could apply.",
            "url": "https://www.bbc.com/news/technology-67133157",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "face",
                "fine",
                "law",
                "overturns",
                "company",
                "enforcement",
                "uk",
                "data",
                "clients",
                "ico",
                "action",
                "privacy",
                "clearview",
                "images",
                "search",
                "ai"
            ],
            "summary": "Face search company Clearview AI overturns UK privacy fineGetty ImagesA company which enables its clients to search a database of billions of images scraped from the internet for matches to a particular face has won an appeal against the UK's privacy watchdog.\nLast year, Clearview AI was fined more than £7.5m by the Information Commissioner's Office (ICO) for unlawfully storing facial images.\nClearview AI offers its clients a system that works like a search engine for faces - users upload a photo and it finds matches in a database of billions of images it has collected.\nIn simple terms, Clearview succeeded in appealing against the ICO's fine and enforcement action because it was used solely by law enforcement bodies outside the UK.\n\"UK data protection law (UK GDPR) provides that acts of foreign governments fall outside its scope; it is not for one government to seek to bind or control the activities of another sovereign state\".",
            "metadata": {
                "source_domain": "www.bbc.com",
                "scrape_date": "2024-10-25T12:40:12.708111",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 3316
            }
        },
        {
            "title": "The Impact of AI on Privacy: Protecting Personal Data",
            "text": "From virtual assistants to self-driving cars, artificial intelligence (AI) has become a part of our daily lives, making things more comfortable and convenient. But as AI technologies continue to advance, they also bring significant privacy risks that could lead to our personal data being compromised if AI is used without proper checks and balances.\n\nPrivacy risks can arise in numerous ways, including data breaches, unauthorized access, misuse of data, intentional or unintentional bias and lack of transparency. Additionally, the pace of AI development is so rapid that regulations often lag behind, leaving companies with little guidance on how to protect personal data. This makes it essential for companies to consider the ethical and legal implications of AI technologies and opens the discussion concerning the importance of accountability, robust implementation of data protection measures, and cybersecurity safeguards.\n\n‍\n\nHow is AI collecting and using personal data?\n\nAs AI software becomes more advanced and intertwined with our lives, the types of personal data that these systems can collect are expanding rapidly. You might not even realize just how much data AI systems are gathering about you as you go about your day.\n\nFor years now, we have provided intelligent software apps via our phones, computers, smart speakers, and virtual assistants with a myriad of knowledge; and the list keeps growing - our biometric data such as fingerprints and faces, internet browsing history, health data, personal and work contact details, financial information, shopping preferences and patterns, our comments, likes, dislikes, and even everyday life events such as birthdays, weddings, and vacations.\n\nOur personal data, comprising various sensitive types, collectively creates a comprehensive profile of our identity and interests, which can be unsettling to some degree as we entrust our information to unpredictable and unregulated entities.\n\n‍\n\nExamples of how AI collects data and process data\n\nAI technologies collect and process an enormous amount of data including personal information, from facial and voice recognition to web activities, and location data. While AI has numerous uses, it also presents several privacy challenges and risks.\n\nSocial media: AI can use highly trained decision-making algorithms on social media platforms, such as Facebook and TikTok, or messaging apps such as Snapchat, to collect and analyze users' behavior, interests, and preferences and to offer highly personalized and targeted content and advertisements. Left unchecked, AI can perpetuate biases, amplify harmful content, and spread manipulated content such as deepfake videos. This can lead to the spread of misinformation, discrimination, and harm to individuals and society.\n\nFacial recognition technology: This technology is used in a wide range of applications, from security to law enforcement, or even marketing, and helps detect the presence and the looks of individuals. AI systems capture images and videos, process them to extract facial features to create digital representations of faces that can be used to generate comparisons, identifications, or verifications. There are privacy concerns associated with the collection, use and processing of this data.\n\nLocation tracking: AI collects location data through GPS, Wi-Fi, and cellular signals for various purposes, including personalization and business needs. However, the dangers of location tracking lie in the potential misuse of this data. For instance, companies could use location data to infer sensitive personal information such as political affiliation, religious beliefs, and other compromising sensitive information that can lead to identity theft or other potential dangers.\n\n‍\n\nWhat are the privacy risks of AI?\n\nAs we delve deeper into the world of artificial intelligence, there is no denying the potential benefits it can bring to our lives. However, as the use of AI becomes more widespread, many experts have raised concerns about AI data privacy risks. Some of which include:\n\nUnintentional bias: AI systems can exhibit bias based on the data on which they are trained. If the data is biased, the AI system will also be biased, leading to unfair or discriminatory outcomes.\n\nInaccurate predictions: AI systems can make inaccurate predictions, which can have serious consequences in fields such as healthcare or finance. For example, if an AI system predicts that a patient is at low risk for a disease when they are actually at high risk, this could result in a missed diagnosis and delayed treatment.\n\nUnauthorized access to personal data: AI systems often require access to personal data in order to function. IIf this data is not properly secured, it can be accessed by unauthorized individuals or organizations. Users should also be aware of options to turn off AI overviews in certain platforms to minimize privacy risks.\n\nUnforeseen consequences: With machine learning becoming more complex, advanced, and automated, there is a risk that unforeseen consequences could arise. For example, an AI system used in a transportation system could inadvertently cause accidents or disruptions.\n\nJob displacement: As AI systems become more capable, there is a growing concern that it may cause an upheaval in the job market by outpacing human training and displacing workers. Unemployment rates may rise, and our economy could face significant disruption as a result.\n\n‍\n\nMitigating Privacy Risks of AI\n\nWhat can companies do to reduce AI privacy risks? A couple of things to consider, they need to implement secure data protection policies that secure customer data. This involves employing strict encryption methods, conducting regular safety checks, and implementing strict access controls to prevent unauthorized access to sensitive data. Additionally, companies need to adopt a privacy built-in approach, ensuring that privacy considerations are baked into the design and development of AI technologies from the beginning.\n\nHere are some other key considerations that should be examined further, and that could use more research, guidance, and points of discussion:\n\n‍\n\nData minimization\n\nData minimization is a critical aspect of ensuring that only relevant data is used by an AI system, preventing it from accessing and processing any misuse of non-essential personal information.\n\n‍\n\nEncryption\n\nCompanies should aim to provide at least one form of encryption defense against malicious sources that aim to steal confidential information that is being processed by AI systems.\n\n‍\n\nTransparent data use policies\n\nDeveloping documentation and policies that clearly state how AI technologies use personal data and manage visibility in google search results. Organizations in general could benefit from open and honest discussions on the distinct roles and goals of using such information. Everyone will have a better understanding of how the technology works, and perhaps help set up the needed best practices for using such data.\n\n‍\n\nAuditing and monitoring AI systems\n\nRegularly making checks and balances to detect any discrepancies due to untrustworthy actions from internal or external sources and making sure this kind of events do not get overlooked.\n\n‍\n\nEthical considerations\n\nTraining AI to avoid biases could possibly be done in several ways. One strategy is to ensure that the data used to train the AI system is diverse and representative of the population it will be serving. This can involve collecting data from different sources and including a broad range of demographic groups. Additionally, AI systems can be designed to be transparent, so that users can understand how the system is making decisions and whether there is any bias present.\n\nAnother approach is to incorporate fairness metrics into the development of AI systems, which can help identify and address any potential biases, although systems like this can still have some issues. Finally, ongoing monitoring and evaluation of AI can help to identify and address any biases that may emerge over time.\n\n‍\n\nThe role of transparency and accountability in developing and deploying AI\n\nArtificial Intelligence technologies have transformed the way businesses operate, offering companies new levels of connectivity, efficiency, and convenience. However, the privacy risks of AI must not be ignored. As AI technologies become more advanced, so do the privacy risks they pose. Organizations must take a proactive approach to reduce these emerging privacy challenges and risks, implementing secure data protection principles, privacy-by-design architecture, and ethical considerations.\n\nAdditionally, complying with privacy regulations such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA), companies can establish comprehensive privacy policies that outline practices for handling personal data, including the right to access, correct, and delete personal data.\n\nUltimately, safeguarding personal data from AI privacy challenges should be a top priority for companies today. With AI applications becoming increasingly abundant, taking the necessary steps to protect user data is essential for any business that wants to remain competitive in the digital future.\n\n‍\n\nHow Velaro is addressing privacy challenges posed by AI systems to protect personal data\n\nAs a company providing AI-powered customer engagement solutions, at Velaro we recognize and understand the importance of protecting personal data from misuse. To ensure privacy and security, we take several steps to protect personal data, such as implementing strict data access controls, robust encryption methods, and regular security audits. We also conduct comprehensive data protection impact assessments to identify and mitigate potential privacy risks associated with our AI systems.\n\n‍\n\nDon't let privacy risks hold you back from implementing AI in your business. Contact us to discuss our solutions for protecting personal data.",
            "url": "https://velaro.com/blog/the-privacy-paradox-of-ai-emerging-challenges-on-personal-data#:~:text=But%20as%20AI%20technologies%20continue,without%20proper%20checks%20and%20balances.",
            "authors": [
                "Andrea Granados"
            ],
            "publish_date": null,
            "keywords": [
                "systems",
                "system",
                "personal",
                "data",
                "technologies",
                "information",
                "impact",
                "privacy",
                "risks",
                "companies",
                "protecting",
                "ai"
            ],
            "summary": "However, as the use of AI becomes more widespread, many experts have raised concerns about AI data privacy risks.\nUnauthorized access to personal data: AI systems often require access to personal data in order to function.\n‍Mitigating Privacy Risks of AIWhat can companies do to reduce AI privacy risks?\n‍Transparent data use policiesDeveloping documentation and policies that clearly state how AI technologies use personal data and manage visibility in google search results.\nWe also conduct comprehensive data protection impact assessments to identify and mitigate potential privacy risks associated with our AI systems.",
            "metadata": {
                "source_domain": "velaro.com",
                "scrape_date": "2024-10-25T12:40:12.835188",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 10002
            }
        },
        {
            "title": "Exposing the secretive company at the forefront of facial recognition technology",
            "text": "Exposing the secretive company at the forefront of facial recognition technology\n\nNYT reporter Kashmir Hill says Clearview AI has a database of billions of photos scraped from the internet, which it sells to governments and police departments. Her book is Your Face Belongs To Us.\n\nTERRY GROSS, HOST:\n\nThis is FRESH AIR. I'm Terry Gross. Facial recognition technology is convenient when you use it to unlock your phone or log into an app. But you might be surprised to know that your face is most likely already in a facial recognition database that can be used to identify who you are without you even being aware it's happening or knowing who's using it and why.\n\nA company expanding the technological possibilities of this technology and testing its legal and ethical limits is Clearview AI. It's a startup whose clients already include some law enforcement and government agencies. If you haven't already heard of it, it's in part because the company didn't want you to know it existed. It did its best to remain secretive until it was exposed by my guest, Kashmir Hill. She's a New York Times tech reporter who first wrote about Clearview AI in 2020. She describes her beat as the future tech dystopia and how we can try to avoid it. Kashmir has continued to report on Clearview AI and other developments in facial recognition technology. Now, she has a new book called \"Your Face Belongs To Us: A Secretive Startup's Quest To End Privacy As We Know It.\"\n\nKashmir Hill, welcome to FRESH AIR. Tell us what the Clearview AI facial recognition technology is capable of doing.\n\nKASHMIR HILL: So the way it works is that you upload someone's face - a photo of someone - to the Clearview AI app, and then it will return to you all the places on the internet where that person's face has appeared, along with links to those photos.\n\nGROSS: So we're talking about anything that's on the internet - your photos on social media.\n\nHILL: It could lead to your Facebook profile, your Instagram account, your Venmo account, your LinkedIn profile, reveal your name, you know, possibly where you live, who your friends are. And it may well reveal photos that you didn't realize were on the internet, maybe some photos you didn't want to be there.\n\nGROSS: And you'll talk about photos you didn't know they have on you a little bit later. So let's talk about some of the nightmare scenarios that Clearview's facial recognition technology might create.\n\nHILL: So let's think about the worst-case scenarios for facial recognition technology. Some of the sensitive uses that I think about are, you know, a woman who is walking out of a Planned Parenthood and there are protesters outside, and they look at her face, take her photo, find out her identity, make assumptions that she had an abortion and, you know, write about her online or...\n\nGROSS: Mentioning her name.\n\nHILL: ...Harass her right there in the moment. Or if you are at a bar and you are talking to somebody and decide that they are creepy and you never want to talk to them again, they could take your photo and learn who you are, learn where you live, have all this information about you.\n\nFor police use of this technology, you know, it can be very useful for solving crimes, but, you know, it can also be wielded in a way that could be very chilling or intimidating. Say, if there are protesters against police brutality and the government is able to very easily identify them. And we have seen this already happen in other countries, not with Clearview AI's technology but with other facial recognition technology. In China, you know, this kind of technology has been used to identify protesters in Hong Kong, to identify Uyghur Muslims and for more surprising uses like naming and shaming people who wear pajamas in public or making sure that somebody in a public restroom doesn't take too much toilet paper. They have to look at a face recognition camera, only get a little bit of toilet paper and then wait a certain amount of time until their face can unlock more.\n\nGROSS: Who would have ever thought of that? (Laughter) OK, so in the U.S., who has this Clearview facial recognition technology now? And are there restrictions on who can use it?\n\nHILL: So in the U.S. right now, I mean, Clearview AI has been used by thousands of police departments, according to Clearview AI. And it has come up in public records requests. A lot of local journalists have done reporting on their local departments using it. They have a contract with the Department of Homeland Security, they have a contract with the FBI and they have received funding from both the Army and the Air Force.\n\nGROSS: So what would they use it for in the military?\n\nHILL: Well, in the military, you can imagine this being very useful for identifying strangers around military bases, you know, in cities that we're in. Clearview AI has actually given their technology for free to Ukraine to use in its war with Russia. And the Ukrainians say that they have used it to, you know, identify Russian spies who are trying to blend in with the population and they're able to search their face and see their - you know, their social media profiles that link them to Russia that show them in their military uniforms.\n\nUkraine has also used Clearview AI to identify the corpses of Russian soldiers, soldiers who have been killed, and to find their identities, to find their social media profiles. And they have then sent those photos to their loved ones, you know, to a wife, to a mother, to a boyfriend, to a sister, to a brother, to say, look, this is your loved one. They are dead. And it was a way to try to turn the tide of public opinion in Russia against the war, to show them the toll. But a lot of people who saw that use thought it was just an incredibly, you know, chilling and disturbing use of the - of this kind of technology and more.\n\nGROSS: There are U.S. government agencies using this technology, too, right?\n\nHILL: Yes. I mean, we have some limited look at how every single agency uses the technology. So I talked to a Department of Homeland Security officer who has used Clearview AI, and he told me about a specific case in which he used it. And it was a case of child sexual abuse. He had an image that had been found in a foreign user's account in Syria, and they didn't know exactly, you know, who the abuser was or who the child was or even where this photo was taken. They were able to determine that it was in the U.S. kind of based on essentially electrical outlets.\n\nAnd so he used Clearview AI to search the face of the abuser and it ended up having a hit on Instagram. And it was a photo where this man appeared in the background of someone else's photo. He was - it was a photo at kind of a bodybuilding convention in Las Vegas. And this man was standing behind a workout supplements counter. And this was the breadcrumb that the DHS officer needed to find out who he was. He ended up calling the workout supplements company, you know, asking them if they knew the man. And eventually, they located him in Las Vegas and arrested him. And so it was really - you could kind of see the power of a technology like this in officers' hands.\n\nGROSS: All right. Let's take a short break here, and then we'll talk some more. If you're just joining us, my guest is Kashmir Hill. She's a tech reporter for The New York Times and author of the new book, \"Your Face Belongs To Us: A Secretive Startup's Quest To End Privacy As We Know It.\" We'll be right back after a short break. This is FRESH AIR.\n\n(SOUNDBITE OF ALEXANDRE DESPLAT'S \"SPY MEETING\")\n\nGROSS: This is FRESH AIR. Let's get back to my interview with New York Times tech reporter Kashmir Hill. Her new book is called \"Your Face Belongs to Us: A Secretive Startup's Quest To End Privacy As We Know It.\" The company she investigates, Clearview AI, has developed state-of-the-art facial recognition technology that's already being used by many law enforcement agencies, as well as some government agencies. It's been used to identify criminals, including child predators. But it's also made mistakes, which have had consequences for the wrongly accused. Here's an example.\n\nHILL: Randall Reed is a man who lives in Atlanta. He's a Black man. He was driving to his mother's house the day after Thanksgiving, and he gets pulled over by a number of police officers. There was something like four police cars that pulled him over. And they get him out of the car, they start arresting him, and he has no idea why or what's going on. And they say you're under arrest. There's a warrant out for you in Louisiana for larceny. And he is bewildered. He says, I've never been to Louisiana.\n\nAnd it turns out there was a crime committed there, a gang of people who were buying designer purses, very expensive designer purses, from consignment stores in and around New Orleans using a stolen credit card. And they ran a surveillance still of these men, and one of them matched to Randall Reed's face. And Randall Reed ends up being held in jail in Atlanta for a week while they're waiting to extradite him. And he has to hire lawyers in Georgia, hire a lawyer in New Orleans.\n\nAnd the lawyer in New Orleans was able to, by basically going to one of these stores and asking for the surveillance footage - to realize that, oh, wow, this suspect actually looks a lot like my client. And this detective ends up telling him that, yes, facial recognition was used. And so Randall Reed basically takes a bunch of photos of his face and a video of his face and sends that to the police, and then the charges end up being dropped.\n\nBut this was - I mean, this is incredibly traumatic. And in this case, Clearview AI was the technology that was used to identify him. And that is one of the huge problems about the use of Clearview AI is, you know, if police are using this to solve basically a shoplifting crime, they're doing that by searching this database of millions of people. You know, Clearview says that there are 30 billion faces in its database. And so this is a question that activists are asking, you know? Should we all, all of us who are in that database, be in the lineup any time a small crime is committed in a local jurisdiction?\n\nGROSS: You write that of the people who are falsely accused based on faulty recognition technology, the majority of them are people of color and that the algorithms have more trouble correctly identifying people of color than they do identifying white people, building in what is already a racial bias in the criminal justice system. Can you explain, without getting very technical, why these algorithms have more trouble identifying people of color?\n\nHILL: Yeah, I mean, this is a complicated issue. So facial recognition technology for a very long time had serious bias issues. And the reason was basically that the people working on facial recognition technology tended to be white men, and they were making sure that it worked on them. And they were using photos of white men to kind of train the AI. And the way that these systems learn - and this is the case for kind of everything from facial recognition technology to tools like ChatGPT - is that you give a computer a lot of data, and it gets very good at identifying patterns.\n\nAnd so if you give that computer, you know, only photos of white men or mostly photos of white men, or mostly photos of white people or mostly photos of men, it gets better at identifying those people. And so, yes, this was a problem for a very long time. And there were researchers like Joy Buolamwini who pointed out that this was flawed, that it didn't work as well on darker faces, on women, on children, on older people. And that criticism was heard by the facial recognition technology industry, and they have improved these system. They have gotten more diverse faces to train the AI, and it has improved.\n\nAnd there have been a lot of questions raised about how they got that data. I mean, part of it is that they just turn to all of the photos of ourselves that we and others have posted on the internet. In one case, Google actually hired a contractor to go out and try to get, basically, photos of Black people. And they targeted homeless people and students. A Chinese company at one point basically offered their technology for free in Africa so that they could collect darker faces to help train their algorithms.\n\nBut the technology has improved a lot since its early days when it was really, you know, quite flawed. But obviously, we are still seeing racist outcomes. Of the handful of people we know to have been wrongfully arrested for the crime of looking like someone else, in every case, the person has been Black.\n\nGROSS: So still in my mind is that you said that Clearview AI has 30 billion faces in its database.\n\nHILL: Yes, and that's many more faces than people who live on the planet. So for many individuals, there's going to be many different versions of your face. The CEO...\n\nGROSS: Oh, I see.\n\nHILL: Yeah.\n\nGROSS: So it's, like, different photos of you counted in that?\n\nHILL: Yeah. So the CEO has run searches on me. And, you know, the - I can't remember the last number, but I think it was something like there were 160 different photos of me on the internet that it was pulling up.\n\nGROSS: So Clearview AI, in developing its facial recognition technology, is responsible for technological breakthroughs, but it's also leading to a lot of questions legally and ethically about, where are the boundaries here? Is there a way to say stop when things go too far, and what is that place? You write about how Google and Facebook and maybe some other companies had developed facial recognition technology earlier but didn't want to release it. They thought it was too dangerous, so they didn't make it available. Can you expand on that for us?\n\nHILL: This was a really surprising finding for me. You know, when I first got wind of Clearview AI in the fall of 2019 and started talking to experts, people were shocked that this company came out of nowhere and built this radical tool unlike anything, you know, released by the big technology giants or even by the U.S. government. And everyone thought that it was something they had done technologically. But what I found since then in working on the book is that actually Google had talked about developing something like this as early as 2011, and its then chairman, Eric Schmidt, said that it was the one technology that Google built but decided to hold back. And that was because they were worried about the dangerous ways it could be used by, say, a dictator to control his or her citizens.\n\nAnd I discovered that Facebook too developed something like this. I actually got to watch this video of engineers who work there in this conference room in Menlo Park. And they had rigged up a smartphone on the brim of a baseball cap. And when the guy who was wearing it turned to look at somebody, the smartphone would call out the name of the person he was looking at. But Facebook to decide to hold it back. And that is, you know, pretty surprising from Google and Facebook. They are such boundary pushing companies. They have really changed our notions of privacy. But they both felt that they didn't want to be first with this technology, that it was unethical, potentially illegal.\n\nBut Clearview, you know, didn't have those same concerns. It was this new radical startup, a very unusual background, and it just wanted to make its mark on the world. And the building blocks were there for them to do this. You know, countless photos of people on the internet that are not very well protected against the kind of scraping or mass downloading that Clearview did. And then these facial recognition algorithms that are just easier to develop now if you have some technical savvy because the open source - what's called the open source community around these technologies has kind of shared them online. And so what Clearview did was just what others weren't willing to do. I call it ethical arbitrage in the book. And what is so alarming about that is it means that there will be other Clearview AIs and there already are.\n\nGROSS: Well, a paradox here is that although Google and Facebook developed facial recognition technology, they decided it was too potentially dangerous and withheld it from public use. However, hasn't Clearview AI harvested faces through Google and from Facebook?\n\nHILL: Clearview AI has scraped photos from millions of websites, including Instagram, Facebook, LinkedIn, Venmo, YouTube. Yes, you know, it has taken photos from these companies, some of these companies like Facebook especially who convinced us to put our photos online alongside our faces. They did offer the building blocks that that Clearview AI has used. And, you know, after I reported what Clearview AI had done, many of these companies sent cease-and-desist letters to Clearview AI saying stop scraping our sites and delete the photos that you collected from our sites and, you know, said it violates our terms of service. But then they didn't do anything else besides send those letters. There hasn't been a lawsuit against Clearview AI. And as far as I know, as I understand, Clearview AI has not deleted any of those photos. And I think it's continuing to scrape those sites.\n\nGROSS: It's time to take another break, so let me reintroduce you. If you're just joining us, my guest is Kashmir Hill. She's a tech reporter for The New York Times and author of the new book, \"Your Face Belongs to Us: A Secretive Startup's Quest To End Privacy As We Know It.\" We'll be right back after we take a short break. I'm Terry Gross, and this is FRESH AIR.\n\n(SOUNDBITE OF MUSIC)\n\nGROSS: This is FRESH AIR. I'm Terry Gross. Let's get back to my interview with Kashmir Hill, author of the new book \"Your Face Belongs to Us: A Secretive Startup's Quest To End Privacy As We Know It.\" It's about a company called Clearview AI that's expanding the technological possibilities of facial recognition technology and testing its legal and ethical limits. It's a startup whose clients already include some law enforcement agencies and government agencies. She exposed them. It had been a very secretive company. She exposed them in a 2020 article for The New York Times.\n\nHow has this affected your use of social media and putting your picture online? They already have your photos, but still.\n\nHILL: So I think a lot of people get hopeless about privacy or feel like, what can I do to protect myself? I do think that people can make choices that will protect them, but it's also a societal responsibility. So for me personally, I am a fairly public person. I have many photos on the internet. But when I post photos of my children, for example, I tend to do so privately on, you know, a private - you know, privately on Instagram, just for friends and family. Or I text photos, you know, share with my friends. I am much more private about their images knowing that this technology is out there.\n\nIt is also the case that people can get themselves, in some places, taken out of these databases, so that is advice that I give people, you know? It's not just a matter of being careful what you post. If you live in certain states that protect your face better, you can go to Clearview AI and ask for access to the information they have on you and ask them to delete it. There are privacy laws that give you those rights in California, Connecticut, Virginia, Colorado.\n\nAnd so, yeah, if you're a citizen of one of those states, if you're a resident of one of those states, you can get out of Clearview AI's database. And that is a kind of hopeful part of this book, is that we don't have to just give in to the whims of technology and what it's capable of. We can constrain what's possible with a legal framework, you know? We can pass privacy laws and enforce them, and that will help protect us against what is now becoming possible with technology.\n\nGROSS: You know, a lot of us already use facial recognition technology in our private lives, like, to use it to unlock your phone or log on to an app. Do you use it? Like, what are your thoughts about that in terms of what you're exposing yourself to, if anything?\n\nHILL: Yeah, I mean, people think that because I'm a privacy reporter, I must be a complete - I must have everything on lockdown. But I am a normal person who lives my life in normal ways. It's part of how I get ideas for stories, is just seeing how we interact with the world and what happens when my information is out there. So you know, I do unlock my phone with my face.\n\nWhen I was traveling to do research for this book, I went to London because they have police vans there, these mobile vans that they send out with facial recognition cameras on the roof to scan crowds and pick up wanted people off the streets. And so I really wanted to go there and have that part of what's happening with facial recognition technology in the book. And when I got to Heathrow Airport, rather than having to wait for hours in line, you know, for a customs agent to look at my passport, I just put it on a little scanner bed, looked into a camera - and there is a biometric chip on your passport that has your face print - and it matched me to the passport and just let me right in.\n\nI mean, there are many beneficial uses of facial recognition technology, and it's part of why I wanted to write this book, because I wanted people to understand it doesn't need to be an all or nothing situation. I hope that we can harness the beneficial uses of facial recognition technology that are convenient to us, that make our lives better, without having to embrace this completely dystopian, you know, world in which facial recognition technology is running all the time on all the cameras, on everybody's phone. And anywhere you go, people can know who you are and, you know, have it just end anonymity as we know it.\n\nGROSS: That's a chilling thought. Let's talk about how you first found out about Clearview AI, because it had been doing everything in its power to prevent the public from knowing about it. How did you first find out it existed?\n\nHILL: So I got a tip in the fall of 2019 from a public records researcher who had been looking into, you know, what types of facial recognition technology police were using, you know, which companies, how much they were paying for it. And he had gotten this 26-page PDF from the Atlanta Police Department. And it included this company that he hadn't heard of before - there wasn't much online - called Clearview AI that claimed that it had scraped billions of photos from the internet, including social media sites, and that it was selling it to hundreds of law enforcement agencies.\n\nAnd there was a really surprising, privileged and confidential legal memo that the Atlanta Police Department turned over written by Paul Clement, who is - used to be one of the top lawyers in the country. He was the solicitor general under George W. Bush. He had written this memo for police to reassure them that they could use Clearview AI without breaking the law. And this just caught my attention right away. And I started digging in. And, you know, the more I dug, the stranger this company seemed.\n\nGROSS: Well, you couldn't find their office. You couldn't find anyone to talk with. What were some of the obstacles you ran into?\n\nHILL: So...\n\nGROSS: I mean, you found their address, but you couldn't find a building.\n\nHILL: Yeah. So one of the strangest things was, you know, they had a very basic website. And it just described what they were doing as artificial intelligence for a better world. And there was an office address there. And it happened to be just a few blocks away from The New York Times. And so I mapped on Google Maps, I walked over, and I got to where it was supposed to be and the building did not exist. And that was very strange to me.\n\nI also looked them up, you know, on the internet. And they had only one employee on LinkedIn. His name was John Good. He only had two connections on the site. It definitely looked like a fake person. You know, I reached out to that John Good and never got a response. You know, I called everyone I could find that seemed to have some connection to the company. No one would call me back. And so then I turned to police officers, trying to find people using the app, and that's where I had success. I talked to officers who had used it. They said it was incredible. It worked like nothing they had ever used before.\n\nBut through the process of talking to police officers, I discovered that Clearview AI was tracking me, that they had put an alert on my face. And every time one of these officers uploaded my photo to try to show me what the results were like, they were getting a call from Clearview AI and being told to stop talking to me. And Clearview AI actually blocked my face for a while from having any results. And that was very chilling to me because I realized, well, one, this company is - has this power to see who law enforcement is looking for, and they're using it on me, and also that they had the ability to control whether or not a person could be found.\n\nGROSS: Yeah. But you were able to see what pictures they had of you. And they had photos of you that you didn't know existed, including photos where you're, like, buried in the background. But it was still able to identify that photo as you. Tell us about some of the most surprising photos that were harvested.\n\nHILL: Yeah. So eventually the company did talk to me. They hired a very seasoned crisis communications consultant. And so I was able to meet Hoan Ton-That, who is the technical co-founder of Clearview AI. And he has since run my face through the app, you know, several times. And in one case, it brought up this photo that I recognized as being taken in Washington, D.C. And there's - you know, there's somebody in the foreground and somebody on the sidewalk in the background walking by. And I was looking at the photo, and I didn't immediately see me until I recognized that the person in profile in the background of the photo was wearing a coat that I bought in - at an American vintage store in Tokyo many, many years ago. And so I realized, wow, that's me. I can even recognize myself with my human eyes that that's me. But this - you know, this algorithm is able to find me.\n\nThere was a photo on the internet of somebody I had been talking to for a story, and that made me realize I may need to be much more careful with sensitive sources out in public if something like this is - becomes more ubiquitous because I won't anymore be able to trust necessarily that if I leave my, you know, phone at home and meet them at a dive bar - that someone can't make the connection between us. So, yeah, it was just very surprising. I even, at one point, covered my mouth and nose, you know, the way that you would with a COVID mask. And even then, Hoan Ton-That was still able to take a photo of me and bring up other photos of me. It really is astounding how far this technology has come from its early days, when it was very buggy and didn't work very well.\n\nGROSS: So it can identify you even if you're wearing a mask. That's remarkable. Have you tried to get your own face removed from Clearview AI's database?\n\nHILL: Well, unfortunately, I am a resident of New York, and so I do not have the privacy protections that other people in the U.S. or people outside of the U.S. have. So I can't get Clearview AI to delete the photos of me.\n\nGROSS: Oh, so it's only people in other countries who have that ability.\n\nHILL: So people in Europe have this ability. And then there are states in this country that have privacy laws that give them the right to access and delete information that companies have on them. So if you live in California, Colorado, Virginia or Connecticut, you can go to Clearview AI and get your information deleted. And if you're in Illinois, you're protected by an extra special law that specifically protects your face. But the rest of us are out of luck.\n\nGROSS: Let me reintroduce you. If you're just joining us, my guest is New York Times tech reporter Kashmir Hill. She's the author of the new book \"Your Face Belongs To Us: A Secretive Startup's Quest to End Privacy As We Know It.\" It's about facial recognition technology and the company Clearview AI. We'll be right back. This is FRESH AIR.\n\n(SOUNDBITE OF THE WEE TRIO'S \"LOLA\")\n\nGROSS: This is FRESH AIR. Let's get back to my interview with Kashmir Hill. She's a New York Times tech reporter and author of the new book \"Your Face Belongs To Us: A Secretive Startup's Quest To End Privacy As We Know It.\" It's about the company Clearview AI and its quest to develop facial recognition technology and all the successes it's had and all the failures it's had so far, how it's testing the ethical and legal limits of use of this technology.\n\nYou know, we talked about how law enforcement agencies, some government agencies, the military is using or is interested in using this technology from this company. What about private corporations? Are any of them using it?\n\nHILL: So Clearview AI, when they were first pitching this technology, did want private corporations to use it. They were pitching it to grocery stores and hotels and real estate buildings. One of the people they pitched, actually, was John Catsimatidis, who's a businessman in New York, has run for mayor there, owns the Gristedes grocery stores. And part of their pitch was that they would give the app actually to potential investors and to these businesspeople. And so John Catsimatidis told me they thought about using it. They had a lot of Haagen-Dazs thieves at his stores at the time, and so they tested it. They didn't ultimately install Clearview AI's Technology. But he himself loved having the app on his phone, and he told me about how he used it one time when his daughter walked into an Italian restaurant when he was dining there and she was with a date he didn't recognize. And so he had a waiter take a picture of the couple so he could identify who the man was, which I thought was a really, really shocking use.\n\nSo Clearview AI has agreed not to sell its database to companies and to only sell it to police agencies. But there are other facial recognition technologies out there. And I think the most notable example of this is Madison Square Garden, the big events venue in New York City. They own Radio City Music Hall and the Beacon Theater, and they installed facial recognition technology a few years ago to keep out security threats. But in the last year, the owner, James Dolan, decided that he wanted to use the technology to keep out his enemies - namely lawyers who worked for firms that had sued him. And so Madison Square Garden ended up making a list of these 90 firms that had lawsuits against it, scraping the lawyers' photos from their own websites and creating a face ban on these people so that when they tried to go to a Knicks game or Rangers game or a Mariah Carey concert, they get turned away at the door, and they're told, sorry, you're not welcome here until you drop your suit against us.\n\nAnd yeah, I mean, it's a really incredible deployment of this technology and shows how chilling the uses could be, that you might be, you know, turned away from a company because of where you work, because maybe - I could imagine a future in which a company turns you away because you wrote a bad Yelp review or they don't like your political leanings.\n\nGROSS: You went with a lawyer who is on the banned list of Madison Square Garden to see if the technology actually prevented her from getting in. And it did. It worked.\n\nHILL: Yeah. It was incredible. I mean, we - so I went with her. I can't remember if it was a Rangers game or a Knicks game, but I bought our tickets, so it was not under her name, not, you know, associated with her in any conceivable way. And we walked through the door to the stadium and put our purses - our bags down on, you know, the security belt, walked through the metal detector, and a security guard immediately walked up to her. And he asked for her ID, she showed it. And he said, you know, you're going to have to stand here for a moment. My manager's coming over. And he came over and he said, hey, you work for this firm. You know, you're not allowed to come into the stadium. And she said, well, I'm not working on the case, you know, against your company. It's other lawyers in my firm. He says it doesn't matter. Everybody from your firm is banned. He gave her a note and kicked us out. And I mean, it happened, you know, within a minute of our walking through the door.\n\nGROSS: Let's take another break here, and then we'll talk some more. If you're just joining us, my guest is Kashmir Hill, a tech reporter for The New York Times and author of the book \"Your Face Belongs To Us.\" We'll be right back after we take a short break. This is FRESH AIR.\n\n(SOUNDBITE OF THE MIDNIGHT HOUR'S \"BETTER ENDEAVOR\")\n\nGROSS: This is FRESH AIR. Let's get back to my interview with Kashmir Hill. She's a tech reporter for The New York Times and author of the new book, \"Your Face Belongs To Us: A Secretive Startup's Quest To End Privacy As We Know It.\" The startup referred to in the title is Clearview AI, and it's a company that has advanced facial recognition technology. And it's raised a lot of questions about the ethical and legal limits of this technology.\n\nLet's talk a little bit about the founder of Clearview AI, and the CEO, Hoan Ton-That. Part of his background was that he was a MAGA supporter. What are his connections to Donald Trump and to the far right?\n\nHILL: Yeah. So Hoan Ton-That, he grew up in Australia. He dropped out of college at 19, moved to San Francisco and he was actually kind of part of a liberal crowd when he lived in San Francisco. And grew his hair long, was a musician, hung out with artists. But then around 2015, he moved to New York, and this seemed to be a time when his politics really shifted. He would later tell me that he was radicalized by the internet, but he started following a lot of people on the far right, you know, Milo Yiannopoulos, Breitbart writers. He started hanging out with a guy named Charles Johnson, known as Chuck Johnson on the internet, who is very much a conservative provocateur, ran a very conservative news site that did what a lot of people described as race baiting.\n\nAnd Hoan Ton-That and Charles Johnson decided to go to the Republican National Convention together in 2016, where Trump was being anointed the candidate. And yeah, they were very much all in on Trump. And while they were there, they actually met with Peter Thiel, who, you know, was a big Trump supporter, and he was speaking at the convention. Peter Thiel would later become their first investor in Clearview AI before it was even called Clearview AI, when it was called Smart Checker. But that is where the company started. It did start very much within conservative circles in politics.\n\nGROSS: What does that tell you, if anything, about how Clearview AI is using facial recognition technology? I mean, one of the fears is that, like, authoritarian governments could use this for nefarious purposes. And Trump, who the founders of the company - or at least most of the founders of the company - supported, he definitely has authoritarian tendencies.\n\nHILL: I mean, one of the first ways that Clearview AI was used before it was called that - it was still called Smart Checker at the time - was at the DeploraBall, which was this event in D.C. when Trump was becoming president. And Hoan Ton-That, you know, later said in documents about it that they had used the technology to keep anti-fascists - antifa - from being able to get into this event. And they revealed that in a pitch they made to the Hungarian government. They were trying to sell their tool for border security. And, you know, Hungary, I think many would describe as an authoritarian government. And they said that they had fine-tuned the technology so that it could be used to identify people who are affiliated with George Soros and the Open Foundations Society. So specifically, they were trying to sell the technology to an authoritarian government to try to identify and keep out people that are affiliated with kind of civil liberties. So it was very disturbing.\n\nBut now Hoan Ton-That says that, you know, he is apolitical. He kind of says he doesn't hold those old views anymore. And, in fact, Clearview AI was used on January 6 when rioters stormed the Capitol. The FBI had photos of all these people because many of them were filming themselves on social media and posting photos online, and they weren't wearing masks. And so many police departments started running their photos through Clearview AI to identify them.\n\nGROSS: You know, I can't help but wonder. Even if this technology is regulated, what's the likelihood it's going to escape into the wild anyway? And what I'm thinking of specifically is we write about - I think it was a potential investor who was given this technology so he could better understand it, and he let his daughter play with it, and she played with it with her friends. So, like, if a potential investor in the company who has been pitched all about it and knows what the boundaries are supposed to be lets his daughter use it and share it with friends, what does that say about the potential of this, just no matter how controlled it is, getting out into hands it's not supposed to be in?\n\nHILL: So Clearview AI, yes, in its early days was used by, yeah, all of these investors, even celebrities were using the technology. Joe Montana at one point emailed Hoan Ton-That because he wanted access to help him remember people's names when he met them. The thing is - so Clearview AI, because of all the blowback, because it has faced such public scrutiny, is limiting its technology to police and security use. But, you know, as we were talking about earlier, there are other people who can do what Clearview AI has done and they have. There is a public face search engine right now called PimEyes, and it does not have as robust a database as Clearview AI. It hasn't scraped as many sites, hasn't scraped social media sites. It hasn't accumulated as many photos.\n\nBut yeah, I mean, I could upload your face right now to PimEyes, and I would get results. I would get photos of you potentially, along with links to where they appear. And, you know, I have run PimEyes on myself. It pulls up many photos of me, not as many as Clearview AI. I ran it on my then-5-year-old daughter and had a hit, something I'd forgotten, a photo of her on the internet. PimEyes does let you ask for results to be removed. I did for my own daughter. I mean, the cat is very much getting out of the bag, and it's part of why I wrote this book right now is because we need to figure out what we want or this will become very widespread.\n\nGROSS: Kashmir Hill, thank you so much for your reporting and your new book. I hope this isn't really the end of privacy as we know it, but... (laughter).\n\nHILL: Thank you, Terry. And I do think there is hope for privacy.\n\nGROSS: Oh, good to hear. OK. Thanks so much.\n\nKashmir Hill is a tech reporter for The New York Times and author of the new book \"Your Face Belongs To Us.\" If you'd like to catch up on FRESH AIR interviews you missed, like our interviews with Leslie Jones, who has a new memoir, or Kerry Washington, who has a new one too, or songwriter, singer and musician Allison Russell, check out our podcast. You'll find lots of FRESH AIR interviews. And if you haven't already subscribed to our free newsletter, give it a shot. It will give you something enjoyable to read about our show and the people who produce it. You'll get it in your mailbox every Saturday morning. You can subscribe at whyy.org/freshair.\n\nFRESH AIR's executive producer is Danny Miller. Our technical director and engineer is Audrey Bentham. Our interviews and reviews are produced and edited by Amy Salit, Phyllis Myers, Roberta Shorrock, Ann Marie Baldonado, Sam Briger, Lauren Krenzel, Heidi Saman, Therese Madden, Seth Kelley and Susan Nyakuindi. Our digital media producer is Molly Seavy-Nesper. Thea Chaloner directed today's show. Our co-host is Tonya Mosley. I'm Terry Gross.\n\nCopyright © 2023 NPR. All rights reserved. Visit our website terms of use and permissions pages at www.npr.org for further information.\n\nNPR transcripts are created on a rush deadline by an NPR contractor. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of NPR’s programming is the audio record.",
            "url": "https://www.npr.org/2023/09/28/1202310781/exposing-the-secretive-company-at-the-forefront-of-facial-recognition-technology",
            "authors": [
                "Terry Gross"
            ],
            "publish_date": "2023-09-28T00:00:00",
            "keywords": [
                "face",
                "exposing",
                "know",
                "technology",
                "company",
                "used",
                "secretive",
                "facial",
                "forefront",
                "photos",
                "ai",
                "clearview",
                "recognition"
            ],
            "summary": "Facial recognition technology is convenient when you use it to unlock your phone or log into an app.\nTell us what the Clearview AI facial recognition technology is capable of doing.\nAnd we have seen this already happen in other countries, not with Clearview AI's technology but with other facial recognition technology.\n(Laughter) OK, so in the U.S., who has this Clearview facial recognition technology now?\nAnd that criticism was heard by the facial recognition technology industry, and they have improved these system.",
            "metadata": {
                "source_domain": "www.npr.org",
                "scrape_date": "2024-10-25T12:40:13.219844",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 40735
            }
        },
        {
            "title": "IAPP",
            "text": "{\"text\": \"You need to enable JavaScript to run this app.\"}",
            "url": "https://iapp.org/news/b/opc-finds-rcmps-use-of-clearview-ai-violates-privacy-act",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "iapp"
            ],
            "summary": "",
            "metadata": {
                "source_domain": "iapp.org",
                "scrape_date": "2024-10-25T12:40:13.015402",
                "content_type": "news_articles",
                "extraction_method": "trafilatura",
                "content_length": 0
            }
        },
        {
            "title": "The walls are closing in on Clearview AI",
            "text": "The ICO found that Clearview AI had been in breach of data protection laws, collected personal data without people’s consent, and asked for additional information, such as photos, when people asked if they were in the database. It found that this may have “acted as a disincentive” for people who objected to their data being scraped.\n\n“The company not only enables identification of those people, but effectively monitors their behaviour and offers it as a commercial service. That is unacceptable,” said John Edwards, the UK’s information commissioner, in a statement.\n\nClearview AI boasts one of the world’s largest databases of people’s faces, with 20 billion images that it has scraped off the internet from publicly available sources, such as social media, without their consent. Clients such as police departments pay for access to the database to look for matches.\n\nData protection authorities around the Western world have found this to be a clear violation of privacy and are now beginning to work together to clamp down. Edwards stressed that “international cooperation is essential to protect people’s privacy rights in 2022” and is due to meet with European regulators in Brussels this week. The UK’s investigation into Clearview AI was carried out jointly with the Australian information commissioner.",
            "url": "https://www.technologyreview.com/2022/05/24/1052653/clearview-ai-data-privacy-uk/",
            "authors": [
                "Melissa Heikkilä"
            ],
            "publish_date": "2022-05-24T00:00:00",
            "keywords": [
                "protection",
                "closing",
                "privacy",
                "edwards",
                "walls",
                "information",
                "data",
                "consent",
                "ai",
                "uks",
                "clearview",
                "peoples",
                "database"
            ],
            "summary": "The ICO found that Clearview AI had been in breach of data protection laws, collected personal data without people’s consent, and asked for additional information, such as photos, when people asked if they were in the database.\nThat is unacceptable,” said John Edwards, the UK’s information commissioner, in a statement.\nData protection authorities around the Western world have found this to be a clear violation of privacy and are now beginning to work together to clamp down.\nEdwards stressed that “international cooperation is essential to protect people’s privacy rights in 2022” and is due to meet with European regulators in Brussels this week.\nThe UK’s investigation into Clearview AI was carried out jointly with the Australian information commissioner.",
            "metadata": {
                "source_domain": "www.technologyreview.com",
                "scrape_date": "2024-10-25T12:40:14.468300",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 1315
            }
        },
        {
            "title": "RCMP's use of facial recognition tech violated privacy laws, investigation finds",
            "text": "The RCMP's use of a controversial, third-party facial recognition technology was a serious violation of Canada's privacy laws, the privacy commissioner says.\n\nPrivacy Commissioner Daniel Therrien tabled a report to Parliament this morning after investigating the national police force's use of software from U.S.-based Clearview AI.\n\nHe concluded that by using this software, the RCMP violated the section of the Privacy Act that says that no personal information can be collected by a government institution \"unless it relates directly to an operating program or activity of the institution.\"\n\n\"The use of facial recognition technology by the RCMP to search through massive repositories of Canadians who are innocent of any suspicion of crime presents a serious violation of privacy,\" Therrien said in the report.\n\n\"A government institution cannot collect personal information from a third party agent if that third party agent collected the information unlawfully.\"\n\nRCMP initially denied using Clearview AI\n\nConcerns about Clearview AI's software intensified last year after a New York Times investigation revealed the software had extracted more than three billion photos from public websites like Facebook and Instagram. It then turned them into a database used by more than 600 law enforcement agencies in the U.S., Canada and elsewhere.\n\nThe RCMP at first denied using Clearview AI but confirmed it had been using the software last year, after news broke that the company's client list had been hacked.\n\nPrivacy Commissioner Daniel Therrien tabled a report to Parliament Thursday morning after investigating the national police force's use of the software from U.S.-based Clearview AI. (Adrian Wyld/The Canadian Press)\n\nAt the time, the RCMP acknowledged vaguely that \"a few units in the RCMP\" had been using the tech to \"enhance criminal investigations.\"\n\nIt's still not clear what the force was using the technology for.\n\n\"Our investigation found that approximately six per cent of the searches made through Clearview was an incident involving child exploitation or child sexual cases. But in something like 85 per cent of the searches that we were able to to look at, the RCMP did not actually account for the use,\" Therrien said.\n\n\"And that is extremely troubling.\"\n\nClearview AI has since stopped offering its services to Canada. While Therrien said the RCMP is no longer using the software, he remains troubled that the force did not agree with his conclusion that it contravened the Privacy Act.\n\nThe RCMP argued that the law does not \"expressly impose a duty to confirm the legal basis for the collection of personal information by its private sector partners, says the report.\n\n\"We acknowledge that there is always room for improvement and we continually seek opportunities to strengthen our policies, procedures and training,\" said the RCMP in a media statement.\n\nNDP MP Charlie Angus said the RCMP's use of this technology adds to the mistrust of the RCMP felt in Indigenous, Black and racialized communities and protest groups.\n\n\"The Privacy Commissioner's findings in this report are startling and incredibly disturbing,\" he said in a media statement.\n\n\"Privacy rights are fundamental. Clear rules over the consent and taking of private information must be a priority for our government. The Liberal government must now hold the RCMP to account to implement these recommendations put forward by the Privacy Commissioner.\"\n\nBetter personal data controls needed: Therrien\n\nThe report also found the RCMP did not have proper systems in place to track, identify, assess and control this type of personal information.\n\nIt recommends that within a year, the RCMP improve its policies, systems and training, which the force has agreed to do.\n\nBrenda McPhail, director of the privacy, surveillance and technology project at the Canadian Civil Liberties Association, said it appears the RCMP was in a rush to use the technology.\n\n\"It's not that genie is out of the bottle. It's that people are wanting to use this technology before we've had the necessary public conversations about whether or not we should be using it because it is deeply rights infringing,\" she said.\n\n\"We need to talk to how it can be done to protect people.\"\n\nA February report from Therrien and three other privacy commissioners found Clearview AI created a significant risk to individuals by allowing law enforcement and companies to match photos against its database of more than three billion images, including Canadians and children.\n\nIt called on governments to beef up federal and provincial privacy laws after it found Clearview AI violated Canadian privacy laws by collecting photos of Canadians without their knowledge or consent.\n\nA lawyer for Clearview AI said the company disagrees with the privacy commissioner's assertion that their actions are not fully in accordance with Canadian law.\n\n\"Clearview AI respects the RCMP and was honoured to deploy its groundbreaking, lawful technology to help the agency solve crimes, especially crimes against children,\" said Doug Mitchell, of IMK Advocates.\n\n\"Clearview AI has gone beyond its obligations and is willing to consider further accommodations in order to meet some of the Privacy Commission's concerns within the bounds of the law and feasibility. Clearview AI hopes to continue the dialogue in order to find common ground.\"",
            "url": "https://www.cbc.ca/news/politics/rcmp-clearview-ai-1.6060228",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "rcmps",
                "clearview",
                "finds",
                "using",
                "software",
                "technology",
                "therrien",
                "investigation",
                "violated",
                "facial",
                "personal",
                "laws",
                "ai",
                "report",
                "privacy",
                "rcmp",
                "tech",
                "recognition"
            ],
            "summary": "The RCMP's use of a controversial, third-party facial recognition technology was a serious violation of Canada's privacy laws, the privacy commissioner says.\nPrivacy Commissioner Daniel Therrien tabled a report to Parliament this morning after investigating the national police force's use of software from U.S.-based Clearview AI.\nIt called on governments to beef up federal and provincial privacy laws after it found Clearview AI violated Canadian privacy laws by collecting photos of Canadians without their knowledge or consent.\nA lawyer for Clearview AI said the company disagrees with the privacy commissioner's assertion that their actions are not fully in accordance with Canadian law.\nClearview AI hopes to continue the dialogue in order to find common ground.\"",
            "metadata": {
                "source_domain": "www.cbc.ca",
                "scrape_date": "2024-10-25T12:40:15.062327",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 5372
            }
        },
        {
            "title": "Clearview AI Settles Suit and Agrees to Limits on Facial Recognition Database",
            "text": "Clearview AI, the facial recognition software maker, on Monday settled a lawsuit brought by the American Civil Liberties Union and agreed to limit its face database in the United States primarily to government agencies and not allow most American companies to have access to it.\n\nUnder the settlement, which was filed with an Illinois state court, Clearview will not sell its database of what it said were more than 20 billion facial photos to most private individuals and businesses in the country. But the company can largely still sell that database to federal and state agencies.\n\nThe agreement is the latest blow to the New York-based start-up, which built its facial recognition software by scraping photos from the web and popular sites, such as Facebook, LinkedIn and Instagram. Clearview then sold its software to local police departments and government agencies, including the F.B.I. and Immigration and Customs Enforcement.\n\nBut its technology has been deemed illegal in Canada, Australia and parts of Europe for violating privacy laws. Clearview also faces a provisional $22.6 million fine in Britain, as well as a 20 million-euro fine from Italy’s data protection agency.",
            "url": "https://www.nytimes.com/2022/05/09/technology/clearview-ai-suit.html",
            "authors": [
                "Ryan Mac",
                "Kashmir Hill"
            ],
            "publish_date": "2022-05-09T00:00:00",
            "keywords": [
                "american",
                "database",
                "suit",
                "recognition",
                "settles",
                "software",
                "state",
                "fine",
                "sell",
                "photos",
                "limits",
                "ai",
                "clearview",
                "agrees",
                "facial"
            ],
            "summary": "Clearview AI, the facial recognition software maker, on Monday settled a lawsuit brought by the American Civil Liberties Union and agreed to limit its face database in the United States primarily to government agencies and not allow most American companies to have access to it.\nUnder the settlement, which was filed with an Illinois state court, Clearview will not sell its database of what it said were more than 20 billion facial photos to most private individuals and businesses in the country.\nBut the company can largely still sell that database to federal and state agencies.\nThe agreement is the latest blow to the New York-based start-up, which built its facial recognition software by scraping photos from the web and popular sites, such as Facebook, LinkedIn and Instagram.\nClearview also faces a provisional $22.6 million fine in Britain, as well as a 20 million-euro fine from Italy’s data protection agency.",
            "metadata": {
                "source_domain": "www.nytimes.com",
                "scrape_date": "2024-10-25T12:40:15.197370",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 1184
            }
        },
        {
            "title": "Clearview AI",
            "text": "American facial recognition software company\n\nClearview AI, Inc. is an American facial recognition company, providing software primarily to law enforcement and other government agencies.[2] The company's algorithm matches faces to a database of more than 20 billion images collected from the Internet, including social media applications.[1] Founded by Hoan Ton-That and Richard Schwartz, the company maintained a low profile until late 2019, until its usage by law enforcement was first reported.[3]\n\nUse of the facial recognition tool has been controversial. Several U.S. senators have expressed concern about privacy rights and the American Civil Liberties Union (ACLU) has sued the company for violating privacy laws on several occasions. U.S. police have used the software to apprehend suspected criminals.[4][5][6] Clearview's practices have led to fines and bans by EU nations for violating privacy laws, and investigations in the U.S. and other countries.[7][8][9] In 2022, Clearview reached a settlement with the ACLU, in which they agreed to restrict U.S. market sales of facial recognition services to government entities.\n\nClearview AI was the victim of a data breach in 2020 which exposed their customer list. This demonstrated 2,200 organizations in 27 countries had accounts with facial recognition searches.[10]\n\nHistory [ edit ]\n\nClearview AI was founded in 2017 by Hoan Ton-That and Richard Schwartz after transferring the assets of another company, SmartCheckr, which the pair originally founded in 2017 alongside Charles C. Johnson.[11][3] The company was founded in Manhattan after the founders met at the Manhattan Institute.[1] The company initially raised $8.4 million from investors including Kirenaga Partners and Peter Thiel.[12] Additional fundraising, in 2020, collected $8.625 million in exchange for equity. The company did not disclose investors in the second round. In 2021, another fundraising round received $30 million. Early use of Clearview's app was given to potential investors in their Series A fundraising round. Billionaire John Catsimatidis used it to identify someone his daughter dated and piloted it at one of his Gristedes grocery markets in New York City to identify shoplifters.[14][15]\n\nIn October 2020, a company spokesperson claimed that Clearview AI's valuation was more than $100 million.[16] The company announced its first chief strategy officer, chief revenue officer, and chief marketing officer in May 2021. Devesh Ashra, a former deputy assistant secretary with the United States Department of the Treasury, became its chief strategy officer. Chris Metaxas, a former executive at LexisNexis Risk Solutions, became its chief revenue officer. Susan Crandall, a former marketing executive at LexisNexis Risk Solutions and Motorola Solutions, became its chief marketing officer.[17] Devesh Ashra and Chris Metaxas left the company in 2021. In August 2021, Clearview AI announced the formation of an advisory board including Raymond Kelly, Richard A. Clarke, Rudy Washington, Floyd Abrams, Lee S. Wolosky, and Owen West.[18] The company claimed to have scraped more than 10 billion images as of October 2021.[19] In May 2022, Clearview AI announced that it would be expanding sales of its facial recognition software to schools and lending platforms outside the U.S.[20]\n\nClearview AI hired a notable legal team to defend the company against several lawsuits that threatened their business model. Their legal staff includes Tor Ekeland, Lee S. Wolosky, Paul Clement, Floyd Abrams, and Jack Mulcaire.[21][1][22] Abrams stated the issue of privacy rights versus free speech in the First Amendment could reach the Supreme Court.[21]\n\nUsage [ edit ]\n\nClearview AI provides facial recognition software where users can upload an image of a face and match it against their database.[23] The software then supplies links to where the \"match\" can be found online.[24] The company operated in near secrecy until the release of an investigative report in The New York Times titled \"The Secretive Company That Might End Privacy as We Know It\" in January 2020. It maintained this secrecy by publishing fake information about the company's location and employees and erasing social media for the founders.[3][1][25] Citing the article, over 40 tech and civil rights organizations sent a letter to the Privacy and Civil Liberties Oversight Board (PCLOB) and four congressional committees, outlining their concerns with facial recognition and Clearview, and asking the PCLOB to suspend use of facial recognition.[26][27][28][1]\n\nClearview served to accelerate a global debate on the regulation of facial recognition technology by governments and law enforcement.[29][30] Law enforcement officers have stated that Clearview's facial recognition is far superior in identifying perpetrators from any angle than previously used technology.[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.[32] On February 5 and 6, 2020, Google, YouTube, Facebook, and Venmo sent cease and desist letters as it is against their policies.[33][34] Ton-That responded in an interview that there is a First Amendment right to access public data. He later stated that Clearview has scraped over 50 billion images from across the web.[29][35][36]\n\nThe New Zealand Police used it in a trial after being approached by Clearview's Marko Jukic in January 2020. Jukic said it would have helped identify the Christchurch mosque shooter had the technology been available. The usage of Clearview's software in this case raised strong objections once exposed, as neither the users' supervisors or the Privacy Commissioner were aware or approved of its use. After it was revealed by RNZ, Justice Minister Andrew Little stated, \"It clearly wasn't endorsed, from the senior police hierarchy, and it clearly didn't get the endorsement from the [Police] Minister... that is a matter of concern.\"[37][38]\n\nClearview's technology was used for identifying an individual at a May 30, 2020 George Floyd police violence protest in Miami, Florida. Miami's WTVJ confirmed this, as the arrest report only said she was \"identified through investigative means\". The defendant's attorney did not even know it was with Clearview. Ton-That confirmed its use, noting that it was not being used for surveillance, but only to investigate a crime.[39]\n\nIn December 2020, the ACLU of Washington sent a letter to Seattle mayor Jenny Durkan, asking her to ban the Seattle Police Department from using Clearview AI.[40] The letter cited public records retrieved by a local blogger, which showed one officer signing up for and repeatedly logging into the service, as well as corresponding with a company representative. While the ACLU letter raised concerns that the officer's usage violated the Seattle Surveillance Ordinance, an auditor at the City of Seattle Office of the Inspector General argued that the ordinance was designed to address the usage of surveillance technologies by the Department itself, not by an officer without the Department's knowledge.[41]\n\nAfter the January 6 riot at the United States Capitol, the Oxford Police Department in Alabama used Clearview's software to run a number of images posted by the Federal Bureau of Investigation in its public request for suspect information to generate leads for people present during the riot. Photo matches and information were sent to the FBI who declined to comment on its techniques.[5]\n\nIn March 2022, Ukraine's Ministry of Defence began using Clearview AI's facial recognition technology \"to uncover Russian assailants, combat misinformation and identify the dead\". Ton-That also claimed that Ukraine's MoD has \"more than 2 billion images from the Russian social media service VKontakte at its disposal\".[42] Ukrainian government agencies used Clearview over 5,000 times as of April 2022.[43][44] The company provided these accounts and searches for free.[45]\n\nIn a Florida case, Clearview's technology was used by defense attorneys to successfully locate a witness, resulting in the dismissal of vehicular homicide charges against the defendant.[46]\n\nLaw enforcement use of the facial recognition software grew rapidly in the United States. In 2022 more than one million searches were conducted. In 2023, this usage doubled.[36]\n\nMarketing efforts and pushback [ edit ]\n\nClearview AI encouraged user adoption by offering free trials to law enforcement officers rather than departments as a whole. The company additionally used its significant connections to the Republican Party to connect with police departments.[1][47] In onboarding emails, new users were encouraged to go beyond running one or two searches to \"[s]ee if you can reach 100 searches\".[48] During 2020, Clearview sold their facial recognition software for one tenth the cost of competitors.[3]\n\nClearview's marketing claimed their facial recognition led to a terrorist arrest. The identification was submitted to the New York Police Department tip line.[49] Clearview claims to have solved two other New York cases and 40 cold cases, later stating they submitted them to tip lines. NYPD stated they have no institutional relationship with Clearview, but their policies do not ban its use by individual officers. In 2020, thirty NYPD officers were confirmed to have Clearview accounts.[3] In April 2021, documents obtained by the Legal Aid Society under New York's Freedom Of Information Law demonstrated that Clearview had collaborated with the NYPD for years, contrary to past NYPD denials.[50] Clearview met with senior NYPD leadership and entered into a vendor contract with the NYPD.[48] Clearview came under renewed scrutiny for enabling officers to conduct large numbers of searches without formal oversight or approval.[50][48]\n\nThe company was sent a cease and desist letter from the office of New Jersey Attorney General Gurbir Grewal after including a promotional video on its website with images of Grewal.[51] Clearview had claimed that its app played a role in a New Jersey police sting. Grewal confirmed the software was used to identify a child predator, but he also banned the use of Clearview in New Jersey. Tor Ekeland, a lawyer for Clearview, confirmed the marketing video was taken down the same day.[4][52]\n\nIn March 2020, Clearview pitched their technology to states for use in contact tracing to assist with the COVID-19 pandemic.[53][54] A reporter found Clearview's search could identify him while he covered his nose and mouth like a COVID mask would.[45] The idea brought criticism from US senators and other commentators because it seemed the crisis was being used to push unreliable tools that violate personal privacy.[55][56]\n\nContrary to Clearview's initial claims that its service was sold only to law enforcement, a data breach in early 2020 revealed that numerous commercial organizations were on Clearview's customer list. For example, Clearview marketed to private security firms and to casinos.[57] Additionally, Clearview planned expansion to many countries, including authoritarian regimes.[58]\n\nSenator Edward J. Markey wrote to Clearview and Ton-That, stating \"Widespread use of your technology could facilitate dangerous behavior and could effectively destroy individuals' ability to go about their daily lives anonymously.\" Markey asked Clearview to detail aspects of its business, in order to understand these privacy, bias, and security concerns.[32][59] Clearview responded through an attorney, declining to reveal information.[60] In response to this, Markey wrote a second letter, saying their response was unacceptable and contained dubious claims, and that he was concerned about Clearview \"selling its technology to authoritarian regimes\" and possible violations of COPPA.[8][61] Senator Markey wrote a third letter to the company with concerns, stating \"this health crisis cannot justify using unreliable surveillance tools that could undermine our privacy rights.\" Markey asked a series of questions about what government entities Clearview has been talking with, in addition to unanswered privacy concerns.[55]\n\nSenator Ron Wyden voiced concerns about Clearview and had meetings with Ton-That cancelled on three occasions.[62][8]\n\nIn April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.[63]\n\nTechnology [ edit ]\n\nAccuracy [ edit ]\n\nIn October 2021 Clearview submitted its algorithm to one of two facial recognition accuracy tests conducted by the National Institute of Standards and Technology (NIST) every few months. Clearview ranked amongst the top 10 of 300 facial recognition algorithms in a test to determine accuracy in matching two different photos of the same person. Clearview did not submit to the NIST test for matching an unknown face to a 10 billion image database, which more-closely matches the algorithm's intended purpose. This was the first third-party test of the software.[19]\n\nClearview, at various times throughout 2020, has claimed 98.6%, 99.6%, or 100% accuracy. However, these results are from tests conducted by people affiliated with the company and have not used representative samples of the population.[29][64][65]\n\nIn 2021, Clearview announced that it was developing \"deblur\" and \"mask removal\" tools to sharpen blurred images and envision the covered part of an individual's face. These tools would be implemented using machine learning models that fill in the missing details based on statistical patterns found in other images. Clearview acknowledged that deblurring an image and/or removing a mask could potentially make errors more frequent and would only be used to generate leads for police investigations.[35]\n\nAssistant Chief of Police of Miami, Armando Aguilar, said in 2023 that Clearview's AI tool had contributed to the resolution of several murder cases, and that his team had used the technology around 450 times a year. Aguilar emphasized that they do not make arrests based on Clearview's matches alone, and instead use the data as a lead and then proceed via conventional methods of case investigation.[24]\n\nSeveral cases of mistaken identity using Clearview facial recognition have been documented, but \"the lack of data and transparency around police use means the true figure is likely far higher.\" Ton-That claims the technology has approximately 100% accuracy, and attributes mistakes to potential poor policing practices. Ton-That's claimed accuracy level is based on mugshots and would be affected by the quality of the image uploaded.[24]\n\nData breaches [ edit ]\n\nClearview AI experienced a data breach in February 2020 which exposed its list of customers. Clearview's attorney, Tor Ekeland stated the security flaw was corrected.[66] In response to the leaks, the United States House Committee on Science, Space, and Technology sent a letter to the company requesting further insight into their bio-metric and security practices.[67]\n\nWhile Clearview's app is only supposed to be privately accessible to customers, the Android application package and iOS applications were found in unsecured Amazon S3 buckets.[68] The instructions showed how to load an enterprise (developer) certificate so the app could be installed without being published on the App Store. Clearview's access was suspended, as it was against Apple's terms of service for developers, and as a result the app was disabled.[69] In addition to application tracking (Google Analytics, Crashlytics), examination of the source code for the Android version found references to Google Play Services, requests for precise phone location data, voice search, sharing a free demo account to other users, augmented reality integration with Vuzix, and sending gallery photos or taking photos from the app itself. There were also references to scanning barcodes on a drivers license and to RealWear.[70]\n\nIn April 2020, Mossab Hussein of SpiderSilk, a security firm, discovered Clearview's source code repositories were exposed due to misconfigured user security settings. This included secret keys and credentials, including cloud storage and Slack tokens. The compiled apps and pre-release apps were accessible, allowing Hussein to run the macOS and iOS apps against Clearview's services. Hussein reported the breach to Clearview but refused to sign a non-disclosure agreement necessary for Clearview's bug bounty program. Ton-That reacted by calling Hussein's disclosure of the bug as an act of extortion. Hussein also found 70,000 videos in one storage bucket from a Rudin Management apartment building's entrance.[71]\n\nInsight Camera [ edit ]\n\nClearview also operates a secondary business, Insight Camera, which provides AI-enabled security cameras. It is targeted at \"retail, banking and residential buildings\". Two customers have used the technology, United Federation of Teachers and Rudin Management.[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.[74]\n\nCustomer list [ edit ]\n\nFollowing a data leak of Clearview's customer list, BuzzFeed confirmed that 2,200 organizations in 27 countries had accounts with activity. BuzzFeed has the exclusive right to publish this list and has chosen not publish it in its entirety.[10] Clearview AI claims that at least 600 of these users are police departments. These are primarily in the U.S. and Canada, but Clearview has expanded to other countries as well.[3] Although the company claims their services are for law enforcement, they have had contracts with Bank of America, Kohls, and Macy's. Several universities and high schools have done trials with Clearview.[10] The list below highlights particularly notable users.\n\nAmerican law enforcement and government\n\nInternational law enforcement\n\nLegal challenges [ edit ]\n\nClearview AI has had its business model challenged by several lawsuits in multiple jurisdictions. It responded by defending itself, settling in some cases, and exiting several markets.\n\nThe company's claim of a First Amendment right to public information has been disputed by privacy lawyers such as Scott Skinner-Thompson and Margot Kaminski, highlighting the problems and precedents surrounding persistent surveillance and anonymity.[34][89] Former New York City Police Commissioner and executive chairman of Teneo Risk Chief Bill Bratton challenged privacy concerns and recommended strict procedures for law enforcement usage in an op-ed in New York Daily News.[90]\n\nUnited States [ edit ]\n\nAfter the release of The New York Times January 2020 article, lawsuits were filed by the states of Illinois, California, Virginia and New York, citing violations of privacy and safety laws.[91] Most of the lawsuits were transferred to New York's Southern District.[92] Two lawsuits were filed in state courts; in Vermont by the attorney general and in Illinois on behalf of the American Civil Liberties Union (ACLU), which cited a statute that forbids the corporate use of residents' faceprints without explicit consent. Clearview countered that an Illinois law does not apply to a company based in New York.[21]\n\nIn response to a class action lawsuit filed in Illinois for violating the Biometric Information Privacy Act (BIPA), in May 2020 Clearview stated that they instituted a policy to stop working with non-government entities and to remove any photos geolocated in Illinois.[93][94][75] On May 28, 2020, ACLU and Edelson filed a new suit Clearview in Illinois using the BIPA.[95][96] Clearview agreed to a settlement in June 2024, offering 23% of the company (valued at $52 million at the time) rather than a cash settlement, which was likely to bankrupt the company.[97]\n\nIn May 2022, Clearview agreed to settle the 2020 lawsuit from the ACLU. The settlement prohibited the sale of its facial recognition database to private individuals and businesses.[98]\n\nIn the Vermont case, Clearview AI invoked Section 230 immunity. The court denied the use of Section 230 immunity in this case because Vermont's claims were \"based on the means by which Clearview acquired the photographs\" rather than third party content.[99]\n\nCanada [ edit ]\n\nIn July 2020, Clearview AI announced that it was exiting the Canadian market amidst joint investigations into the company and the use of its product by police forces.[100] Daniel Therrien, the Privacy Commissioner of Canada condemned Clearview AI's use of scraped biometric data: \"What Clearview does is mass surveillance and it is illegal. It is completely unacceptable for millions of people who will never be implicated in any crime to find themselves continually in a police lineup.\"[101] In June 2021, Therrien found that the Royal Canadian Mounted Police had broken Canadian privacy law through hundreds of illegal searches using Clearview AI.[102]\n\nEuropean Union and UK [ edit ]\n\nIn January 2021, Clearview AI's biometric photo database was deemed illegal in the European Union (EU) by the Hamburg Data Protection Authority (DPA). The deletion of an affected person's biometric data was ordered. The authority stated that the General Data Protection Regulation (GDPR) is applicable despite the fact that Clearview AI has no European branch.[103] In March 2020, they had requested Clearview AI's customer list, as data protection obligations would also apply to the customers.[104] The data protection advocacy organization NOYB criticized the DPA's decision as the DPA issued an order protecting only the individual complainant instead of an order banning the collection of any European resident's photos.[105]\n\nIn May 2021, the company had numerous legal complaints filed in Austria, France, Greece, Italy and the United Kingdom for violating European privacy laws in its method of documenting and collecting Internet data.[106] In November 2021, Clearview received a provisional notice by the UK's Information Commissioner's Office (ICO) to stop processing its citizens' data citing a range of alleged breaches. The company was also notified of a potential fine of approximately $22.6 million. Clearview claimed that the ICO's allegations were factually inaccurate as the company \"does not do business in the UK, and does not have any UK customers at this time\". The BBC reported on 23 May that the company had been fined \"more than £7.5m by the UK's privacy watchdog and told to delete the data of UK residents\".[107] Clearview was also ordered to delete all facial recognition data of UK residents. This fine marked the fourth of its type placed on Clearview, after similar orders and fines issued from Australia, France, and Italy.[9] However, in October 2023, this fine was overturned following an appeal based on the jurisdiction of the ICO over acts of foreign governments.[108]\n\nIn September 2024, Clearview AI was fined €30.5 million by the Dutch Data Protection Authority (DPA) for constructing what the agency described as an illegal database.[109] The DPA's ruling highlighted that Clearview AI unlawfully collected facial images, including those of Dutch citizens, without obtaining their consent. This practice constitutes a significant violation of the EU's GDPR due to the intrusive nature of facial recognition technology and the lack of transparency regarding the use of individuals' biometric data.[110]\n\nSee also [ edit ]",
            "url": "https://en.wikipedia.org/wiki/Clearview_AI#:~:text=Clearview%2C%20at%20various%20times%20throughout,%25%2C%20or%20100%25%20accuracy.",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "privacy",
                "recognition",
                "company",
                "used",
                "clearviews",
                "data",
                "2020",
                "ai",
                "clearview",
                "facial"
            ],
            "summary": "[21]Usage [ edit ]Clearview AI provides facial recognition software where users can upload an image of a face and match it against their database.\n[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.\n[62][8]In April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.\n[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.\nAmerican law enforcement and governmentInternational law enforcementLegal challenges [ edit ]Clearview AI has had its business model challenged by several lawsuits in multiple jurisdictions.",
            "metadata": {
                "source_domain": "en.wikipedia.org",
                "scrape_date": "2024-10-25T12:40:17.489540",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 23454
            }
        },
        {
            "title": "UK ICO challenges Clearview AI ruling",
            "text": "Clearview AI scrapes images and biometric data from the internet. Its service allows its customers, which include law enforcement agencies, to upload their own images to see if they return a match against the images on Clearview AI’s database.\n\nThe Information Commissioner’s Office (ICO) fined Clearview AI more than £7.5 million in May 2022, and further ordered the company to stop obtaining and using the personal data of people in the UK sourced from the public internet, and to delete the data it has already gathered of UK residents from its systems too.\n\nThe ICO took the action following a joint investigation conducted with its Australian counterpart, the Office of the Australian Information Commissioner (OAIC). It considered the company was responsible for a series of data protection failings, including rules on fair and lawful processing of personal data, and on the retention of such data.\n\nHowever, in October this year, Clearview AI successfully appealed against the ICO’s enforcement action before the UK’s information rights tribunal, on jurisdictional grounds. The ICO has now announced that it has raised an appeal against the tribunal’s decision.\n\nThe ICO said: “The ruling makes clear that even if a company is not established in the UK, it is subject to UK data protection law that is related to the monitoring of people living in the UK. As such, where Clearview provides its services commercially, it will be subject to the ICO's jurisdiction.”\n\n“The commissioner considers the tribunal incorrectly interpreted the law when finding Clearview’s processing fell outside the reach of UK data protection law on the basis that it provided its services to foreign law enforcement agencies. The commissioner's view is that Clearview itself was not processing for foreign law enforcement purposes and should not be shielded from the scope of UK law on that basis,” it said.\n\nEmily Cox of Pinsent Masons said it is unsurprising that the ICO has sought leave to appeal given the potential implications of facial recognition technology.\n\n“The regulator will want absolute clarity as to an interpretation of GDPR which allows a commercial enterprise to benefit from an exemption for the law enforcement agencies which it serves,” Cox said. “It will also be conscious of the divergent regulatory outcome thus far when compared with other jurisdictions in the EU.”\n\nData protection authorities in France, Italy and Greece have all issued fines against Clearview AI.",
            "url": "https://www.pinsentmasons.com/out-law/news/uk-ico-challenges-clearview-ai-ruling",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "challenges",
                "protection",
                "law",
                "enforcement",
                "uk",
                "data",
                "information",
                "ruling",
                "ico",
                "ai",
                "processing",
                "clearview"
            ],
            "summary": "Clearview AI scrapes images and biometric data from the internet.\nIts service allows its customers, which include law enforcement agencies, to upload their own images to see if they return a match against the images on Clearview AI’s database.\nHowever, in October this year, Clearview AI successfully appealed against the ICO’s enforcement action before the UK’s information rights tribunal, on jurisdictional grounds.\nThe ICO said: “The ruling makes clear that even if a company is not established in the UK, it is subject to UK data protection law that is related to the monitoring of people living in the UK.\nThe commissioner's view is that Clearview itself was not processing for foreign law enforcement purposes and should not be shielded from the scope of UK law on that basis,” it said.",
            "metadata": {
                "source_domain": "www.pinsentmasons.com",
                "scrape_date": "2024-10-25T12:40:17.740874",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 2478
            }
        },
        {
            "title": "Clearview AI",
            "text": "American facial recognition software company\n\nClearview AI, Inc. is an American facial recognition company, providing software primarily to law enforcement and other government agencies.[2] The company's algorithm matches faces to a database of more than 20 billion images collected from the Internet, including social media applications.[1] Founded by Hoan Ton-That and Richard Schwartz, the company maintained a low profile until late 2019, until its usage by law enforcement was first reported.[3]\n\nUse of the facial recognition tool has been controversial. Several U.S. senators have expressed concern about privacy rights and the American Civil Liberties Union (ACLU) has sued the company for violating privacy laws on several occasions. U.S. police have used the software to apprehend suspected criminals.[4][5][6] Clearview's practices have led to fines and bans by EU nations for violating privacy laws, and investigations in the U.S. and other countries.[7][8][9] In 2022, Clearview reached a settlement with the ACLU, in which they agreed to restrict U.S. market sales of facial recognition services to government entities.\n\nClearview AI was the victim of a data breach in 2020 which exposed their customer list. This demonstrated 2,200 organizations in 27 countries had accounts with facial recognition searches.[10]\n\nHistory [ edit ]\n\nClearview AI was founded in 2017 by Hoan Ton-That and Richard Schwartz after transferring the assets of another company, SmartCheckr, which the pair originally founded in 2017 alongside Charles C. Johnson.[11][3] The company was founded in Manhattan after the founders met at the Manhattan Institute.[1] The company initially raised $8.4 million from investors including Kirenaga Partners and Peter Thiel.[12] Additional fundraising, in 2020, collected $8.625 million in exchange for equity. The company did not disclose investors in the second round. In 2021, another fundraising round received $30 million. Early use of Clearview's app was given to potential investors in their Series A fundraising round. Billionaire John Catsimatidis used it to identify someone his daughter dated and piloted it at one of his Gristedes grocery markets in New York City to identify shoplifters.[14][15]\n\nIn October 2020, a company spokesperson claimed that Clearview AI's valuation was more than $100 million.[16] The company announced its first chief strategy officer, chief revenue officer, and chief marketing officer in May 2021. Devesh Ashra, a former deputy assistant secretary with the United States Department of the Treasury, became its chief strategy officer. Chris Metaxas, a former executive at LexisNexis Risk Solutions, became its chief revenue officer. Susan Crandall, a former marketing executive at LexisNexis Risk Solutions and Motorola Solutions, became its chief marketing officer.[17] Devesh Ashra and Chris Metaxas left the company in 2021. In August 2021, Clearview AI announced the formation of an advisory board including Raymond Kelly, Richard A. Clarke, Rudy Washington, Floyd Abrams, Lee S. Wolosky, and Owen West.[18] The company claimed to have scraped more than 10 billion images as of October 2021.[19] In May 2022, Clearview AI announced that it would be expanding sales of its facial recognition software to schools and lending platforms outside the U.S.[20]\n\nClearview AI hired a notable legal team to defend the company against several lawsuits that threatened their business model. Their legal staff includes Tor Ekeland, Lee S. Wolosky, Paul Clement, Floyd Abrams, and Jack Mulcaire.[21][1][22] Abrams stated the issue of privacy rights versus free speech in the First Amendment could reach the Supreme Court.[21]\n\nUsage [ edit ]\n\nClearview AI provides facial recognition software where users can upload an image of a face and match it against their database.[23] The software then supplies links to where the \"match\" can be found online.[24] The company operated in near secrecy until the release of an investigative report in The New York Times titled \"The Secretive Company That Might End Privacy as We Know It\" in January 2020. It maintained this secrecy by publishing fake information about the company's location and employees and erasing social media for the founders.[3][1][25] Citing the article, over 40 tech and civil rights organizations sent a letter to the Privacy and Civil Liberties Oversight Board (PCLOB) and four congressional committees, outlining their concerns with facial recognition and Clearview, and asking the PCLOB to suspend use of facial recognition.[26][27][28][1]\n\nClearview served to accelerate a global debate on the regulation of facial recognition technology by governments and law enforcement.[29][30] Law enforcement officers have stated that Clearview's facial recognition is far superior in identifying perpetrators from any angle than previously used technology.[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.[32] On February 5 and 6, 2020, Google, YouTube, Facebook, and Venmo sent cease and desist letters as it is against their policies.[33][34] Ton-That responded in an interview that there is a First Amendment right to access public data. He later stated that Clearview has scraped over 50 billion images from across the web.[29][35][36]\n\nThe New Zealand Police used it in a trial after being approached by Clearview's Marko Jukic in January 2020. Jukic said it would have helped identify the Christchurch mosque shooter had the technology been available. The usage of Clearview's software in this case raised strong objections once exposed, as neither the users' supervisors or the Privacy Commissioner were aware or approved of its use. After it was revealed by RNZ, Justice Minister Andrew Little stated, \"It clearly wasn't endorsed, from the senior police hierarchy, and it clearly didn't get the endorsement from the [Police] Minister... that is a matter of concern.\"[37][38]\n\nClearview's technology was used for identifying an individual at a May 30, 2020 George Floyd police violence protest in Miami, Florida. Miami's WTVJ confirmed this, as the arrest report only said she was \"identified through investigative means\". The defendant's attorney did not even know it was with Clearview. Ton-That confirmed its use, noting that it was not being used for surveillance, but only to investigate a crime.[39]\n\nIn December 2020, the ACLU of Washington sent a letter to Seattle mayor Jenny Durkan, asking her to ban the Seattle Police Department from using Clearview AI.[40] The letter cited public records retrieved by a local blogger, which showed one officer signing up for and repeatedly logging into the service, as well as corresponding with a company representative. While the ACLU letter raised concerns that the officer's usage violated the Seattle Surveillance Ordinance, an auditor at the City of Seattle Office of the Inspector General argued that the ordinance was designed to address the usage of surveillance technologies by the Department itself, not by an officer without the Department's knowledge.[41]\n\nAfter the January 6 riot at the United States Capitol, the Oxford Police Department in Alabama used Clearview's software to run a number of images posted by the Federal Bureau of Investigation in its public request for suspect information to generate leads for people present during the riot. Photo matches and information were sent to the FBI who declined to comment on its techniques.[5]\n\nIn March 2022, Ukraine's Ministry of Defence began using Clearview AI's facial recognition technology \"to uncover Russian assailants, combat misinformation and identify the dead\". Ton-That also claimed that Ukraine's MoD has \"more than 2 billion images from the Russian social media service VKontakte at its disposal\".[42] Ukrainian government agencies used Clearview over 5,000 times as of April 2022.[43][44] The company provided these accounts and searches for free.[45]\n\nIn a Florida case, Clearview's technology was used by defense attorneys to successfully locate a witness, resulting in the dismissal of vehicular homicide charges against the defendant.[46]\n\nLaw enforcement use of the facial recognition software grew rapidly in the United States. In 2022 more than one million searches were conducted. In 2023, this usage doubled.[36]\n\nMarketing efforts and pushback [ edit ]\n\nClearview AI encouraged user adoption by offering free trials to law enforcement officers rather than departments as a whole. The company additionally used its significant connections to the Republican Party to connect with police departments.[1][47] In onboarding emails, new users were encouraged to go beyond running one or two searches to \"[s]ee if you can reach 100 searches\".[48] During 2020, Clearview sold their facial recognition software for one tenth the cost of competitors.[3]\n\nClearview's marketing claimed their facial recognition led to a terrorist arrest. The identification was submitted to the New York Police Department tip line.[49] Clearview claims to have solved two other New York cases and 40 cold cases, later stating they submitted them to tip lines. NYPD stated they have no institutional relationship with Clearview, but their policies do not ban its use by individual officers. In 2020, thirty NYPD officers were confirmed to have Clearview accounts.[3] In April 2021, documents obtained by the Legal Aid Society under New York's Freedom Of Information Law demonstrated that Clearview had collaborated with the NYPD for years, contrary to past NYPD denials.[50] Clearview met with senior NYPD leadership and entered into a vendor contract with the NYPD.[48] Clearview came under renewed scrutiny for enabling officers to conduct large numbers of searches without formal oversight or approval.[50][48]\n\nThe company was sent a cease and desist letter from the office of New Jersey Attorney General Gurbir Grewal after including a promotional video on its website with images of Grewal.[51] Clearview had claimed that its app played a role in a New Jersey police sting. Grewal confirmed the software was used to identify a child predator, but he also banned the use of Clearview in New Jersey. Tor Ekeland, a lawyer for Clearview, confirmed the marketing video was taken down the same day.[4][52]\n\nIn March 2020, Clearview pitched their technology to states for use in contact tracing to assist with the COVID-19 pandemic.[53][54] A reporter found Clearview's search could identify him while he covered his nose and mouth like a COVID mask would.[45] The idea brought criticism from US senators and other commentators because it seemed the crisis was being used to push unreliable tools that violate personal privacy.[55][56]\n\nContrary to Clearview's initial claims that its service was sold only to law enforcement, a data breach in early 2020 revealed that numerous commercial organizations were on Clearview's customer list. For example, Clearview marketed to private security firms and to casinos.[57] Additionally, Clearview planned expansion to many countries, including authoritarian regimes.[58]\n\nSenator Edward J. Markey wrote to Clearview and Ton-That, stating \"Widespread use of your technology could facilitate dangerous behavior and could effectively destroy individuals' ability to go about their daily lives anonymously.\" Markey asked Clearview to detail aspects of its business, in order to understand these privacy, bias, and security concerns.[32][59] Clearview responded through an attorney, declining to reveal information.[60] In response to this, Markey wrote a second letter, saying their response was unacceptable and contained dubious claims, and that he was concerned about Clearview \"selling its technology to authoritarian regimes\" and possible violations of COPPA.[8][61] Senator Markey wrote a third letter to the company with concerns, stating \"this health crisis cannot justify using unreliable surveillance tools that could undermine our privacy rights.\" Markey asked a series of questions about what government entities Clearview has been talking with, in addition to unanswered privacy concerns.[55]\n\nSenator Ron Wyden voiced concerns about Clearview and had meetings with Ton-That cancelled on three occasions.[62][8]\n\nIn April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.[63]\n\nTechnology [ edit ]\n\nAccuracy [ edit ]\n\nIn October 2021 Clearview submitted its algorithm to one of two facial recognition accuracy tests conducted by the National Institute of Standards and Technology (NIST) every few months. Clearview ranked amongst the top 10 of 300 facial recognition algorithms in a test to determine accuracy in matching two different photos of the same person. Clearview did not submit to the NIST test for matching an unknown face to a 10 billion image database, which more-closely matches the algorithm's intended purpose. This was the first third-party test of the software.[19]\n\nClearview, at various times throughout 2020, has claimed 98.6%, 99.6%, or 100% accuracy. However, these results are from tests conducted by people affiliated with the company and have not used representative samples of the population.[29][64][65]\n\nIn 2021, Clearview announced that it was developing \"deblur\" and \"mask removal\" tools to sharpen blurred images and envision the covered part of an individual's face. These tools would be implemented using machine learning models that fill in the missing details based on statistical patterns found in other images. Clearview acknowledged that deblurring an image and/or removing a mask could potentially make errors more frequent and would only be used to generate leads for police investigations.[35]\n\nAssistant Chief of Police of Miami, Armando Aguilar, said in 2023 that Clearview's AI tool had contributed to the resolution of several murder cases, and that his team had used the technology around 450 times a year. Aguilar emphasized that they do not make arrests based on Clearview's matches alone, and instead use the data as a lead and then proceed via conventional methods of case investigation.[24]\n\nSeveral cases of mistaken identity using Clearview facial recognition have been documented, but \"the lack of data and transparency around police use means the true figure is likely far higher.\" Ton-That claims the technology has approximately 100% accuracy, and attributes mistakes to potential poor policing practices. Ton-That's claimed accuracy level is based on mugshots and would be affected by the quality of the image uploaded.[24]\n\nData breaches [ edit ]\n\nClearview AI experienced a data breach in February 2020 which exposed its list of customers. Clearview's attorney, Tor Ekeland stated the security flaw was corrected.[66] In response to the leaks, the United States House Committee on Science, Space, and Technology sent a letter to the company requesting further insight into their bio-metric and security practices.[67]\n\nWhile Clearview's app is only supposed to be privately accessible to customers, the Android application package and iOS applications were found in unsecured Amazon S3 buckets.[68] The instructions showed how to load an enterprise (developer) certificate so the app could be installed without being published on the App Store. Clearview's access was suspended, as it was against Apple's terms of service for developers, and as a result the app was disabled.[69] In addition to application tracking (Google Analytics, Crashlytics), examination of the source code for the Android version found references to Google Play Services, requests for precise phone location data, voice search, sharing a free demo account to other users, augmented reality integration with Vuzix, and sending gallery photos or taking photos from the app itself. There were also references to scanning barcodes on a drivers license and to RealWear.[70]\n\nIn April 2020, Mossab Hussein of SpiderSilk, a security firm, discovered Clearview's source code repositories were exposed due to misconfigured user security settings. This included secret keys and credentials, including cloud storage and Slack tokens. The compiled apps and pre-release apps were accessible, allowing Hussein to run the macOS and iOS apps against Clearview's services. Hussein reported the breach to Clearview but refused to sign a non-disclosure agreement necessary for Clearview's bug bounty program. Ton-That reacted by calling Hussein's disclosure of the bug as an act of extortion. Hussein also found 70,000 videos in one storage bucket from a Rudin Management apartment building's entrance.[71]\n\nInsight Camera [ edit ]\n\nClearview also operates a secondary business, Insight Camera, which provides AI-enabled security cameras. It is targeted at \"retail, banking and residential buildings\". Two customers have used the technology, United Federation of Teachers and Rudin Management.[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.[74]\n\nCustomer list [ edit ]\n\nFollowing a data leak of Clearview's customer list, BuzzFeed confirmed that 2,200 organizations in 27 countries had accounts with activity. BuzzFeed has the exclusive right to publish this list and has chosen not publish it in its entirety.[10] Clearview AI claims that at least 600 of these users are police departments. These are primarily in the U.S. and Canada, but Clearview has expanded to other countries as well.[3] Although the company claims their services are for law enforcement, they have had contracts with Bank of America, Kohls, and Macy's. Several universities and high schools have done trials with Clearview.[10] The list below highlights particularly notable users.\n\nAmerican law enforcement and government\n\nInternational law enforcement\n\nLegal challenges [ edit ]\n\nClearview AI has had its business model challenged by several lawsuits in multiple jurisdictions. It responded by defending itself, settling in some cases, and exiting several markets.\n\nThe company's claim of a First Amendment right to public information has been disputed by privacy lawyers such as Scott Skinner-Thompson and Margot Kaminski, highlighting the problems and precedents surrounding persistent surveillance and anonymity.[34][89] Former New York City Police Commissioner and executive chairman of Teneo Risk Chief Bill Bratton challenged privacy concerns and recommended strict procedures for law enforcement usage in an op-ed in New York Daily News.[90]\n\nUnited States [ edit ]\n\nAfter the release of The New York Times January 2020 article, lawsuits were filed by the states of Illinois, California, Virginia and New York, citing violations of privacy and safety laws.[91] Most of the lawsuits were transferred to New York's Southern District.[92] Two lawsuits were filed in state courts; in Vermont by the attorney general and in Illinois on behalf of the American Civil Liberties Union (ACLU), which cited a statute that forbids the corporate use of residents' faceprints without explicit consent. Clearview countered that an Illinois law does not apply to a company based in New York.[21]\n\nIn response to a class action lawsuit filed in Illinois for violating the Biometric Information Privacy Act (BIPA), in May 2020 Clearview stated that they instituted a policy to stop working with non-government entities and to remove any photos geolocated in Illinois.[93][94][75] On May 28, 2020, ACLU and Edelson filed a new suit Clearview in Illinois using the BIPA.[95][96] Clearview agreed to a settlement in June 2024, offering 23% of the company (valued at $52 million at the time) rather than a cash settlement, which was likely to bankrupt the company.[97]\n\nIn May 2022, Clearview agreed to settle the 2020 lawsuit from the ACLU. The settlement prohibited the sale of its facial recognition database to private individuals and businesses.[98]\n\nIn the Vermont case, Clearview AI invoked Section 230 immunity. The court denied the use of Section 230 immunity in this case because Vermont's claims were \"based on the means by which Clearview acquired the photographs\" rather than third party content.[99]\n\nCanada [ edit ]\n\nIn July 2020, Clearview AI announced that it was exiting the Canadian market amidst joint investigations into the company and the use of its product by police forces.[100] Daniel Therrien, the Privacy Commissioner of Canada condemned Clearview AI's use of scraped biometric data: \"What Clearview does is mass surveillance and it is illegal. It is completely unacceptable for millions of people who will never be implicated in any crime to find themselves continually in a police lineup.\"[101] In June 2021, Therrien found that the Royal Canadian Mounted Police had broken Canadian privacy law through hundreds of illegal searches using Clearview AI.[102]\n\nEuropean Union and UK [ edit ]\n\nIn January 2021, Clearview AI's biometric photo database was deemed illegal in the European Union (EU) by the Hamburg Data Protection Authority (DPA). The deletion of an affected person's biometric data was ordered. The authority stated that the General Data Protection Regulation (GDPR) is applicable despite the fact that Clearview AI has no European branch.[103] In March 2020, they had requested Clearview AI's customer list, as data protection obligations would also apply to the customers.[104] The data protection advocacy organization NOYB criticized the DPA's decision as the DPA issued an order protecting only the individual complainant instead of an order banning the collection of any European resident's photos.[105]\n\nIn May 2021, the company had numerous legal complaints filed in Austria, France, Greece, Italy and the United Kingdom for violating European privacy laws in its method of documenting and collecting Internet data.[106] In November 2021, Clearview received a provisional notice by the UK's Information Commissioner's Office (ICO) to stop processing its citizens' data citing a range of alleged breaches. The company was also notified of a potential fine of approximately $22.6 million. Clearview claimed that the ICO's allegations were factually inaccurate as the company \"does not do business in the UK, and does not have any UK customers at this time\". The BBC reported on 23 May that the company had been fined \"more than £7.5m by the UK's privacy watchdog and told to delete the data of UK residents\".[107] Clearview was also ordered to delete all facial recognition data of UK residents. This fine marked the fourth of its type placed on Clearview, after similar orders and fines issued from Australia, France, and Italy.[9] However, in October 2023, this fine was overturned following an appeal based on the jurisdiction of the ICO over acts of foreign governments.[108]\n\nIn September 2024, Clearview AI was fined €30.5 million by the Dutch Data Protection Authority (DPA) for constructing what the agency described as an illegal database.[109] The DPA's ruling highlighted that Clearview AI unlawfully collected facial images, including those of Dutch citizens, without obtaining their consent. This practice constitutes a significant violation of the EU's GDPR due to the intrusive nature of facial recognition technology and the lack of transparency regarding the use of individuals' biometric data.[110]\n\nSee also [ edit ]",
            "url": "https://en.wikipedia.org/wiki/Clearview_AI",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "privacy",
                "recognition",
                "company",
                "used",
                "clearviews",
                "data",
                "2020",
                "ai",
                "clearview",
                "facial"
            ],
            "summary": "[21]Usage [ edit ]Clearview AI provides facial recognition software where users can upload an image of a face and match it against their database.\n[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.\n[62][8]In April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.\n[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.\nAmerican law enforcement and governmentInternational law enforcementLegal challenges [ edit ]Clearview AI has had its business model challenged by several lawsuits in multiple jurisdictions.",
            "metadata": {
                "source_domain": "en.wikipedia.org",
                "scrape_date": "2024-10-25T12:40:18.467647",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 23454
            }
        },
        {
            "title": "Clearview AI fined $33.7 million by Dutch data protection watchdog over ‘illegal database’ of faces",
            "text": "THE HAGUE, Netherlands (AP) — The Dutch data protection watchdog on Tuesday issued facial recognition startup Clearview AI with a fine of 30.5 million euros ($33.7 million) over its creation of what the agency called an “illegal database” of billion of photos of faces.\n\nThe Netherlands’ Data Protection Agency, or DPA, also warned Dutch companies that using Clearview’s services is also banned.\n\nThe data agency said that New York-based Clearview “has not objected to this decision and is therefore unable to appeal against the fine.”\n\nBut in a statement emailed to The Associated Press, Clearview’s chief legal officer, Jack Mulcaire, said that the decision is “unlawful, devoid of due process and is unenforceable.”\n\nThe Dutch agency said that building the database and insufficiently informing people whose images appear in the database amounted to serious breaches of the European Union’s General Data Protection Regulation, or GDPR.\n\n“Facial recognition is a highly intrusive technology, that you cannot simply unleash on anyone in the world,” DPA chairman Aleid Wolfsen said in a statement.\n\n“If there is a photo of you on the Internet — and doesn’t that apply to all of us? — then you can end up in the database of Clearview and be tracked. This is not a doom scenario from a scary film. Nor is it something that could only be done in China,” he said.\n\nDPA said that if Clearview doesn’t halt the breaches of the regulation, it faces noncompliance penalties of up to 5.1 million euros ($5.6 million) on top of the fine.\n\nMulcaire said in his statement that Clearview doesn’t fall under EU data protection regulations.\n\n“Clearview AI does not have a place of business in the Netherlands or the EU, it does not have any customers in the Netherlands or the EU, and does not undertake any activities that would otherwise mean it is subject to the GDPR,” he said.\n\nIn June, Clearview reached a settlement in an Illinois lawsuit alleging its massive photographic collection of faces violated the subjects’ privacy rights, a deal that attorneys estimate could be worth more than $50 million. Clearview didn’t admit any liability as part of the settlement agreement.\n\nThe case in Illinois consolidated lawsuits from around the U.S. filed against Clearview, which pulled photos from social media and elsewhere on the internet to create a database that it sold to businesses, individuals and government entities.",
            "url": "https://apnews.com/article/clearview-ai-facial-recognition-privacy-fine-netherlands-a1ac33c15d561d37a923b6c382f48ab4",
            "authors": [],
            "publish_date": "2024-09-03T09:26:24",
            "keywords": [
                "protection",
                "faces",
                "agency",
                "illegal",
                "eu",
                "fined",
                "netherlands",
                "dutch",
                "data",
                "watchdog",
                "million",
                "clearview",
                "doesnt",
                "database"
            ],
            "summary": "THE HAGUE, Netherlands (AP) — The Dutch data protection watchdog on Tuesday issued facial recognition startup Clearview AI with a fine of 30.5 million euros ($33.7 million) over its creation of what the agency called an “illegal database” of billion of photos of faces.\nThe Netherlands’ Data Protection Agency, or DPA, also warned Dutch companies that using Clearview’s services is also banned.\n— then you can end up in the database of Clearview and be tracked.\nDPA said that if Clearview doesn’t halt the breaches of the regulation, it faces noncompliance penalties of up to 5.1 million euros ($5.6 million) on top of the fine.\nMulcaire said in his statement that Clearview doesn’t fall under EU data protection regulations.",
            "metadata": {
                "source_domain": "apnews.com",
                "scrape_date": "2024-10-25T12:40:19.527484",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 2410
            }
        },
        {
            "title": "Clearview AI",
            "text": "American facial recognition software company\n\nClearview AI, Inc. is an American facial recognition company, providing software primarily to law enforcement and other government agencies.[2] The company's algorithm matches faces to a database of more than 20 billion images collected from the Internet, including social media applications.[1] Founded by Hoan Ton-That and Richard Schwartz, the company maintained a low profile until late 2019, until its usage by law enforcement was first reported.[3]\n\nUse of the facial recognition tool has been controversial. Several U.S. senators have expressed concern about privacy rights and the American Civil Liberties Union (ACLU) has sued the company for violating privacy laws on several occasions. U.S. police have used the software to apprehend suspected criminals.[4][5][6] Clearview's practices have led to fines and bans by EU nations for violating privacy laws, and investigations in the U.S. and other countries.[7][8][9] In 2022, Clearview reached a settlement with the ACLU, in which they agreed to restrict U.S. market sales of facial recognition services to government entities.\n\nClearview AI was the victim of a data breach in 2020 which exposed their customer list. This demonstrated 2,200 organizations in 27 countries had accounts with facial recognition searches.[10]\n\nHistory [ edit ]\n\nClearview AI was founded in 2017 by Hoan Ton-That and Richard Schwartz after transferring the assets of another company, SmartCheckr, which the pair originally founded in 2017 alongside Charles C. Johnson.[11][3] The company was founded in Manhattan after the founders met at the Manhattan Institute.[1] The company initially raised $8.4 million from investors including Kirenaga Partners and Peter Thiel.[12] Additional fundraising, in 2020, collected $8.625 million in exchange for equity. The company did not disclose investors in the second round. In 2021, another fundraising round received $30 million. Early use of Clearview's app was given to potential investors in their Series A fundraising round. Billionaire John Catsimatidis used it to identify someone his daughter dated and piloted it at one of his Gristedes grocery markets in New York City to identify shoplifters.[14][15]\n\nIn October 2020, a company spokesperson claimed that Clearview AI's valuation was more than $100 million.[16] The company announced its first chief strategy officer, chief revenue officer, and chief marketing officer in May 2021. Devesh Ashra, a former deputy assistant secretary with the United States Department of the Treasury, became its chief strategy officer. Chris Metaxas, a former executive at LexisNexis Risk Solutions, became its chief revenue officer. Susan Crandall, a former marketing executive at LexisNexis Risk Solutions and Motorola Solutions, became its chief marketing officer.[17] Devesh Ashra and Chris Metaxas left the company in 2021. In August 2021, Clearview AI announced the formation of an advisory board including Raymond Kelly, Richard A. Clarke, Rudy Washington, Floyd Abrams, Lee S. Wolosky, and Owen West.[18] The company claimed to have scraped more than 10 billion images as of October 2021.[19] In May 2022, Clearview AI announced that it would be expanding sales of its facial recognition software to schools and lending platforms outside the U.S.[20]\n\nClearview AI hired a notable legal team to defend the company against several lawsuits that threatened their business model. Their legal staff includes Tor Ekeland, Lee S. Wolosky, Paul Clement, Floyd Abrams, and Jack Mulcaire.[21][1][22] Abrams stated the issue of privacy rights versus free speech in the First Amendment could reach the Supreme Court.[21]\n\nUsage [ edit ]\n\nClearview AI provides facial recognition software where users can upload an image of a face and match it against their database.[23] The software then supplies links to where the \"match\" can be found online.[24] The company operated in near secrecy until the release of an investigative report in The New York Times titled \"The Secretive Company That Might End Privacy as We Know It\" in January 2020. It maintained this secrecy by publishing fake information about the company's location and employees and erasing social media for the founders.[3][1][25] Citing the article, over 40 tech and civil rights organizations sent a letter to the Privacy and Civil Liberties Oversight Board (PCLOB) and four congressional committees, outlining their concerns with facial recognition and Clearview, and asking the PCLOB to suspend use of facial recognition.[26][27][28][1]\n\nClearview served to accelerate a global debate on the regulation of facial recognition technology by governments and law enforcement.[29][30] Law enforcement officers have stated that Clearview's facial recognition is far superior in identifying perpetrators from any angle than previously used technology.[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.[32] On February 5 and 6, 2020, Google, YouTube, Facebook, and Venmo sent cease and desist letters as it is against their policies.[33][34] Ton-That responded in an interview that there is a First Amendment right to access public data. He later stated that Clearview has scraped over 50 billion images from across the web.[29][35][36]\n\nThe New Zealand Police used it in a trial after being approached by Clearview's Marko Jukic in January 2020. Jukic said it would have helped identify the Christchurch mosque shooter had the technology been available. The usage of Clearview's software in this case raised strong objections once exposed, as neither the users' supervisors or the Privacy Commissioner were aware or approved of its use. After it was revealed by RNZ, Justice Minister Andrew Little stated, \"It clearly wasn't endorsed, from the senior police hierarchy, and it clearly didn't get the endorsement from the [Police] Minister... that is a matter of concern.\"[37][38]\n\nClearview's technology was used for identifying an individual at a May 30, 2020 George Floyd police violence protest in Miami, Florida. Miami's WTVJ confirmed this, as the arrest report only said she was \"identified through investigative means\". The defendant's attorney did not even know it was with Clearview. Ton-That confirmed its use, noting that it was not being used for surveillance, but only to investigate a crime.[39]\n\nIn December 2020, the ACLU of Washington sent a letter to Seattle mayor Jenny Durkan, asking her to ban the Seattle Police Department from using Clearview AI.[40] The letter cited public records retrieved by a local blogger, which showed one officer signing up for and repeatedly logging into the service, as well as corresponding with a company representative. While the ACLU letter raised concerns that the officer's usage violated the Seattle Surveillance Ordinance, an auditor at the City of Seattle Office of the Inspector General argued that the ordinance was designed to address the usage of surveillance technologies by the Department itself, not by an officer without the Department's knowledge.[41]\n\nAfter the January 6 riot at the United States Capitol, the Oxford Police Department in Alabama used Clearview's software to run a number of images posted by the Federal Bureau of Investigation in its public request for suspect information to generate leads for people present during the riot. Photo matches and information were sent to the FBI who declined to comment on its techniques.[5]\n\nIn March 2022, Ukraine's Ministry of Defence began using Clearview AI's facial recognition technology \"to uncover Russian assailants, combat misinformation and identify the dead\". Ton-That also claimed that Ukraine's MoD has \"more than 2 billion images from the Russian social media service VKontakte at its disposal\".[42] Ukrainian government agencies used Clearview over 5,000 times as of April 2022.[43][44] The company provided these accounts and searches for free.[45]\n\nIn a Florida case, Clearview's technology was used by defense attorneys to successfully locate a witness, resulting in the dismissal of vehicular homicide charges against the defendant.[46]\n\nLaw enforcement use of the facial recognition software grew rapidly in the United States. In 2022 more than one million searches were conducted. In 2023, this usage doubled.[36]\n\nMarketing efforts and pushback [ edit ]\n\nClearview AI encouraged user adoption by offering free trials to law enforcement officers rather than departments as a whole. The company additionally used its significant connections to the Republican Party to connect with police departments.[1][47] In onboarding emails, new users were encouraged to go beyond running one or two searches to \"[s]ee if you can reach 100 searches\".[48] During 2020, Clearview sold their facial recognition software for one tenth the cost of competitors.[3]\n\nClearview's marketing claimed their facial recognition led to a terrorist arrest. The identification was submitted to the New York Police Department tip line.[49] Clearview claims to have solved two other New York cases and 40 cold cases, later stating they submitted them to tip lines. NYPD stated they have no institutional relationship with Clearview, but their policies do not ban its use by individual officers. In 2020, thirty NYPD officers were confirmed to have Clearview accounts.[3] In April 2021, documents obtained by the Legal Aid Society under New York's Freedom Of Information Law demonstrated that Clearview had collaborated with the NYPD for years, contrary to past NYPD denials.[50] Clearview met with senior NYPD leadership and entered into a vendor contract with the NYPD.[48] Clearview came under renewed scrutiny for enabling officers to conduct large numbers of searches without formal oversight or approval.[50][48]\n\nThe company was sent a cease and desist letter from the office of New Jersey Attorney General Gurbir Grewal after including a promotional video on its website with images of Grewal.[51] Clearview had claimed that its app played a role in a New Jersey police sting. Grewal confirmed the software was used to identify a child predator, but he also banned the use of Clearview in New Jersey. Tor Ekeland, a lawyer for Clearview, confirmed the marketing video was taken down the same day.[4][52]\n\nIn March 2020, Clearview pitched their technology to states for use in contact tracing to assist with the COVID-19 pandemic.[53][54] A reporter found Clearview's search could identify him while he covered his nose and mouth like a COVID mask would.[45] The idea brought criticism from US senators and other commentators because it seemed the crisis was being used to push unreliable tools that violate personal privacy.[55][56]\n\nContrary to Clearview's initial claims that its service was sold only to law enforcement, a data breach in early 2020 revealed that numerous commercial organizations were on Clearview's customer list. For example, Clearview marketed to private security firms and to casinos.[57] Additionally, Clearview planned expansion to many countries, including authoritarian regimes.[58]\n\nSenator Edward J. Markey wrote to Clearview and Ton-That, stating \"Widespread use of your technology could facilitate dangerous behavior and could effectively destroy individuals' ability to go about their daily lives anonymously.\" Markey asked Clearview to detail aspects of its business, in order to understand these privacy, bias, and security concerns.[32][59] Clearview responded through an attorney, declining to reveal information.[60] In response to this, Markey wrote a second letter, saying their response was unacceptable and contained dubious claims, and that he was concerned about Clearview \"selling its technology to authoritarian regimes\" and possible violations of COPPA.[8][61] Senator Markey wrote a third letter to the company with concerns, stating \"this health crisis cannot justify using unreliable surveillance tools that could undermine our privacy rights.\" Markey asked a series of questions about what government entities Clearview has been talking with, in addition to unanswered privacy concerns.[55]\n\nSenator Ron Wyden voiced concerns about Clearview and had meetings with Ton-That cancelled on three occasions.[62][8]\n\nIn April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.[63]\n\nTechnology [ edit ]\n\nAccuracy [ edit ]\n\nIn October 2021 Clearview submitted its algorithm to one of two facial recognition accuracy tests conducted by the National Institute of Standards and Technology (NIST) every few months. Clearview ranked amongst the top 10 of 300 facial recognition algorithms in a test to determine accuracy in matching two different photos of the same person. Clearview did not submit to the NIST test for matching an unknown face to a 10 billion image database, which more-closely matches the algorithm's intended purpose. This was the first third-party test of the software.[19]\n\nClearview, at various times throughout 2020, has claimed 98.6%, 99.6%, or 100% accuracy. However, these results are from tests conducted by people affiliated with the company and have not used representative samples of the population.[29][64][65]\n\nIn 2021, Clearview announced that it was developing \"deblur\" and \"mask removal\" tools to sharpen blurred images and envision the covered part of an individual's face. These tools would be implemented using machine learning models that fill in the missing details based on statistical patterns found in other images. Clearview acknowledged that deblurring an image and/or removing a mask could potentially make errors more frequent and would only be used to generate leads for police investigations.[35]\n\nAssistant Chief of Police of Miami, Armando Aguilar, said in 2023 that Clearview's AI tool had contributed to the resolution of several murder cases, and that his team had used the technology around 450 times a year. Aguilar emphasized that they do not make arrests based on Clearview's matches alone, and instead use the data as a lead and then proceed via conventional methods of case investigation.[24]\n\nSeveral cases of mistaken identity using Clearview facial recognition have been documented, but \"the lack of data and transparency around police use means the true figure is likely far higher.\" Ton-That claims the technology has approximately 100% accuracy, and attributes mistakes to potential poor policing practices. Ton-That's claimed accuracy level is based on mugshots and would be affected by the quality of the image uploaded.[24]\n\nData breaches [ edit ]\n\nClearview AI experienced a data breach in February 2020 which exposed its list of customers. Clearview's attorney, Tor Ekeland stated the security flaw was corrected.[66] In response to the leaks, the United States House Committee on Science, Space, and Technology sent a letter to the company requesting further insight into their bio-metric and security practices.[67]\n\nWhile Clearview's app is only supposed to be privately accessible to customers, the Android application package and iOS applications were found in unsecured Amazon S3 buckets.[68] The instructions showed how to load an enterprise (developer) certificate so the app could be installed without being published on the App Store. Clearview's access was suspended, as it was against Apple's terms of service for developers, and as a result the app was disabled.[69] In addition to application tracking (Google Analytics, Crashlytics), examination of the source code for the Android version found references to Google Play Services, requests for precise phone location data, voice search, sharing a free demo account to other users, augmented reality integration with Vuzix, and sending gallery photos or taking photos from the app itself. There were also references to scanning barcodes on a drivers license and to RealWear.[70]\n\nIn April 2020, Mossab Hussein of SpiderSilk, a security firm, discovered Clearview's source code repositories were exposed due to misconfigured user security settings. This included secret keys and credentials, including cloud storage and Slack tokens. The compiled apps and pre-release apps were accessible, allowing Hussein to run the macOS and iOS apps against Clearview's services. Hussein reported the breach to Clearview but refused to sign a non-disclosure agreement necessary for Clearview's bug bounty program. Ton-That reacted by calling Hussein's disclosure of the bug as an act of extortion. Hussein also found 70,000 videos in one storage bucket from a Rudin Management apartment building's entrance.[71]\n\nInsight Camera [ edit ]\n\nClearview also operates a secondary business, Insight Camera, which provides AI-enabled security cameras. It is targeted at \"retail, banking and residential buildings\". Two customers have used the technology, United Federation of Teachers and Rudin Management.[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.[74]\n\nCustomer list [ edit ]\n\nFollowing a data leak of Clearview's customer list, BuzzFeed confirmed that 2,200 organizations in 27 countries had accounts with activity. BuzzFeed has the exclusive right to publish this list and has chosen not publish it in its entirety.[10] Clearview AI claims that at least 600 of these users are police departments. These are primarily in the U.S. and Canada, but Clearview has expanded to other countries as well.[3] Although the company claims their services are for law enforcement, they have had contracts with Bank of America, Kohls, and Macy's. Several universities and high schools have done trials with Clearview.[10] The list below highlights particularly notable users.\n\nAmerican law enforcement and government\n\nInternational law enforcement\n\nLegal challenges [ edit ]\n\nClearview AI has had its business model challenged by several lawsuits in multiple jurisdictions. It responded by defending itself, settling in some cases, and exiting several markets.\n\nThe company's claim of a First Amendment right to public information has been disputed by privacy lawyers such as Scott Skinner-Thompson and Margot Kaminski, highlighting the problems and precedents surrounding persistent surveillance and anonymity.[34][89] Former New York City Police Commissioner and executive chairman of Teneo Risk Chief Bill Bratton challenged privacy concerns and recommended strict procedures for law enforcement usage in an op-ed in New York Daily News.[90]\n\nUnited States [ edit ]\n\nAfter the release of The New York Times January 2020 article, lawsuits were filed by the states of Illinois, California, Virginia and New York, citing violations of privacy and safety laws.[91] Most of the lawsuits were transferred to New York's Southern District.[92] Two lawsuits were filed in state courts; in Vermont by the attorney general and in Illinois on behalf of the American Civil Liberties Union (ACLU), which cited a statute that forbids the corporate use of residents' faceprints without explicit consent. Clearview countered that an Illinois law does not apply to a company based in New York.[21]\n\nIn response to a class action lawsuit filed in Illinois for violating the Biometric Information Privacy Act (BIPA), in May 2020 Clearview stated that they instituted a policy to stop working with non-government entities and to remove any photos geolocated in Illinois.[93][94][75] On May 28, 2020, ACLU and Edelson filed a new suit Clearview in Illinois using the BIPA.[95][96] Clearview agreed to a settlement in June 2024, offering 23% of the company (valued at $52 million at the time) rather than a cash settlement, which was likely to bankrupt the company.[97]\n\nIn May 2022, Clearview agreed to settle the 2020 lawsuit from the ACLU. The settlement prohibited the sale of its facial recognition database to private individuals and businesses.[98]\n\nIn the Vermont case, Clearview AI invoked Section 230 immunity. The court denied the use of Section 230 immunity in this case because Vermont's claims were \"based on the means by which Clearview acquired the photographs\" rather than third party content.[99]\n\nCanada [ edit ]\n\nIn July 2020, Clearview AI announced that it was exiting the Canadian market amidst joint investigations into the company and the use of its product by police forces.[100] Daniel Therrien, the Privacy Commissioner of Canada condemned Clearview AI's use of scraped biometric data: \"What Clearview does is mass surveillance and it is illegal. It is completely unacceptable for millions of people who will never be implicated in any crime to find themselves continually in a police lineup.\"[101] In June 2021, Therrien found that the Royal Canadian Mounted Police had broken Canadian privacy law through hundreds of illegal searches using Clearview AI.[102]\n\nEuropean Union and UK [ edit ]\n\nIn January 2021, Clearview AI's biometric photo database was deemed illegal in the European Union (EU) by the Hamburg Data Protection Authority (DPA). The deletion of an affected person's biometric data was ordered. The authority stated that the General Data Protection Regulation (GDPR) is applicable despite the fact that Clearview AI has no European branch.[103] In March 2020, they had requested Clearview AI's customer list, as data protection obligations would also apply to the customers.[104] The data protection advocacy organization NOYB criticized the DPA's decision as the DPA issued an order protecting only the individual complainant instead of an order banning the collection of any European resident's photos.[105]\n\nIn May 2021, the company had numerous legal complaints filed in Austria, France, Greece, Italy and the United Kingdom for violating European privacy laws in its method of documenting and collecting Internet data.[106] In November 2021, Clearview received a provisional notice by the UK's Information Commissioner's Office (ICO) to stop processing its citizens' data citing a range of alleged breaches. The company was also notified of a potential fine of approximately $22.6 million. Clearview claimed that the ICO's allegations were factually inaccurate as the company \"does not do business in the UK, and does not have any UK customers at this time\". The BBC reported on 23 May that the company had been fined \"more than £7.5m by the UK's privacy watchdog and told to delete the data of UK residents\".[107] Clearview was also ordered to delete all facial recognition data of UK residents. This fine marked the fourth of its type placed on Clearview, after similar orders and fines issued from Australia, France, and Italy.[9] However, in October 2023, this fine was overturned following an appeal based on the jurisdiction of the ICO over acts of foreign governments.[108]\n\nIn September 2024, Clearview AI was fined €30.5 million by the Dutch Data Protection Authority (DPA) for constructing what the agency described as an illegal database.[109] The DPA's ruling highlighted that Clearview AI unlawfully collected facial images, including those of Dutch citizens, without obtaining their consent. This practice constitutes a significant violation of the EU's GDPR due to the intrusive nature of facial recognition technology and the lack of transparency regarding the use of individuals' biometric data.[110]\n\nSee also [ edit ]",
            "url": "https://en.wikipedia.org/wiki/Clearview_AI#Usage",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "privacy",
                "recognition",
                "company",
                "used",
                "clearviews",
                "data",
                "2020",
                "ai",
                "clearview",
                "facial"
            ],
            "summary": "[21]Usage [ edit ]Clearview AI provides facial recognition software where users can upload an image of a face and match it against their database.\n[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.\n[62][8]In April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.\n[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.\nAmerican law enforcement and governmentInternational law enforcementLegal challenges [ edit ]Clearview AI has had its business model challenged by several lawsuits in multiple jurisdictions.",
            "metadata": {
                "source_domain": "en.wikipedia.org",
                "scrape_date": "2024-10-25T12:40:19.632487",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 23454
            }
        },
        {
            "title": "Clearview AI",
            "text": "American facial recognition software company\n\nClearview AI, Inc. is an American facial recognition company, providing software primarily to law enforcement and other government agencies.[2] The company's algorithm matches faces to a database of more than 20 billion images collected from the Internet, including social media applications.[1] Founded by Hoan Ton-That and Richard Schwartz, the company maintained a low profile until late 2019, until its usage by law enforcement was first reported.[3]\n\nUse of the facial recognition tool has been controversial. Several U.S. senators have expressed concern about privacy rights and the American Civil Liberties Union (ACLU) has sued the company for violating privacy laws on several occasions. U.S. police have used the software to apprehend suspected criminals.[4][5][6] Clearview's practices have led to fines and bans by EU nations for violating privacy laws, and investigations in the U.S. and other countries.[7][8][9] In 2022, Clearview reached a settlement with the ACLU, in which they agreed to restrict U.S. market sales of facial recognition services to government entities.\n\nClearview AI was the victim of a data breach in 2020 which exposed their customer list. This demonstrated 2,200 organizations in 27 countries had accounts with facial recognition searches.[10]\n\nHistory [ edit ]\n\nClearview AI was founded in 2017 by Hoan Ton-That and Richard Schwartz after transferring the assets of another company, SmartCheckr, which the pair originally founded in 2017 alongside Charles C. Johnson.[11][3] The company was founded in Manhattan after the founders met at the Manhattan Institute.[1] The company initially raised $8.4 million from investors including Kirenaga Partners and Peter Thiel.[12] Additional fundraising, in 2020, collected $8.625 million in exchange for equity. The company did not disclose investors in the second round. In 2021, another fundraising round received $30 million. Early use of Clearview's app was given to potential investors in their Series A fundraising round. Billionaire John Catsimatidis used it to identify someone his daughter dated and piloted it at one of his Gristedes grocery markets in New York City to identify shoplifters.[14][15]\n\nIn October 2020, a company spokesperson claimed that Clearview AI's valuation was more than $100 million.[16] The company announced its first chief strategy officer, chief revenue officer, and chief marketing officer in May 2021. Devesh Ashra, a former deputy assistant secretary with the United States Department of the Treasury, became its chief strategy officer. Chris Metaxas, a former executive at LexisNexis Risk Solutions, became its chief revenue officer. Susan Crandall, a former marketing executive at LexisNexis Risk Solutions and Motorola Solutions, became its chief marketing officer.[17] Devesh Ashra and Chris Metaxas left the company in 2021. In August 2021, Clearview AI announced the formation of an advisory board including Raymond Kelly, Richard A. Clarke, Rudy Washington, Floyd Abrams, Lee S. Wolosky, and Owen West.[18] The company claimed to have scraped more than 10 billion images as of October 2021.[19] In May 2022, Clearview AI announced that it would be expanding sales of its facial recognition software to schools and lending platforms outside the U.S.[20]\n\nClearview AI hired a notable legal team to defend the company against several lawsuits that threatened their business model. Their legal staff includes Tor Ekeland, Lee S. Wolosky, Paul Clement, Floyd Abrams, and Jack Mulcaire.[21][1][22] Abrams stated the issue of privacy rights versus free speech in the First Amendment could reach the Supreme Court.[21]\n\nUsage [ edit ]\n\nClearview AI provides facial recognition software where users can upload an image of a face and match it against their database.[23] The software then supplies links to where the \"match\" can be found online.[24] The company operated in near secrecy until the release of an investigative report in The New York Times titled \"The Secretive Company That Might End Privacy as We Know It\" in January 2020. It maintained this secrecy by publishing fake information about the company's location and employees and erasing social media for the founders.[3][1][25] Citing the article, over 40 tech and civil rights organizations sent a letter to the Privacy and Civil Liberties Oversight Board (PCLOB) and four congressional committees, outlining their concerns with facial recognition and Clearview, and asking the PCLOB to suspend use of facial recognition.[26][27][28][1]\n\nClearview served to accelerate a global debate on the regulation of facial recognition technology by governments and law enforcement.[29][30] Law enforcement officers have stated that Clearview's facial recognition is far superior in identifying perpetrators from any angle than previously used technology.[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.[32] On February 5 and 6, 2020, Google, YouTube, Facebook, and Venmo sent cease and desist letters as it is against their policies.[33][34] Ton-That responded in an interview that there is a First Amendment right to access public data. He later stated that Clearview has scraped over 50 billion images from across the web.[29][35][36]\n\nThe New Zealand Police used it in a trial after being approached by Clearview's Marko Jukic in January 2020. Jukic said it would have helped identify the Christchurch mosque shooter had the technology been available. The usage of Clearview's software in this case raised strong objections once exposed, as neither the users' supervisors or the Privacy Commissioner were aware or approved of its use. After it was revealed by RNZ, Justice Minister Andrew Little stated, \"It clearly wasn't endorsed, from the senior police hierarchy, and it clearly didn't get the endorsement from the [Police] Minister... that is a matter of concern.\"[37][38]\n\nClearview's technology was used for identifying an individual at a May 30, 2020 George Floyd police violence protest in Miami, Florida. Miami's WTVJ confirmed this, as the arrest report only said she was \"identified through investigative means\". The defendant's attorney did not even know it was with Clearview. Ton-That confirmed its use, noting that it was not being used for surveillance, but only to investigate a crime.[39]\n\nIn December 2020, the ACLU of Washington sent a letter to Seattle mayor Jenny Durkan, asking her to ban the Seattle Police Department from using Clearview AI.[40] The letter cited public records retrieved by a local blogger, which showed one officer signing up for and repeatedly logging into the service, as well as corresponding with a company representative. While the ACLU letter raised concerns that the officer's usage violated the Seattle Surveillance Ordinance, an auditor at the City of Seattle Office of the Inspector General argued that the ordinance was designed to address the usage of surveillance technologies by the Department itself, not by an officer without the Department's knowledge.[41]\n\nAfter the January 6 riot at the United States Capitol, the Oxford Police Department in Alabama used Clearview's software to run a number of images posted by the Federal Bureau of Investigation in its public request for suspect information to generate leads for people present during the riot. Photo matches and information were sent to the FBI who declined to comment on its techniques.[5]\n\nIn March 2022, Ukraine's Ministry of Defence began using Clearview AI's facial recognition technology \"to uncover Russian assailants, combat misinformation and identify the dead\". Ton-That also claimed that Ukraine's MoD has \"more than 2 billion images from the Russian social media service VKontakte at its disposal\".[42] Ukrainian government agencies used Clearview over 5,000 times as of April 2022.[43][44] The company provided these accounts and searches for free.[45]\n\nIn a Florida case, Clearview's technology was used by defense attorneys to successfully locate a witness, resulting in the dismissal of vehicular homicide charges against the defendant.[46]\n\nLaw enforcement use of the facial recognition software grew rapidly in the United States. In 2022 more than one million searches were conducted. In 2023, this usage doubled.[36]\n\nMarketing efforts and pushback [ edit ]\n\nClearview AI encouraged user adoption by offering free trials to law enforcement officers rather than departments as a whole. The company additionally used its significant connections to the Republican Party to connect with police departments.[1][47] In onboarding emails, new users were encouraged to go beyond running one or two searches to \"[s]ee if you can reach 100 searches\".[48] During 2020, Clearview sold their facial recognition software for one tenth the cost of competitors.[3]\n\nClearview's marketing claimed their facial recognition led to a terrorist arrest. The identification was submitted to the New York Police Department tip line.[49] Clearview claims to have solved two other New York cases and 40 cold cases, later stating they submitted them to tip lines. NYPD stated they have no institutional relationship with Clearview, but their policies do not ban its use by individual officers. In 2020, thirty NYPD officers were confirmed to have Clearview accounts.[3] In April 2021, documents obtained by the Legal Aid Society under New York's Freedom Of Information Law demonstrated that Clearview had collaborated with the NYPD for years, contrary to past NYPD denials.[50] Clearview met with senior NYPD leadership and entered into a vendor contract with the NYPD.[48] Clearview came under renewed scrutiny for enabling officers to conduct large numbers of searches without formal oversight or approval.[50][48]\n\nThe company was sent a cease and desist letter from the office of New Jersey Attorney General Gurbir Grewal after including a promotional video on its website with images of Grewal.[51] Clearview had claimed that its app played a role in a New Jersey police sting. Grewal confirmed the software was used to identify a child predator, but he also banned the use of Clearview in New Jersey. Tor Ekeland, a lawyer for Clearview, confirmed the marketing video was taken down the same day.[4][52]\n\nIn March 2020, Clearview pitched their technology to states for use in contact tracing to assist with the COVID-19 pandemic.[53][54] A reporter found Clearview's search could identify him while he covered his nose and mouth like a COVID mask would.[45] The idea brought criticism from US senators and other commentators because it seemed the crisis was being used to push unreliable tools that violate personal privacy.[55][56]\n\nContrary to Clearview's initial claims that its service was sold only to law enforcement, a data breach in early 2020 revealed that numerous commercial organizations were on Clearview's customer list. For example, Clearview marketed to private security firms and to casinos.[57] Additionally, Clearview planned expansion to many countries, including authoritarian regimes.[58]\n\nSenator Edward J. Markey wrote to Clearview and Ton-That, stating \"Widespread use of your technology could facilitate dangerous behavior and could effectively destroy individuals' ability to go about their daily lives anonymously.\" Markey asked Clearview to detail aspects of its business, in order to understand these privacy, bias, and security concerns.[32][59] Clearview responded through an attorney, declining to reveal information.[60] In response to this, Markey wrote a second letter, saying their response was unacceptable and contained dubious claims, and that he was concerned about Clearview \"selling its technology to authoritarian regimes\" and possible violations of COPPA.[8][61] Senator Markey wrote a third letter to the company with concerns, stating \"this health crisis cannot justify using unreliable surveillance tools that could undermine our privacy rights.\" Markey asked a series of questions about what government entities Clearview has been talking with, in addition to unanswered privacy concerns.[55]\n\nSenator Ron Wyden voiced concerns about Clearview and had meetings with Ton-That cancelled on three occasions.[62][8]\n\nIn April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.[63]\n\nTechnology [ edit ]\n\nAccuracy [ edit ]\n\nIn October 2021 Clearview submitted its algorithm to one of two facial recognition accuracy tests conducted by the National Institute of Standards and Technology (NIST) every few months. Clearview ranked amongst the top 10 of 300 facial recognition algorithms in a test to determine accuracy in matching two different photos of the same person. Clearview did not submit to the NIST test for matching an unknown face to a 10 billion image database, which more-closely matches the algorithm's intended purpose. This was the first third-party test of the software.[19]\n\nClearview, at various times throughout 2020, has claimed 98.6%, 99.6%, or 100% accuracy. However, these results are from tests conducted by people affiliated with the company and have not used representative samples of the population.[29][64][65]\n\nIn 2021, Clearview announced that it was developing \"deblur\" and \"mask removal\" tools to sharpen blurred images and envision the covered part of an individual's face. These tools would be implemented using machine learning models that fill in the missing details based on statistical patterns found in other images. Clearview acknowledged that deblurring an image and/or removing a mask could potentially make errors more frequent and would only be used to generate leads for police investigations.[35]\n\nAssistant Chief of Police of Miami, Armando Aguilar, said in 2023 that Clearview's AI tool had contributed to the resolution of several murder cases, and that his team had used the technology around 450 times a year. Aguilar emphasized that they do not make arrests based on Clearview's matches alone, and instead use the data as a lead and then proceed via conventional methods of case investigation.[24]\n\nSeveral cases of mistaken identity using Clearview facial recognition have been documented, but \"the lack of data and transparency around police use means the true figure is likely far higher.\" Ton-That claims the technology has approximately 100% accuracy, and attributes mistakes to potential poor policing practices. Ton-That's claimed accuracy level is based on mugshots and would be affected by the quality of the image uploaded.[24]\n\nData breaches [ edit ]\n\nClearview AI experienced a data breach in February 2020 which exposed its list of customers. Clearview's attorney, Tor Ekeland stated the security flaw was corrected.[66] In response to the leaks, the United States House Committee on Science, Space, and Technology sent a letter to the company requesting further insight into their bio-metric and security practices.[67]\n\nWhile Clearview's app is only supposed to be privately accessible to customers, the Android application package and iOS applications were found in unsecured Amazon S3 buckets.[68] The instructions showed how to load an enterprise (developer) certificate so the app could be installed without being published on the App Store. Clearview's access was suspended, as it was against Apple's terms of service for developers, and as a result the app was disabled.[69] In addition to application tracking (Google Analytics, Crashlytics), examination of the source code for the Android version found references to Google Play Services, requests for precise phone location data, voice search, sharing a free demo account to other users, augmented reality integration with Vuzix, and sending gallery photos or taking photos from the app itself. There were also references to scanning barcodes on a drivers license and to RealWear.[70]\n\nIn April 2020, Mossab Hussein of SpiderSilk, a security firm, discovered Clearview's source code repositories were exposed due to misconfigured user security settings. This included secret keys and credentials, including cloud storage and Slack tokens. The compiled apps and pre-release apps were accessible, allowing Hussein to run the macOS and iOS apps against Clearview's services. Hussein reported the breach to Clearview but refused to sign a non-disclosure agreement necessary for Clearview's bug bounty program. Ton-That reacted by calling Hussein's disclosure of the bug as an act of extortion. Hussein also found 70,000 videos in one storage bucket from a Rudin Management apartment building's entrance.[71]\n\nInsight Camera [ edit ]\n\nClearview also operates a secondary business, Insight Camera, which provides AI-enabled security cameras. It is targeted at \"retail, banking and residential buildings\". Two customers have used the technology, United Federation of Teachers and Rudin Management.[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.[74]\n\nCustomer list [ edit ]\n\nFollowing a data leak of Clearview's customer list, BuzzFeed confirmed that 2,200 organizations in 27 countries had accounts with activity. BuzzFeed has the exclusive right to publish this list and has chosen not publish it in its entirety.[10] Clearview AI claims that at least 600 of these users are police departments. These are primarily in the U.S. and Canada, but Clearview has expanded to other countries as well.[3] Although the company claims their services are for law enforcement, they have had contracts with Bank of America, Kohls, and Macy's. Several universities and high schools have done trials with Clearview.[10] The list below highlights particularly notable users.\n\nAmerican law enforcement and government\n\nInternational law enforcement\n\nLegal challenges [ edit ]\n\nClearview AI has had its business model challenged by several lawsuits in multiple jurisdictions. It responded by defending itself, settling in some cases, and exiting several markets.\n\nThe company's claim of a First Amendment right to public information has been disputed by privacy lawyers such as Scott Skinner-Thompson and Margot Kaminski, highlighting the problems and precedents surrounding persistent surveillance and anonymity.[34][89] Former New York City Police Commissioner and executive chairman of Teneo Risk Chief Bill Bratton challenged privacy concerns and recommended strict procedures for law enforcement usage in an op-ed in New York Daily News.[90]\n\nUnited States [ edit ]\n\nAfter the release of The New York Times January 2020 article, lawsuits were filed by the states of Illinois, California, Virginia and New York, citing violations of privacy and safety laws.[91] Most of the lawsuits were transferred to New York's Southern District.[92] Two lawsuits were filed in state courts; in Vermont by the attorney general and in Illinois on behalf of the American Civil Liberties Union (ACLU), which cited a statute that forbids the corporate use of residents' faceprints without explicit consent. Clearview countered that an Illinois law does not apply to a company based in New York.[21]\n\nIn response to a class action lawsuit filed in Illinois for violating the Biometric Information Privacy Act (BIPA), in May 2020 Clearview stated that they instituted a policy to stop working with non-government entities and to remove any photos geolocated in Illinois.[93][94][75] On May 28, 2020, ACLU and Edelson filed a new suit Clearview in Illinois using the BIPA.[95][96] Clearview agreed to a settlement in June 2024, offering 23% of the company (valued at $52 million at the time) rather than a cash settlement, which was likely to bankrupt the company.[97]\n\nIn May 2022, Clearview agreed to settle the 2020 lawsuit from the ACLU. The settlement prohibited the sale of its facial recognition database to private individuals and businesses.[98]\n\nIn the Vermont case, Clearview AI invoked Section 230 immunity. The court denied the use of Section 230 immunity in this case because Vermont's claims were \"based on the means by which Clearview acquired the photographs\" rather than third party content.[99]\n\nCanada [ edit ]\n\nIn July 2020, Clearview AI announced that it was exiting the Canadian market amidst joint investigations into the company and the use of its product by police forces.[100] Daniel Therrien, the Privacy Commissioner of Canada condemned Clearview AI's use of scraped biometric data: \"What Clearview does is mass surveillance and it is illegal. It is completely unacceptable for millions of people who will never be implicated in any crime to find themselves continually in a police lineup.\"[101] In June 2021, Therrien found that the Royal Canadian Mounted Police had broken Canadian privacy law through hundreds of illegal searches using Clearview AI.[102]\n\nEuropean Union and UK [ edit ]\n\nIn January 2021, Clearview AI's biometric photo database was deemed illegal in the European Union (EU) by the Hamburg Data Protection Authority (DPA). The deletion of an affected person's biometric data was ordered. The authority stated that the General Data Protection Regulation (GDPR) is applicable despite the fact that Clearview AI has no European branch.[103] In March 2020, they had requested Clearview AI's customer list, as data protection obligations would also apply to the customers.[104] The data protection advocacy organization NOYB criticized the DPA's decision as the DPA issued an order protecting only the individual complainant instead of an order banning the collection of any European resident's photos.[105]\n\nIn May 2021, the company had numerous legal complaints filed in Austria, France, Greece, Italy and the United Kingdom for violating European privacy laws in its method of documenting and collecting Internet data.[106] In November 2021, Clearview received a provisional notice by the UK's Information Commissioner's Office (ICO) to stop processing its citizens' data citing a range of alleged breaches. The company was also notified of a potential fine of approximately $22.6 million. Clearview claimed that the ICO's allegations were factually inaccurate as the company \"does not do business in the UK, and does not have any UK customers at this time\". The BBC reported on 23 May that the company had been fined \"more than £7.5m by the UK's privacy watchdog and told to delete the data of UK residents\".[107] Clearview was also ordered to delete all facial recognition data of UK residents. This fine marked the fourth of its type placed on Clearview, after similar orders and fines issued from Australia, France, and Italy.[9] However, in October 2023, this fine was overturned following an appeal based on the jurisdiction of the ICO over acts of foreign governments.[108]\n\nIn September 2024, Clearview AI was fined €30.5 million by the Dutch Data Protection Authority (DPA) for constructing what the agency described as an illegal database.[109] The DPA's ruling highlighted that Clearview AI unlawfully collected facial images, including those of Dutch citizens, without obtaining their consent. This practice constitutes a significant violation of the EU's GDPR due to the intrusive nature of facial recognition technology and the lack of transparency regarding the use of individuals' biometric data.[110]\n\nSee also [ edit ]",
            "url": "https://en.wikipedia.org/wiki/Clearview_AI#Technology",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "privacy",
                "recognition",
                "company",
                "used",
                "clearviews",
                "data",
                "2020",
                "ai",
                "clearview",
                "facial"
            ],
            "summary": "[21]Usage [ edit ]Clearview AI provides facial recognition software where users can upload an image of a face and match it against their database.\n[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.\n[62][8]In April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.\n[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.\nAmerican law enforcement and governmentInternational law enforcementLegal challenges [ edit ]Clearview AI has had its business model challenged by several lawsuits in multiple jurisdictions.",
            "metadata": {
                "source_domain": "en.wikipedia.org",
                "scrape_date": "2024-10-25T12:40:20.178316",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 23454
            }
        },
        {
            "title": "Clearview AI",
            "text": "American facial recognition software company\n\nClearview AI, Inc. is an American facial recognition company, providing software primarily to law enforcement and other government agencies.[2] The company's algorithm matches faces to a database of more than 20 billion images collected from the Internet, including social media applications.[1] Founded by Hoan Ton-That and Richard Schwartz, the company maintained a low profile until late 2019, until its usage by law enforcement was first reported.[3]\n\nUse of the facial recognition tool has been controversial. Several U.S. senators have expressed concern about privacy rights and the American Civil Liberties Union (ACLU) has sued the company for violating privacy laws on several occasions. U.S. police have used the software to apprehend suspected criminals.[4][5][6] Clearview's practices have led to fines and bans by EU nations for violating privacy laws, and investigations in the U.S. and other countries.[7][8][9] In 2022, Clearview reached a settlement with the ACLU, in which they agreed to restrict U.S. market sales of facial recognition services to government entities.\n\nClearview AI was the victim of a data breach in 2020 which exposed their customer list. This demonstrated 2,200 organizations in 27 countries had accounts with facial recognition searches.[10]\n\nHistory [ edit ]\n\nClearview AI was founded in 2017 by Hoan Ton-That and Richard Schwartz after transferring the assets of another company, SmartCheckr, which the pair originally founded in 2017 alongside Charles C. Johnson.[11][3] The company was founded in Manhattan after the founders met at the Manhattan Institute.[1] The company initially raised $8.4 million from investors including Kirenaga Partners and Peter Thiel.[12] Additional fundraising, in 2020, collected $8.625 million in exchange for equity. The company did not disclose investors in the second round. In 2021, another fundraising round received $30 million. Early use of Clearview's app was given to potential investors in their Series A fundraising round. Billionaire John Catsimatidis used it to identify someone his daughter dated and piloted it at one of his Gristedes grocery markets in New York City to identify shoplifters.[14][15]\n\nIn October 2020, a company spokesperson claimed that Clearview AI's valuation was more than $100 million.[16] The company announced its first chief strategy officer, chief revenue officer, and chief marketing officer in May 2021. Devesh Ashra, a former deputy assistant secretary with the United States Department of the Treasury, became its chief strategy officer. Chris Metaxas, a former executive at LexisNexis Risk Solutions, became its chief revenue officer. Susan Crandall, a former marketing executive at LexisNexis Risk Solutions and Motorola Solutions, became its chief marketing officer.[17] Devesh Ashra and Chris Metaxas left the company in 2021. In August 2021, Clearview AI announced the formation of an advisory board including Raymond Kelly, Richard A. Clarke, Rudy Washington, Floyd Abrams, Lee S. Wolosky, and Owen West.[18] The company claimed to have scraped more than 10 billion images as of October 2021.[19] In May 2022, Clearview AI announced that it would be expanding sales of its facial recognition software to schools and lending platforms outside the U.S.[20]\n\nClearview AI hired a notable legal team to defend the company against several lawsuits that threatened their business model. Their legal staff includes Tor Ekeland, Lee S. Wolosky, Paul Clement, Floyd Abrams, and Jack Mulcaire.[21][1][22] Abrams stated the issue of privacy rights versus free speech in the First Amendment could reach the Supreme Court.[21]\n\nUsage [ edit ]\n\nClearview AI provides facial recognition software where users can upload an image of a face and match it against their database.[23] The software then supplies links to where the \"match\" can be found online.[24] The company operated in near secrecy until the release of an investigative report in The New York Times titled \"The Secretive Company That Might End Privacy as We Know It\" in January 2020. It maintained this secrecy by publishing fake information about the company's location and employees and erasing social media for the founders.[3][1][25] Citing the article, over 40 tech and civil rights organizations sent a letter to the Privacy and Civil Liberties Oversight Board (PCLOB) and four congressional committees, outlining their concerns with facial recognition and Clearview, and asking the PCLOB to suspend use of facial recognition.[26][27][28][1]\n\nClearview served to accelerate a global debate on the regulation of facial recognition technology by governments and law enforcement.[29][30] Law enforcement officers have stated that Clearview's facial recognition is far superior in identifying perpetrators from any angle than previously used technology.[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.[32] On February 5 and 6, 2020, Google, YouTube, Facebook, and Venmo sent cease and desist letters as it is against their policies.[33][34] Ton-That responded in an interview that there is a First Amendment right to access public data. He later stated that Clearview has scraped over 50 billion images from across the web.[29][35][36]\n\nThe New Zealand Police used it in a trial after being approached by Clearview's Marko Jukic in January 2020. Jukic said it would have helped identify the Christchurch mosque shooter had the technology been available. The usage of Clearview's software in this case raised strong objections once exposed, as neither the users' supervisors or the Privacy Commissioner were aware or approved of its use. After it was revealed by RNZ, Justice Minister Andrew Little stated, \"It clearly wasn't endorsed, from the senior police hierarchy, and it clearly didn't get the endorsement from the [Police] Minister... that is a matter of concern.\"[37][38]\n\nClearview's technology was used for identifying an individual at a May 30, 2020 George Floyd police violence protest in Miami, Florida. Miami's WTVJ confirmed this, as the arrest report only said she was \"identified through investigative means\". The defendant's attorney did not even know it was with Clearview. Ton-That confirmed its use, noting that it was not being used for surveillance, but only to investigate a crime.[39]\n\nIn December 2020, the ACLU of Washington sent a letter to Seattle mayor Jenny Durkan, asking her to ban the Seattle Police Department from using Clearview AI.[40] The letter cited public records retrieved by a local blogger, which showed one officer signing up for and repeatedly logging into the service, as well as corresponding with a company representative. While the ACLU letter raised concerns that the officer's usage violated the Seattle Surveillance Ordinance, an auditor at the City of Seattle Office of the Inspector General argued that the ordinance was designed to address the usage of surveillance technologies by the Department itself, not by an officer without the Department's knowledge.[41]\n\nAfter the January 6 riot at the United States Capitol, the Oxford Police Department in Alabama used Clearview's software to run a number of images posted by the Federal Bureau of Investigation in its public request for suspect information to generate leads for people present during the riot. Photo matches and information were sent to the FBI who declined to comment on its techniques.[5]\n\nIn March 2022, Ukraine's Ministry of Defence began using Clearview AI's facial recognition technology \"to uncover Russian assailants, combat misinformation and identify the dead\". Ton-That also claimed that Ukraine's MoD has \"more than 2 billion images from the Russian social media service VKontakte at its disposal\".[42] Ukrainian government agencies used Clearview over 5,000 times as of April 2022.[43][44] The company provided these accounts and searches for free.[45]\n\nIn a Florida case, Clearview's technology was used by defense attorneys to successfully locate a witness, resulting in the dismissal of vehicular homicide charges against the defendant.[46]\n\nLaw enforcement use of the facial recognition software grew rapidly in the United States. In 2022 more than one million searches were conducted. In 2023, this usage doubled.[36]\n\nMarketing efforts and pushback [ edit ]\n\nClearview AI encouraged user adoption by offering free trials to law enforcement officers rather than departments as a whole. The company additionally used its significant connections to the Republican Party to connect with police departments.[1][47] In onboarding emails, new users were encouraged to go beyond running one or two searches to \"[s]ee if you can reach 100 searches\".[48] During 2020, Clearview sold their facial recognition software for one tenth the cost of competitors.[3]\n\nClearview's marketing claimed their facial recognition led to a terrorist arrest. The identification was submitted to the New York Police Department tip line.[49] Clearview claims to have solved two other New York cases and 40 cold cases, later stating they submitted them to tip lines. NYPD stated they have no institutional relationship with Clearview, but their policies do not ban its use by individual officers. In 2020, thirty NYPD officers were confirmed to have Clearview accounts.[3] In April 2021, documents obtained by the Legal Aid Society under New York's Freedom Of Information Law demonstrated that Clearview had collaborated with the NYPD for years, contrary to past NYPD denials.[50] Clearview met with senior NYPD leadership and entered into a vendor contract with the NYPD.[48] Clearview came under renewed scrutiny for enabling officers to conduct large numbers of searches without formal oversight or approval.[50][48]\n\nThe company was sent a cease and desist letter from the office of New Jersey Attorney General Gurbir Grewal after including a promotional video on its website with images of Grewal.[51] Clearview had claimed that its app played a role in a New Jersey police sting. Grewal confirmed the software was used to identify a child predator, but he also banned the use of Clearview in New Jersey. Tor Ekeland, a lawyer for Clearview, confirmed the marketing video was taken down the same day.[4][52]\n\nIn March 2020, Clearview pitched their technology to states for use in contact tracing to assist with the COVID-19 pandemic.[53][54] A reporter found Clearview's search could identify him while he covered his nose and mouth like a COVID mask would.[45] The idea brought criticism from US senators and other commentators because it seemed the crisis was being used to push unreliable tools that violate personal privacy.[55][56]\n\nContrary to Clearview's initial claims that its service was sold only to law enforcement, a data breach in early 2020 revealed that numerous commercial organizations were on Clearview's customer list. For example, Clearview marketed to private security firms and to casinos.[57] Additionally, Clearview planned expansion to many countries, including authoritarian regimes.[58]\n\nSenator Edward J. Markey wrote to Clearview and Ton-That, stating \"Widespread use of your technology could facilitate dangerous behavior and could effectively destroy individuals' ability to go about their daily lives anonymously.\" Markey asked Clearview to detail aspects of its business, in order to understand these privacy, bias, and security concerns.[32][59] Clearview responded through an attorney, declining to reveal information.[60] In response to this, Markey wrote a second letter, saying their response was unacceptable and contained dubious claims, and that he was concerned about Clearview \"selling its technology to authoritarian regimes\" and possible violations of COPPA.[8][61] Senator Markey wrote a third letter to the company with concerns, stating \"this health crisis cannot justify using unreliable surveillance tools that could undermine our privacy rights.\" Markey asked a series of questions about what government entities Clearview has been talking with, in addition to unanswered privacy concerns.[55]\n\nSenator Ron Wyden voiced concerns about Clearview and had meetings with Ton-That cancelled on three occasions.[62][8]\n\nIn April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.[63]\n\nTechnology [ edit ]\n\nAccuracy [ edit ]\n\nIn October 2021 Clearview submitted its algorithm to one of two facial recognition accuracy tests conducted by the National Institute of Standards and Technology (NIST) every few months. Clearview ranked amongst the top 10 of 300 facial recognition algorithms in a test to determine accuracy in matching two different photos of the same person. Clearview did not submit to the NIST test for matching an unknown face to a 10 billion image database, which more-closely matches the algorithm's intended purpose. This was the first third-party test of the software.[19]\n\nClearview, at various times throughout 2020, has claimed 98.6%, 99.6%, or 100% accuracy. However, these results are from tests conducted by people affiliated with the company and have not used representative samples of the population.[29][64][65]\n\nIn 2021, Clearview announced that it was developing \"deblur\" and \"mask removal\" tools to sharpen blurred images and envision the covered part of an individual's face. These tools would be implemented using machine learning models that fill in the missing details based on statistical patterns found in other images. Clearview acknowledged that deblurring an image and/or removing a mask could potentially make errors more frequent and would only be used to generate leads for police investigations.[35]\n\nAssistant Chief of Police of Miami, Armando Aguilar, said in 2023 that Clearview's AI tool had contributed to the resolution of several murder cases, and that his team had used the technology around 450 times a year. Aguilar emphasized that they do not make arrests based on Clearview's matches alone, and instead use the data as a lead and then proceed via conventional methods of case investigation.[24]\n\nSeveral cases of mistaken identity using Clearview facial recognition have been documented, but \"the lack of data and transparency around police use means the true figure is likely far higher.\" Ton-That claims the technology has approximately 100% accuracy, and attributes mistakes to potential poor policing practices. Ton-That's claimed accuracy level is based on mugshots and would be affected by the quality of the image uploaded.[24]\n\nData breaches [ edit ]\n\nClearview AI experienced a data breach in February 2020 which exposed its list of customers. Clearview's attorney, Tor Ekeland stated the security flaw was corrected.[66] In response to the leaks, the United States House Committee on Science, Space, and Technology sent a letter to the company requesting further insight into their bio-metric and security practices.[67]\n\nWhile Clearview's app is only supposed to be privately accessible to customers, the Android application package and iOS applications were found in unsecured Amazon S3 buckets.[68] The instructions showed how to load an enterprise (developer) certificate so the app could be installed without being published on the App Store. Clearview's access was suspended, as it was against Apple's terms of service for developers, and as a result the app was disabled.[69] In addition to application tracking (Google Analytics, Crashlytics), examination of the source code for the Android version found references to Google Play Services, requests for precise phone location data, voice search, sharing a free demo account to other users, augmented reality integration with Vuzix, and sending gallery photos or taking photos from the app itself. There were also references to scanning barcodes on a drivers license and to RealWear.[70]\n\nIn April 2020, Mossab Hussein of SpiderSilk, a security firm, discovered Clearview's source code repositories were exposed due to misconfigured user security settings. This included secret keys and credentials, including cloud storage and Slack tokens. The compiled apps and pre-release apps were accessible, allowing Hussein to run the macOS and iOS apps against Clearview's services. Hussein reported the breach to Clearview but refused to sign a non-disclosure agreement necessary for Clearview's bug bounty program. Ton-That reacted by calling Hussein's disclosure of the bug as an act of extortion. Hussein also found 70,000 videos in one storage bucket from a Rudin Management apartment building's entrance.[71]\n\nInsight Camera [ edit ]\n\nClearview also operates a secondary business, Insight Camera, which provides AI-enabled security cameras. It is targeted at \"retail, banking and residential buildings\". Two customers have used the technology, United Federation of Teachers and Rudin Management.[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.[74]\n\nCustomer list [ edit ]\n\nFollowing a data leak of Clearview's customer list, BuzzFeed confirmed that 2,200 organizations in 27 countries had accounts with activity. BuzzFeed has the exclusive right to publish this list and has chosen not publish it in its entirety.[10] Clearview AI claims that at least 600 of these users are police departments. These are primarily in the U.S. and Canada, but Clearview has expanded to other countries as well.[3] Although the company claims their services are for law enforcement, they have had contracts with Bank of America, Kohls, and Macy's. Several universities and high schools have done trials with Clearview.[10] The list below highlights particularly notable users.\n\nAmerican law enforcement and government\n\nInternational law enforcement\n\nLegal challenges [ edit ]\n\nClearview AI has had its business model challenged by several lawsuits in multiple jurisdictions. It responded by defending itself, settling in some cases, and exiting several markets.\n\nThe company's claim of a First Amendment right to public information has been disputed by privacy lawyers such as Scott Skinner-Thompson and Margot Kaminski, highlighting the problems and precedents surrounding persistent surveillance and anonymity.[34][89] Former New York City Police Commissioner and executive chairman of Teneo Risk Chief Bill Bratton challenged privacy concerns and recommended strict procedures for law enforcement usage in an op-ed in New York Daily News.[90]\n\nUnited States [ edit ]\n\nAfter the release of The New York Times January 2020 article, lawsuits were filed by the states of Illinois, California, Virginia and New York, citing violations of privacy and safety laws.[91] Most of the lawsuits were transferred to New York's Southern District.[92] Two lawsuits were filed in state courts; in Vermont by the attorney general and in Illinois on behalf of the American Civil Liberties Union (ACLU), which cited a statute that forbids the corporate use of residents' faceprints without explicit consent. Clearview countered that an Illinois law does not apply to a company based in New York.[21]\n\nIn response to a class action lawsuit filed in Illinois for violating the Biometric Information Privacy Act (BIPA), in May 2020 Clearview stated that they instituted a policy to stop working with non-government entities and to remove any photos geolocated in Illinois.[93][94][75] On May 28, 2020, ACLU and Edelson filed a new suit Clearview in Illinois using the BIPA.[95][96] Clearview agreed to a settlement in June 2024, offering 23% of the company (valued at $52 million at the time) rather than a cash settlement, which was likely to bankrupt the company.[97]\n\nIn May 2022, Clearview agreed to settle the 2020 lawsuit from the ACLU. The settlement prohibited the sale of its facial recognition database to private individuals and businesses.[98]\n\nIn the Vermont case, Clearview AI invoked Section 230 immunity. The court denied the use of Section 230 immunity in this case because Vermont's claims were \"based on the means by which Clearview acquired the photographs\" rather than third party content.[99]\n\nCanada [ edit ]\n\nIn July 2020, Clearview AI announced that it was exiting the Canadian market amidst joint investigations into the company and the use of its product by police forces.[100] Daniel Therrien, the Privacy Commissioner of Canada condemned Clearview AI's use of scraped biometric data: \"What Clearview does is mass surveillance and it is illegal. It is completely unacceptable for millions of people who will never be implicated in any crime to find themselves continually in a police lineup.\"[101] In June 2021, Therrien found that the Royal Canadian Mounted Police had broken Canadian privacy law through hundreds of illegal searches using Clearview AI.[102]\n\nEuropean Union and UK [ edit ]\n\nIn January 2021, Clearview AI's biometric photo database was deemed illegal in the European Union (EU) by the Hamburg Data Protection Authority (DPA). The deletion of an affected person's biometric data was ordered. The authority stated that the General Data Protection Regulation (GDPR) is applicable despite the fact that Clearview AI has no European branch.[103] In March 2020, they had requested Clearview AI's customer list, as data protection obligations would also apply to the customers.[104] The data protection advocacy organization NOYB criticized the DPA's decision as the DPA issued an order protecting only the individual complainant instead of an order banning the collection of any European resident's photos.[105]\n\nIn May 2021, the company had numerous legal complaints filed in Austria, France, Greece, Italy and the United Kingdom for violating European privacy laws in its method of documenting and collecting Internet data.[106] In November 2021, Clearview received a provisional notice by the UK's Information Commissioner's Office (ICO) to stop processing its citizens' data citing a range of alleged breaches. The company was also notified of a potential fine of approximately $22.6 million. Clearview claimed that the ICO's allegations were factually inaccurate as the company \"does not do business in the UK, and does not have any UK customers at this time\". The BBC reported on 23 May that the company had been fined \"more than £7.5m by the UK's privacy watchdog and told to delete the data of UK residents\".[107] Clearview was also ordered to delete all facial recognition data of UK residents. This fine marked the fourth of its type placed on Clearview, after similar orders and fines issued from Australia, France, and Italy.[9] However, in October 2023, this fine was overturned following an appeal based on the jurisdiction of the ICO over acts of foreign governments.[108]\n\nIn September 2024, Clearview AI was fined €30.5 million by the Dutch Data Protection Authority (DPA) for constructing what the agency described as an illegal database.[109] The DPA's ruling highlighted that Clearview AI unlawfully collected facial images, including those of Dutch citizens, without obtaining their consent. This practice constitutes a significant violation of the EU's GDPR due to the intrusive nature of facial recognition technology and the lack of transparency regarding the use of individuals' biometric data.[110]\n\nSee also [ edit ]",
            "url": "https://en.wikipedia.org/wiki/Clearview_AI#Customer_list",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "privacy",
                "recognition",
                "company",
                "used",
                "clearviews",
                "data",
                "2020",
                "ai",
                "clearview",
                "facial"
            ],
            "summary": "[21]Usage [ edit ]Clearview AI provides facial recognition software where users can upload an image of a face and match it against their database.\n[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.\n[62][8]In April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.\n[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.\nAmerican law enforcement and governmentInternational law enforcementLegal challenges [ edit ]Clearview AI has had its business model challenged by several lawsuits in multiple jurisdictions.",
            "metadata": {
                "source_domain": "en.wikipedia.org",
                "scrape_date": "2024-10-25T12:40:20.324085",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 23454
            }
        },
        {
            "title": "Clearview AI",
            "text": "American facial recognition software company\n\nClearview AI, Inc. is an American facial recognition company, providing software primarily to law enforcement and other government agencies.[2] The company's algorithm matches faces to a database of more than 20 billion images collected from the Internet, including social media applications.[1] Founded by Hoan Ton-That and Richard Schwartz, the company maintained a low profile until late 2019, until its usage by law enforcement was first reported.[3]\n\nUse of the facial recognition tool has been controversial. Several U.S. senators have expressed concern about privacy rights and the American Civil Liberties Union (ACLU) has sued the company for violating privacy laws on several occasions. U.S. police have used the software to apprehend suspected criminals.[4][5][6] Clearview's practices have led to fines and bans by EU nations for violating privacy laws, and investigations in the U.S. and other countries.[7][8][9] In 2022, Clearview reached a settlement with the ACLU, in which they agreed to restrict U.S. market sales of facial recognition services to government entities.\n\nClearview AI was the victim of a data breach in 2020 which exposed their customer list. This demonstrated 2,200 organizations in 27 countries had accounts with facial recognition searches.[10]\n\nHistory [ edit ]\n\nClearview AI was founded in 2017 by Hoan Ton-That and Richard Schwartz after transferring the assets of another company, SmartCheckr, which the pair originally founded in 2017 alongside Charles C. Johnson.[11][3] The company was founded in Manhattan after the founders met at the Manhattan Institute.[1] The company initially raised $8.4 million from investors including Kirenaga Partners and Peter Thiel.[12] Additional fundraising, in 2020, collected $8.625 million in exchange for equity. The company did not disclose investors in the second round. In 2021, another fundraising round received $30 million. Early use of Clearview's app was given to potential investors in their Series A fundraising round. Billionaire John Catsimatidis used it to identify someone his daughter dated and piloted it at one of his Gristedes grocery markets in New York City to identify shoplifters.[14][15]\n\nIn October 2020, a company spokesperson claimed that Clearview AI's valuation was more than $100 million.[16] The company announced its first chief strategy officer, chief revenue officer, and chief marketing officer in May 2021. Devesh Ashra, a former deputy assistant secretary with the United States Department of the Treasury, became its chief strategy officer. Chris Metaxas, a former executive at LexisNexis Risk Solutions, became its chief revenue officer. Susan Crandall, a former marketing executive at LexisNexis Risk Solutions and Motorola Solutions, became its chief marketing officer.[17] Devesh Ashra and Chris Metaxas left the company in 2021. In August 2021, Clearview AI announced the formation of an advisory board including Raymond Kelly, Richard A. Clarke, Rudy Washington, Floyd Abrams, Lee S. Wolosky, and Owen West.[18] The company claimed to have scraped more than 10 billion images as of October 2021.[19] In May 2022, Clearview AI announced that it would be expanding sales of its facial recognition software to schools and lending platforms outside the U.S.[20]\n\nClearview AI hired a notable legal team to defend the company against several lawsuits that threatened their business model. Their legal staff includes Tor Ekeland, Lee S. Wolosky, Paul Clement, Floyd Abrams, and Jack Mulcaire.[21][1][22] Abrams stated the issue of privacy rights versus free speech in the First Amendment could reach the Supreme Court.[21]\n\nUsage [ edit ]\n\nClearview AI provides facial recognition software where users can upload an image of a face and match it against their database.[23] The software then supplies links to where the \"match\" can be found online.[24] The company operated in near secrecy until the release of an investigative report in The New York Times titled \"The Secretive Company That Might End Privacy as We Know It\" in January 2020. It maintained this secrecy by publishing fake information about the company's location and employees and erasing social media for the founders.[3][1][25] Citing the article, over 40 tech and civil rights organizations sent a letter to the Privacy and Civil Liberties Oversight Board (PCLOB) and four congressional committees, outlining their concerns with facial recognition and Clearview, and asking the PCLOB to suspend use of facial recognition.[26][27][28][1]\n\nClearview served to accelerate a global debate on the regulation of facial recognition technology by governments and law enforcement.[29][30] Law enforcement officers have stated that Clearview's facial recognition is far superior in identifying perpetrators from any angle than previously used technology.[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.[32] On February 5 and 6, 2020, Google, YouTube, Facebook, and Venmo sent cease and desist letters as it is against their policies.[33][34] Ton-That responded in an interview that there is a First Amendment right to access public data. He later stated that Clearview has scraped over 50 billion images from across the web.[29][35][36]\n\nThe New Zealand Police used it in a trial after being approached by Clearview's Marko Jukic in January 2020. Jukic said it would have helped identify the Christchurch mosque shooter had the technology been available. The usage of Clearview's software in this case raised strong objections once exposed, as neither the users' supervisors or the Privacy Commissioner were aware or approved of its use. After it was revealed by RNZ, Justice Minister Andrew Little stated, \"It clearly wasn't endorsed, from the senior police hierarchy, and it clearly didn't get the endorsement from the [Police] Minister... that is a matter of concern.\"[37][38]\n\nClearview's technology was used for identifying an individual at a May 30, 2020 George Floyd police violence protest in Miami, Florida. Miami's WTVJ confirmed this, as the arrest report only said she was \"identified through investigative means\". The defendant's attorney did not even know it was with Clearview. Ton-That confirmed its use, noting that it was not being used for surveillance, but only to investigate a crime.[39]\n\nIn December 2020, the ACLU of Washington sent a letter to Seattle mayor Jenny Durkan, asking her to ban the Seattle Police Department from using Clearview AI.[40] The letter cited public records retrieved by a local blogger, which showed one officer signing up for and repeatedly logging into the service, as well as corresponding with a company representative. While the ACLU letter raised concerns that the officer's usage violated the Seattle Surveillance Ordinance, an auditor at the City of Seattle Office of the Inspector General argued that the ordinance was designed to address the usage of surveillance technologies by the Department itself, not by an officer without the Department's knowledge.[41]\n\nAfter the January 6 riot at the United States Capitol, the Oxford Police Department in Alabama used Clearview's software to run a number of images posted by the Federal Bureau of Investigation in its public request for suspect information to generate leads for people present during the riot. Photo matches and information were sent to the FBI who declined to comment on its techniques.[5]\n\nIn March 2022, Ukraine's Ministry of Defence began using Clearview AI's facial recognition technology \"to uncover Russian assailants, combat misinformation and identify the dead\". Ton-That also claimed that Ukraine's MoD has \"more than 2 billion images from the Russian social media service VKontakte at its disposal\".[42] Ukrainian government agencies used Clearview over 5,000 times as of April 2022.[43][44] The company provided these accounts and searches for free.[45]\n\nIn a Florida case, Clearview's technology was used by defense attorneys to successfully locate a witness, resulting in the dismissal of vehicular homicide charges against the defendant.[46]\n\nLaw enforcement use of the facial recognition software grew rapidly in the United States. In 2022 more than one million searches were conducted. In 2023, this usage doubled.[36]\n\nMarketing efforts and pushback [ edit ]\n\nClearview AI encouraged user adoption by offering free trials to law enforcement officers rather than departments as a whole. The company additionally used its significant connections to the Republican Party to connect with police departments.[1][47] In onboarding emails, new users were encouraged to go beyond running one or two searches to \"[s]ee if you can reach 100 searches\".[48] During 2020, Clearview sold their facial recognition software for one tenth the cost of competitors.[3]\n\nClearview's marketing claimed their facial recognition led to a terrorist arrest. The identification was submitted to the New York Police Department tip line.[49] Clearview claims to have solved two other New York cases and 40 cold cases, later stating they submitted them to tip lines. NYPD stated they have no institutional relationship with Clearview, but their policies do not ban its use by individual officers. In 2020, thirty NYPD officers were confirmed to have Clearview accounts.[3] In April 2021, documents obtained by the Legal Aid Society under New York's Freedom Of Information Law demonstrated that Clearview had collaborated with the NYPD for years, contrary to past NYPD denials.[50] Clearview met with senior NYPD leadership and entered into a vendor contract with the NYPD.[48] Clearview came under renewed scrutiny for enabling officers to conduct large numbers of searches without formal oversight or approval.[50][48]\n\nThe company was sent a cease and desist letter from the office of New Jersey Attorney General Gurbir Grewal after including a promotional video on its website with images of Grewal.[51] Clearview had claimed that its app played a role in a New Jersey police sting. Grewal confirmed the software was used to identify a child predator, but he also banned the use of Clearview in New Jersey. Tor Ekeland, a lawyer for Clearview, confirmed the marketing video was taken down the same day.[4][52]\n\nIn March 2020, Clearview pitched their technology to states for use in contact tracing to assist with the COVID-19 pandemic.[53][54] A reporter found Clearview's search could identify him while he covered his nose and mouth like a COVID mask would.[45] The idea brought criticism from US senators and other commentators because it seemed the crisis was being used to push unreliable tools that violate personal privacy.[55][56]\n\nContrary to Clearview's initial claims that its service was sold only to law enforcement, a data breach in early 2020 revealed that numerous commercial organizations were on Clearview's customer list. For example, Clearview marketed to private security firms and to casinos.[57] Additionally, Clearview planned expansion to many countries, including authoritarian regimes.[58]\n\nSenator Edward J. Markey wrote to Clearview and Ton-That, stating \"Widespread use of your technology could facilitate dangerous behavior and could effectively destroy individuals' ability to go about their daily lives anonymously.\" Markey asked Clearview to detail aspects of its business, in order to understand these privacy, bias, and security concerns.[32][59] Clearview responded through an attorney, declining to reveal information.[60] In response to this, Markey wrote a second letter, saying their response was unacceptable and contained dubious claims, and that he was concerned about Clearview \"selling its technology to authoritarian regimes\" and possible violations of COPPA.[8][61] Senator Markey wrote a third letter to the company with concerns, stating \"this health crisis cannot justify using unreliable surveillance tools that could undermine our privacy rights.\" Markey asked a series of questions about what government entities Clearview has been talking with, in addition to unanswered privacy concerns.[55]\n\nSenator Ron Wyden voiced concerns about Clearview and had meetings with Ton-That cancelled on three occasions.[62][8]\n\nIn April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.[63]\n\nTechnology [ edit ]\n\nAccuracy [ edit ]\n\nIn October 2021 Clearview submitted its algorithm to one of two facial recognition accuracy tests conducted by the National Institute of Standards and Technology (NIST) every few months. Clearview ranked amongst the top 10 of 300 facial recognition algorithms in a test to determine accuracy in matching two different photos of the same person. Clearview did not submit to the NIST test for matching an unknown face to a 10 billion image database, which more-closely matches the algorithm's intended purpose. This was the first third-party test of the software.[19]\n\nClearview, at various times throughout 2020, has claimed 98.6%, 99.6%, or 100% accuracy. However, these results are from tests conducted by people affiliated with the company and have not used representative samples of the population.[29][64][65]\n\nIn 2021, Clearview announced that it was developing \"deblur\" and \"mask removal\" tools to sharpen blurred images and envision the covered part of an individual's face. These tools would be implemented using machine learning models that fill in the missing details based on statistical patterns found in other images. Clearview acknowledged that deblurring an image and/or removing a mask could potentially make errors more frequent and would only be used to generate leads for police investigations.[35]\n\nAssistant Chief of Police of Miami, Armando Aguilar, said in 2023 that Clearview's AI tool had contributed to the resolution of several murder cases, and that his team had used the technology around 450 times a year. Aguilar emphasized that they do not make arrests based on Clearview's matches alone, and instead use the data as a lead and then proceed via conventional methods of case investigation.[24]\n\nSeveral cases of mistaken identity using Clearview facial recognition have been documented, but \"the lack of data and transparency around police use means the true figure is likely far higher.\" Ton-That claims the technology has approximately 100% accuracy, and attributes mistakes to potential poor policing practices. Ton-That's claimed accuracy level is based on mugshots and would be affected by the quality of the image uploaded.[24]\n\nData breaches [ edit ]\n\nClearview AI experienced a data breach in February 2020 which exposed its list of customers. Clearview's attorney, Tor Ekeland stated the security flaw was corrected.[66] In response to the leaks, the United States House Committee on Science, Space, and Technology sent a letter to the company requesting further insight into their bio-metric and security practices.[67]\n\nWhile Clearview's app is only supposed to be privately accessible to customers, the Android application package and iOS applications were found in unsecured Amazon S3 buckets.[68] The instructions showed how to load an enterprise (developer) certificate so the app could be installed without being published on the App Store. Clearview's access was suspended, as it was against Apple's terms of service for developers, and as a result the app was disabled.[69] In addition to application tracking (Google Analytics, Crashlytics), examination of the source code for the Android version found references to Google Play Services, requests for precise phone location data, voice search, sharing a free demo account to other users, augmented reality integration with Vuzix, and sending gallery photos or taking photos from the app itself. There were also references to scanning barcodes on a drivers license and to RealWear.[70]\n\nIn April 2020, Mossab Hussein of SpiderSilk, a security firm, discovered Clearview's source code repositories were exposed due to misconfigured user security settings. This included secret keys and credentials, including cloud storage and Slack tokens. The compiled apps and pre-release apps were accessible, allowing Hussein to run the macOS and iOS apps against Clearview's services. Hussein reported the breach to Clearview but refused to sign a non-disclosure agreement necessary for Clearview's bug bounty program. Ton-That reacted by calling Hussein's disclosure of the bug as an act of extortion. Hussein also found 70,000 videos in one storage bucket from a Rudin Management apartment building's entrance.[71]\n\nInsight Camera [ edit ]\n\nClearview also operates a secondary business, Insight Camera, which provides AI-enabled security cameras. It is targeted at \"retail, banking and residential buildings\". Two customers have used the technology, United Federation of Teachers and Rudin Management.[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.[74]\n\nCustomer list [ edit ]\n\nFollowing a data leak of Clearview's customer list, BuzzFeed confirmed that 2,200 organizations in 27 countries had accounts with activity. BuzzFeed has the exclusive right to publish this list and has chosen not publish it in its entirety.[10] Clearview AI claims that at least 600 of these users are police departments. These are primarily in the U.S. and Canada, but Clearview has expanded to other countries as well.[3] Although the company claims their services are for law enforcement, they have had contracts with Bank of America, Kohls, and Macy's. Several universities and high schools have done trials with Clearview.[10] The list below highlights particularly notable users.\n\nAmerican law enforcement and government\n\nInternational law enforcement\n\nLegal challenges [ edit ]\n\nClearview AI has had its business model challenged by several lawsuits in multiple jurisdictions. It responded by defending itself, settling in some cases, and exiting several markets.\n\nThe company's claim of a First Amendment right to public information has been disputed by privacy lawyers such as Scott Skinner-Thompson and Margot Kaminski, highlighting the problems and precedents surrounding persistent surveillance and anonymity.[34][89] Former New York City Police Commissioner and executive chairman of Teneo Risk Chief Bill Bratton challenged privacy concerns and recommended strict procedures for law enforcement usage in an op-ed in New York Daily News.[90]\n\nUnited States [ edit ]\n\nAfter the release of The New York Times January 2020 article, lawsuits were filed by the states of Illinois, California, Virginia and New York, citing violations of privacy and safety laws.[91] Most of the lawsuits were transferred to New York's Southern District.[92] Two lawsuits were filed in state courts; in Vermont by the attorney general and in Illinois on behalf of the American Civil Liberties Union (ACLU), which cited a statute that forbids the corporate use of residents' faceprints without explicit consent. Clearview countered that an Illinois law does not apply to a company based in New York.[21]\n\nIn response to a class action lawsuit filed in Illinois for violating the Biometric Information Privacy Act (BIPA), in May 2020 Clearview stated that they instituted a policy to stop working with non-government entities and to remove any photos geolocated in Illinois.[93][94][75] On May 28, 2020, ACLU and Edelson filed a new suit Clearview in Illinois using the BIPA.[95][96] Clearview agreed to a settlement in June 2024, offering 23% of the company (valued at $52 million at the time) rather than a cash settlement, which was likely to bankrupt the company.[97]\n\nIn May 2022, Clearview agreed to settle the 2020 lawsuit from the ACLU. The settlement prohibited the sale of its facial recognition database to private individuals and businesses.[98]\n\nIn the Vermont case, Clearview AI invoked Section 230 immunity. The court denied the use of Section 230 immunity in this case because Vermont's claims were \"based on the means by which Clearview acquired the photographs\" rather than third party content.[99]\n\nCanada [ edit ]\n\nIn July 2020, Clearview AI announced that it was exiting the Canadian market amidst joint investigations into the company and the use of its product by police forces.[100] Daniel Therrien, the Privacy Commissioner of Canada condemned Clearview AI's use of scraped biometric data: \"What Clearview does is mass surveillance and it is illegal. It is completely unacceptable for millions of people who will never be implicated in any crime to find themselves continually in a police lineup.\"[101] In June 2021, Therrien found that the Royal Canadian Mounted Police had broken Canadian privacy law through hundreds of illegal searches using Clearview AI.[102]\n\nEuropean Union and UK [ edit ]\n\nIn January 2021, Clearview AI's biometric photo database was deemed illegal in the European Union (EU) by the Hamburg Data Protection Authority (DPA). The deletion of an affected person's biometric data was ordered. The authority stated that the General Data Protection Regulation (GDPR) is applicable despite the fact that Clearview AI has no European branch.[103] In March 2020, they had requested Clearview AI's customer list, as data protection obligations would also apply to the customers.[104] The data protection advocacy organization NOYB criticized the DPA's decision as the DPA issued an order protecting only the individual complainant instead of an order banning the collection of any European resident's photos.[105]\n\nIn May 2021, the company had numerous legal complaints filed in Austria, France, Greece, Italy and the United Kingdom for violating European privacy laws in its method of documenting and collecting Internet data.[106] In November 2021, Clearview received a provisional notice by the UK's Information Commissioner's Office (ICO) to stop processing its citizens' data citing a range of alleged breaches. The company was also notified of a potential fine of approximately $22.6 million. Clearview claimed that the ICO's allegations were factually inaccurate as the company \"does not do business in the UK, and does not have any UK customers at this time\". The BBC reported on 23 May that the company had been fined \"more than £7.5m by the UK's privacy watchdog and told to delete the data of UK residents\".[107] Clearview was also ordered to delete all facial recognition data of UK residents. This fine marked the fourth of its type placed on Clearview, after similar orders and fines issued from Australia, France, and Italy.[9] However, in October 2023, this fine was overturned following an appeal based on the jurisdiction of the ICO over acts of foreign governments.[108]\n\nIn September 2024, Clearview AI was fined €30.5 million by the Dutch Data Protection Authority (DPA) for constructing what the agency described as an illegal database.[109] The DPA's ruling highlighted that Clearview AI unlawfully collected facial images, including those of Dutch citizens, without obtaining their consent. This practice constitutes a significant violation of the EU's GDPR due to the intrusive nature of facial recognition technology and the lack of transparency regarding the use of individuals' biometric data.[110]\n\nSee also [ edit ]",
            "url": "https://en.wikipedia.org/wiki/Clearview_AI#Legal_challenges",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "privacy",
                "recognition",
                "company",
                "used",
                "clearviews",
                "data",
                "2020",
                "ai",
                "clearview",
                "facial"
            ],
            "summary": "[21]Usage [ edit ]Clearview AI provides facial recognition software where users can upload an image of a face and match it against their database.\n[31] After discovering Clearview AI was scraping images from their site, Twitter sent a cease-and-desist letter to Clearview, insisting that they remove all images as scraping is against Twitter's policies.\n[62][8]In April 2021, Time magazine listed Clearview AI as one of the 100 most influential companies of the year.\n[72][73] The website for Insight Camera was taken down following BuzzFeed's investigation into he connection between Clearview AI and Insight Camera.\nAmerican law enforcement and governmentInternational law enforcementLegal challenges [ edit ]Clearview AI has had its business model challenged by several lawsuits in multiple jurisdictions.",
            "metadata": {
                "source_domain": "en.wikipedia.org",
                "scrape_date": "2024-10-25T12:40:20.845914",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 23454
            }
        },
        {
            "title": "Clearview AI used nearly 1m times by US police, it tells the BBC",
            "text": "Clearview AI used nearly 1m times by US police, it tells the BBC\n\nSpencer Whalen / EyeEm\n\nFacial recognition firm Clearview has run nearly a million searches for US police, its founder has told the BBC.\n\nCEO Hoan Ton-That also revealed Clearview now has 30bn images scraped from platforms such as Facebook, taken without users' permissions.\n\nThe company has been repeatedly fined millions of dollars in Europe and Australia for breaches of privacy.\n\nCritics argue that the police's use of Clearview puts everyone into a \"perpetual police line-up\".\n\n\"Whenever they have a photo of a suspect, they will compare it to your face,\" says Matthew Guariglia from the Electronic Frontier Foundation says. \"It's far too invasive.\"\n\nThe figure of a million searches comes from Clearview and has not been confirmed by police. But in a rare admission, Miami Police has confirmed to the BBC it uses this software for every type of crime.\n\nClearview's system allows a law enforcement customer to upload a photo of a face and find matches in a database of billions of images it has collected.\n\nIt then provides links to where matching images appear online. It is considered one of the most powerful and accurate facial recognition companies in the world.\n\nHoan Ton-That, founder and CEO of Clearview AI, speaking with the BBC\n\nThe company is banned from selling its services to most US companies, after the American Civil Liberties Union (ACLU) took Clearview AI to court in Illinois for breaking privacy law.\n\nBut there is an exemption for police, and Mr Ton-That says his software is used by hundreds of police forces across the US.\n\nPolice in the US do not routinely reveal whether they use the software, and it is banned in several US cities including Portland, San Francisco and Seattle.\n\nThe use of facial recognition by the police is often sold to the public as only being used for serious or violent crimes.\n\nIn a rare interview with law enforcement about the effectiveness of Clearview, Miami Police said they used the software for every type of crime, from murders to shoplifting.\n\nAssistant Chief of Police Armando Aguilar said his team used the system about 450 times a year, and that it had helped solve several murders.\n\nHowever, critics say there are almost no laws around the use of facial recognition by police.\n\nAssistant Chief of Miami Police, Armando Aguilar\n\nMr Aguilar says Miami police treats facial recognition like a tip. \"We don't make an arrest because an algorithm tells us to,\" he says. \"We either put that name in a photographic line-up or we go about solving the case through traditional means.\"\n\nMistaken identity\n\nThere are a handful of documented cases of mistaken identity using facial recognition by the police. However, the lack of data and transparency around police use means the true figure is likely far higher.\n\nMr Ton-That says he is not aware of any cases of mistaken identity using Clearview. He accepts police have made wrongful arrests using facial recognition technology, but attributes those to \"poor policing\".\n\nClearview often points to research that shows it has a near 100% accuracy rate. But these figures are often based on mugshots.\n\nIn reality, the accuracy of Clearview depends on the quality of the image that is fed into it - something Mr Ton-That accepts.\n\nCivil rights campaigners want police forces that use Clearview to openly say when it is used - and for its accuracy to be openly tested in court. They want the algorithm scrutinised by independent experts, and are sceptical of the company's claims.\n\nKaitlin Jackson is a criminal defence lawyer based in New York who campaigns against the police's use of facial recognition.\n\n\"I think the truth is that the idea that this is incredibly accurate is wishful thinking,\" she says. \"There is no way to know that when you're using images in the wild like screengrabs from CCTV.\"\n\nKaitlin Jackson, a New York defence lawyer\n\nHowever, Mr Ton-That told the BBC he does not want to testify in court to its accuracy.\n\n\"We don't really want to be in court testifying about the accuracy of the algorithm… because the investigators, they're using other methods to also verify it,\" he says.\n\nMr Ton-That says he has recently given Clearview's system to defence lawyers in specific cases. He believes that both prosecutors and defenders should have the same access to the technology.\n\nLast year, Andrew Conlyn from Fort Myers, Florida, had charges against him dropped after Clearview was used to find a crucial witness.\n\nMr Conlyn was the passenger in a friend's car in March 2017 when it crashed into palm trees at high speed.\n\nThe driver was ejected from the car and killed. A passer-by pulled Mr Conlyn from the wreckage, but left without making a statement.\n\nAlthough Mr Conlyn said he was the passenger, police suspected he had been driving and he he was charged with vehicular homicide.\n\nHis lawyers had an image of the passer-by from police body cam footage. Just before his trial, Mr Ton-That allowed Clearview to be used in the case.\n\n\"This AI popped him up in like, three to five seconds,\" Mr Conlyn's defence lawyer, Christopher O'Brien, told the BBC. \"It was phenomenal.\"\n\nAndrew Conlyn\n\nThe witness, Vince Ramirez, made a statement that he had taken Mr Conlyn out of the passenger's seat. Shortly after, the charges were dropped.\n\nBut even though there have been cases where Clearview is proven to have worked, some believe it comes at too high a price.\n\n\"Clearview is a private company that is making face prints of people based on their photos online without their consent,\" says Mr Guariglia.\n\n\"It's a huge problem for civil liberties and civil rights, and it absolutely needs to be banned.\"",
            "url": "https://www.bbc.com/news/technology-65057011#:~:text=Clearview%20often%20points%20to%20research,are%20often%20based%20on%20mugshots.",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "nearly",
                "tells",
                "bbc",
                "using",
                "software",
                "used",
                "mr",
                "facial",
                "conlyn",
                "miami",
                "1m",
                "tonthat",
                "ai",
                "times",
                "clearview",
                "recognition"
            ],
            "summary": "Clearview AI used nearly 1m times by US police, it tells the BBCSpencer Whalen / EyeEmFacial recognition firm Clearview has run nearly a million searches for US police, its founder has told the BBC.\nMistaken identityThere are a handful of documented cases of mistaken identity using facial recognition by the police.\nHe accepts police have made wrongful arrests using facial recognition technology, but attributes those to \"poor policing\".\nKaitlin Jackson, a New York defence lawyerHowever, Mr Ton-That told the BBC he does not want to testify in court to its accuracy.\nAndrew ConlynThe witness, Vince Ramirez, made a statement that he had taken Mr Conlyn out of the passenger's seat.",
            "metadata": {
                "source_domain": "www.bbc.com",
                "scrape_date": "2024-10-25T12:40:21.525741",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 5693
            }
        },
        {
            "title": "The Secretive Company That Might End Privacy as We Know It",
            "text": "Until recently, Hoan Ton-That’s greatest hits included an obscure iPhone game and an app that let people put Donald Trump’s distinctive yellow hair on their own photos.\n\nThen Mr. Ton-That — an Australian techie and onetime model — did something momentous: He invented a tool that could end your ability to walk down the street anonymously, and provided it to hundreds of law enforcement agencies, ranging from local cops in Florida to the F.B.I. and the Department of Homeland Security.\n\nHis tiny company, Clearview AI, devised a groundbreaking facial recognition app. You take a picture of a person, upload it and get to see public photos of that person, along with links to where those photos appeared. The system — whose backbone is a database of more than three billion images that Clearview claims to have scraped from Facebook, YouTube, Venmo and millions of other websites — goes far beyond anything ever constructed by the United States government or Silicon Valley giants.\n\nFederal and state law enforcement officers said that while they had only limited knowledge of how Clearview works and who is behind it, they had used its app to help solve shoplifting, identity theft, credit card fraud, murder and child sexual exploitation cases.",
            "url": "https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html",
            "authors": [
                "Kashmir Hill"
            ],
            "publish_date": "2020-01-18T00:00:00",
            "keywords": [
                "yellow",
                "youtube",
                "law",
                "know",
                "company",
                "enforcement",
                "secretive",
                "end",
                "photos",
                "websites",
                "works",
                "privacy",
                "app",
                "clearview",
                "person"
            ],
            "summary": "Until recently, Hoan Ton-That’s greatest hits included an obscure iPhone game and an app that let people put Donald Trump’s distinctive yellow hair on their own photos.\nThen Mr. Ton-That — an Australian techie and onetime model — did something momentous: He invented a tool that could end your ability to walk down the street anonymously, and provided it to hundreds of law enforcement agencies, ranging from local cops in Florida to the F.B.I.\nHis tiny company, Clearview AI, devised a groundbreaking facial recognition app.\nYou take a picture of a person, upload it and get to see public photos of that person, along with links to where those photos appeared.\nFederal and state law enforcement officers said that while they had only limited knowledge of how Clearview works and who is behind it, they had used its app to help solve shoplifting, identity theft, credit card fraud, murder and child sexual exploitation cases.",
            "metadata": {
                "source_domain": "www.nytimes.com",
                "scrape_date": "2024-10-25T12:40:22.193744",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 1246
            }
        },
        {
            "title": "IAPP",
            "text": "{\"text\": \"You need to enable JavaScript to run this app.\"}",
            "url": "https://iapp.org/news/a/shaping-the-future-a-dynamic-taxonomy-for-ai-privacy-risks#:~:text=Insecurity%3A%20AI's%20data%20requirements%20and,of%20false%20or%20misleading%20information.",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "iapp"
            ],
            "summary": "",
            "metadata": {
                "source_domain": "iapp.org",
                "scrape_date": "2024-10-25T12:40:22.032420",
                "content_type": "news_articles",
                "extraction_method": "trafilatura",
                "content_length": 0
            }
        },
        {
            "title": "IAPP",
            "text": "{\"text\": \"You need to enable JavaScript to run this app.\"}",
            "url": "https://iapp.org/news/b/privacy-authorities-order-clearview-ai-to-stop-facial-recognition-use",
            "authors": [],
            "publish_date": null,
            "keywords": [
                "iapp"
            ],
            "summary": "",
            "metadata": {
                "source_domain": "iapp.org",
                "scrape_date": "2024-10-25T12:40:22.534353",
                "content_type": "news_articles",
                "extraction_method": "trafilatura",
                "content_length": 0
            }
        },
        {
            "title": "Facial recognition startup Clearview AI settles privacy suit",
            "text": "CHICAGO (AP) — Facial recognition startup Clearview AI reached a settlement Friday in an Illinois lawsuit alleging its massive photographic collection of faces violated the subjects’ privacy rights, a deal that attorneys estimate could be worth more than $50 million.\n\nBut the unique agreement gives plaintiffs in the federal suit a share of the company’s potential value, rather than a traditional payout. Attorneys’ fees estimated at $20 million also would come out of the settlement amount.\n\nJudge Sharon Johnson Coleman, of the Northern District of Illinois, gave preliminary approval to the agreement Friday.\n\nThe case consolidated lawsuits from around the U.S. filed against Clearview, which pulled photos from social media and elsewhere on the internet to create a database it sold to businesses, individuals and government entities.\n\nThe company settled a separate case alleging violation of privacy rights in Illinois in 2022, agreeing to stop selling access to its database to private businesses or individuals. That agreement still allowed Clearview to work with federal agencies and local law enforcement outside Illinois, which has a strict digital privacy law.\n\nClearview does not admit any liability as part of the latest settlement agreement.\n\n“Clearview AI is pleased to have reached an agreement in this class action settlement,” James Thompson, an attorney representing the company in the suit, said in a written statement Friday.\n\nThe lead plaintiffs’ attorney Jon Loevy said the agreement was a “creative solution” necessitated by Clearview’s financial status.\n\n“Clearview did not have anywhere near the cash to pay fair compensation to the class, so we needed to find a creative solution,” Loevy said in a statement. “Under the settlement, the victims whose privacy was breached now get to participate in any upside that is ultimately generated, thereby recapturing to the class to some extent the ownership of their biometrics.”\n\nIt’s not clear how many people would be eligible to join the settlement. The agreement language is sweeping, including anyone whose images or data are in the company’s database and who lived in the U.S. starting in July 1, 2017.\n\nA national campaign to notify potential plaintiffs is part of the agreement.\n\nThe attorneys for Clearview and the plaintiffs worked with Wayne Andersen, a retired federal judge who now mediates legal cases, to develop the settlement. In court filings presenting the agreement, Andersen bluntly writes that the startup could not have paid any legal judgment if the suit went forward.\n\n“Clearview did not have the funds to pay a multi-million-dollar judgment,” he is quoted in the filing. “Indeed, there was great uncertainty as to whether Clearview would even have enough money to make it through to the end of trial, much less fund a judgment.”\n\nBut some privacy advocates and people pursuing other legal action called the agreement a disappointment that won’t change the company’s operations.\n\nSejal Zota is an attorney and legal director for Just Futures Law, an organization representing plaintiffs in a California suit against the company. Zota said the agreement “legitimizes” Clearview.\n\n“It does not address the root of the problem,” Zota said. “Clearview gets to continue its practice of harvesting and selling people’s faces without their consent, and using them to train its AI tech.”",
            "url": "https://apnews.com/article/clearview-ai-facial-recognition-lawsuit-settlement-5a99ded04630a4e94af01f9f3adf1e29",
            "authors": [
                "Technology",
                "Breaking News"
            ],
            "publish_date": "2024-06-21T21:57:21",
            "keywords": [
                "startup",
                "settlement",
                "suit",
                "zota",
                "settles",
                "plaintiffs",
                "legal",
                "facial",
                "ai",
                "illinois",
                "privacy",
                "clearview",
                "federal",
                "agreement",
                "recognition"
            ],
            "summary": "CHICAGO (AP) — Facial recognition startup Clearview AI reached a settlement Friday in an Illinois lawsuit alleging its massive photographic collection of faces violated the subjects’ privacy rights, a deal that attorneys estimate could be worth more than $50 million.\nBut the unique agreement gives plaintiffs in the federal suit a share of the company’s potential value, rather than a traditional payout.\nThat agreement still allowed Clearview to work with federal agencies and local law enforcement outside Illinois, which has a strict digital privacy law.\nClearview does not admit any liability as part of the latest settlement agreement.\n“Clearview gets to continue its practice of harvesting and selling people’s faces without their consent, and using them to train its AI tech.”",
            "metadata": {
                "source_domain": "apnews.com",
                "scrape_date": "2024-10-25T12:40:24.501656",
                "content_type": "news_articles",
                "extraction_method": "newspaper3k",
                "content_length": 3377
            }
        }
    ]
}